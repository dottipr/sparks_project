{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import wandb\n",
    "from torch import nn, optim\n",
    "import random\n",
    "\n",
    "# from torch.cuda.amp import GradScaler\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from utils.training_inference_tools import (\n",
    "    sampler,\n",
    "    test_function,\n",
    "    training_step,\n",
    "    weights_init,\n",
    "    myTrainingManager,\n",
    ")\n",
    "from utils.training_script_utils import (\n",
    "    init_param_config_logs,\n",
    "    init_training_dataset,\n",
    "    init_testing_dataset,\n",
    "    init_model,\n",
    "    init_criterion,\n",
    ")\n",
    "from models.UNet import unet\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "torch.set_float32_matmul_precision(\"high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# fixed parameters #############################\n",
    "\n",
    "# General params\n",
    "logfile = None  # change this when publishing finished project on github\n",
    "# wandb_project_name = \"sparks2\"\n",
    "output_relative_path = \"runs\"  # directory where output, saved params and\n",
    "# testing results are saved\n",
    "\n",
    "# Dataset parameters\n",
    "ignore_index = 4  # label ignored during training\n",
    "num_classes = 4  # i.e., BG, sparks, waves, puffs\n",
    "ndims = 3  # using 3D data\n",
    "\n",
    "debug_mode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:43:09] [  INFO  ] [training_script_utils] < 97 > -- Loading config_files\\config_final_model_blur_frames_nll_loss.ini\n",
      "[15:43:09] [  INFO  ] [training_script_utils] <203 > -- Command parameters:\n",
      "[15:43:09] [  INFO  ] [training_script_utils] <205 > --                 run_name: final_model_blur_frames_nll_loss_2\n",
      "[15:43:09] [  INFO  ] [training_script_utils] <205 > --            load_run_name: None\n",
      "[15:43:09] [  INFO  ] [training_script_utils] <205 > --               load_epoch: 0\n",
      "[15:43:09] [  INFO  ] [training_script_utils] <205 > --             train_epochs: 100000\n",
      "[15:43:09] [  INFO  ] [training_script_utils] <205 > --                criterion: nll_loss\n",
      "[15:43:09] [  INFO  ] [training_script_utils] <205 > --                 lr_start: 0.0001\n",
      "[15:43:09] [  INFO  ] [training_script_utils] <205 > --       ignore_frames_loss: 6\n",
      "[15:43:09] [  INFO  ] [training_script_utils] <205 > --                     cuda: True\n",
      "[15:43:09] [  INFO  ] [training_script_utils] <205 > --                scheduler: None\n",
      "[15:43:09] [  INFO  ] [training_script_utils] <205 > --                optimizer: adam\n",
      "[15:43:09] [  INFO  ] [training_script_utils] <205 > --            relative_path: ../data/sparks_dataset\n",
      "[15:43:09] [  INFO  ] [training_script_utils] <205 > --             dataset_size: minimal\n",
      "[15:43:09] [  INFO  ] [training_script_utils] <205 > --               batch_size: 4\n",
      "[15:43:09] [  INFO  ] [training_script_utils] <205 > --              num_workers: 0\n",
      "[15:43:09] [  INFO  ] [training_script_utils] <205 > --            data_duration: 256\n",
      "[15:43:09] [  INFO  ] [training_script_utils] <205 > --                data_step: 32\n",
      "[15:43:09] [  INFO  ] [training_script_utils] <205 > --        testing_data_step: 32\n",
      "[15:43:09] [  INFO  ] [training_script_utils] <205 > --           data_smoothing: 2d\n",
      "[15:43:09] [  INFO  ] [training_script_utils] <205 > --               norm_video: abs_max\n",
      "[15:43:09] [  INFO  ] [training_script_utils] <205 > --        remove_background: no\n",
      "[15:43:09] [  INFO  ] [training_script_utils] <205 > --              only_sparks: False\n",
      "[15:43:09] [  INFO  ] [training_script_utils] <205 > --  noise_data_augmentation: False\n",
      "[15:43:09] [  INFO  ] [training_script_utils] <205 > --              sparks_type: raw\n",
      "[15:43:09] [  INFO  ] [training_script_utils] <205 > --                inference: overlap\n",
      "[15:43:09] [  INFO  ] [training_script_utils] <205 > --          nn_architecture: pablos_unet\n",
      "[15:43:09] [  INFO  ] [training_script_utils] <205 > --               unet_steps: 6\n",
      "[15:43:09] [  INFO  ] [training_script_utils] <205 > --     first_layer_channels: 8\n",
      "[15:43:09] [  INFO  ] [training_script_utils] <205 > --             num_channels: 1\n",
      "[15:43:09] [  INFO  ] [training_script_utils] <205 > --                 dilation: 1\n",
      "[15:43:09] [  INFO  ] [training_script_utils] <205 > --              border_mode: same\n",
      "[15:43:09] [  INFO  ] [training_script_utils] <205 > --      batch_normalization: none\n",
      "[15:43:09] [  INFO  ] [training_script_utils] <205 > --       temporal_reduction: False\n",
      "[15:43:09] [  INFO  ] [training_script_utils] <205 > --       initialize_weights: False\n"
     ]
    }
   ],
   "source": [
    "############################## get parameters ##############################\n",
    "\n",
    "c, params, wandb_log = init_param_config_logs(\n",
    "    basedir=None,\n",
    "    verbosity=3 if debug_mode else 2,\n",
    "    wandb_project_name=\"TEST\",\n",
    "    config_file=\"config_final_model_blur_frames_nll_loss.ini\"\n",
    "    # config_file=\"config_final_model.ini\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:43:09] [  INFO  ] [  __main__  ] < 27 > -- Using torch device cuda, with 1 GPUs\n",
      "[15:43:09] [  INFO  ] [  __main__  ] < 39 > -- Normalizing whole video using 16-bit absolute max\n",
      "[15:43:09] [  INFO  ] [  datasets  ] <178 > -- Applying 2d gaussian blur to videos...\n",
      "[15:43:09] [ DEBUG  ] [  datasets  ] <252 > -- Added padding of 12 frames to video with unsuitable duration\n"
     ]
    }
   ],
   "source": [
    "############################ configure datasets ############################\n",
    "\n",
    "# select samples that are used for training and testing\n",
    "if params[\"dataset_size\"] == \"full\":\n",
    "    train_sample_ids = [\n",
    "        \"01\",\n",
    "        \"02\",\n",
    "        \"03\",\n",
    "        \"04\",\n",
    "        \"06\",\n",
    "        \"07\",\n",
    "        \"08\",\n",
    "        \"09\",\n",
    "        \"11\",\n",
    "        \"12\",\n",
    "        \"13\",\n",
    "        \"14\",\n",
    "        \"16\",\n",
    "        \"17\",\n",
    "        \"18\",\n",
    "        \"19\",\n",
    "        \"21\",\n",
    "        \"22\",\n",
    "        \"23\",\n",
    "        \"24\",\n",
    "        \"27\",\n",
    "        \"28\",\n",
    "        \"29\",\n",
    "        \"30\",\n",
    "        \"33\",\n",
    "        \"35\",\n",
    "        \"36\",\n",
    "        \"38\",\n",
    "        \"39\",\n",
    "        \"41\",\n",
    "        \"42\",\n",
    "        \"43\",\n",
    "        \"44\",\n",
    "        \"46\",\n",
    "    ]\n",
    "    test_sample_ids = [\"05\", \"10\", \"15\", \"20\", \"25\", \"32\", \"34\", \"40\", \"45\"]\n",
    "elif params[\"dataset_size\"] == \"minimal\":\n",
    "    train_sample_ids = [\"01\"]\n",
    "    test_sample_ids = [\"34\"]\n",
    "else:\n",
    "    logger.error(f\"{params['dataset_size']} is not a valid dataset size.\")\n",
    "    exit()\n",
    "\n",
    "# detect CUDA devices\n",
    "if params[\"cuda\"]:\n",
    "    # if False:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    pin_memory = True\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    pin_memory = False\n",
    "n_gpus = torch.cuda.device_count()\n",
    "logger.info(f\"Using torch device {device}, with {n_gpus} GPUs\")\n",
    "\n",
    "# set if temporal reduction is used\n",
    "if params[\"temporal_reduction\"]:\n",
    "    logger.info(f\"Using temporal reduction with {params['num_channels']} channels\")\n",
    "\n",
    "# normalize whole videos or chunks individually\n",
    "if params[\"norm_video\"] == \"chunk\":\n",
    "    logger.info(\"Normalizing each chunk using min and max\")\n",
    "elif params[\"norm_video\"] == \"movie\":\n",
    "    logger.info(\"Normalizing whole video using min and max\")\n",
    "elif params[\"norm_video\"] == \"abs_max\":\n",
    "    logger.info(\"Normalizing whole video using 16-bit absolute max\")\n",
    "\n",
    "dataset_path = os.path.realpath(f\"{params['relative_path']}\")\n",
    "\n",
    "# initialize training dataset\n",
    "dataset = init_training_dataset(\n",
    "    params=params,\n",
    "    train_sample_ids=train_sample_ids,\n",
    "    ignore_index=ignore_index,\n",
    "    dataset_path=dataset_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train with only one batch\n",
    "# ids = np.arange(0, params[\"batch_size\"], 1, dtype=np.int64)\n",
    "# dataset = torch.utils.data.Subset(dataset, ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:43:10] [  INFO  ] [  __main__  ] < 1  > -- Samples in training dataset: 9\n",
      "[15:43:10] [ DEBUG  ] [  datasets  ] <304 > -- Computing spark peaks...\n",
      "[15:43:13] [ DEBUG  ] [  datasets  ] <311 > -- Sample 34 contains 16 sparks.\n",
      "[15:43:13] [  INFO  ] [  datasets  ] <178 > -- Applying 2d gaussian blur to videos...\n",
      "[15:43:14] [ DEBUG  ] [  datasets  ] <252 > -- Added padding of 24 frames to video with unsuitable duration\n",
      "[15:43:14] [  INFO  ] [  __main__  ] < 10 > -- Testing dataset 0 contains 22 samples\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"Samples in training dataset: {len(dataset)}\")\n",
    "\n",
    "# initialize testing dataset\n",
    "testing_datasets = init_testing_dataset(\n",
    "    params=params,\n",
    "    test_sample_ids=test_sample_ids,\n",
    "    ignore_index=ignore_index,\n",
    "    dataset_path=dataset_path,\n",
    ")\n",
    "\n",
    "for i, tds in enumerate(testing_datasets):\n",
    "    logger.info(f\"Testing dataset {i} contains {len(tds)} samples\")\n",
    "\n",
    "# initialize data loaders\n",
    "dataset_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=params[\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    num_workers=params[\"num_workers\"],\n",
    "    pin_memory=pin_memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################## configure UNet ##############################\n",
    "\n",
    "network = init_model(params=params, num_classes=num_classes, ndims=ndims)\n",
    "\n",
    "if device != \"cpu\":\n",
    "    network = nn.DataParallel(network).to(device)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "if wandb_log:\n",
    "    wandb.watch(network)\n",
    "\n",
    "if params[\"initialize_weights\"]:\n",
    "    logger.info(\"Initializing UNet weights...\")\n",
    "    network.apply(weights_init)\n",
    "\n",
    "# torch.compile(network, mode=\"default\", backend=\"inductor\")\n",
    "# does not work on windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:43:14] [ DEBUG  ] [  __main__  ] < 4  > -- Number of trainable parameters: 22631764\n"
     ]
    }
   ],
   "source": [
    "if debug_mode:\n",
    "    model_parameters = filter(lambda p: p.requires_grad, network.parameters())\n",
    "    model_parameters = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    logger.debug(f\"Number of trainable parameters: {model_parameters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:43:14] [  INFO  ] [  __main__  ] < 23 > -- Output directory: runs\\final_model_blur_frames_nll_loss_2\n",
      "[15:43:14] [  INFO  ] [training_script_utils] <429 > -- Using class weights: 0.2512798607349396, 312.7631530761719, 0.0, 58.220359802246094\n"
     ]
    }
   ],
   "source": [
    "########################### initialize training ############################\n",
    "\n",
    "if params[\"optimizer\"] == \"adam\":\n",
    "    optimizer = optim.Adam(network.parameters(), lr=params[\"lr_start\"])\n",
    "elif params[\"optimizer\"] == \"adadelta\":\n",
    "    optimizer = optim.Adadelta(network.parameters(), lr=params[\"lr_start\"])\n",
    "else:\n",
    "    logger.error(f\"{params['optimizer']} is not a valid optimizer.\")\n",
    "    exit()\n",
    "\n",
    "if params[\"scheduler\"] == \"step\":\n",
    "    scheduler = optim.lr_scheduler.StepLR(\n",
    "        optimizer,\n",
    "        step_size=params[\"scheduler_step_size\"],\n",
    "        gamma=params[\"scheduler_gamma\"],\n",
    "    )\n",
    "else:\n",
    "    scheduler = None\n",
    "\n",
    "network.train()\n",
    "\n",
    "output_path = os.path.join(output_relative_path, params[\"run_name\"])\n",
    "logger.info(f\"Output directory: {output_path}\")\n",
    "\n",
    "summary_writer = SummaryWriter(os.path.join(output_path, \"summary\"), purge_step=0)\n",
    "\n",
    "if params[\"load_run_name\"] != None:\n",
    "    load_path = os.path.join(output_relative_path, params[\"load_run_name\"])\n",
    "    logger.info(f\"Model loaded from directory: {load_path}\")\n",
    "else:\n",
    "    load_path = None\n",
    "\n",
    "# initialize loss function\n",
    "criterion = init_criterion(\n",
    "    params=params, dataset=dataset, ignore_index=ignore_index, device=device\n",
    ")\n",
    "\n",
    "# directory where predicted class movies are saved\n",
    "preds_output_dir = os.path.join(output_path, \"predictions\")\n",
    "os.makedirs(preds_output_dir, exist_ok=True)\n",
    "\n",
    "# generate dict of managed objects\n",
    "managed_objects = {\"network\": network, \"optimizer\": optimizer}\n",
    "if scheduler is not None:\n",
    "    managed_objects[\"scheduler\"] = scheduler\n",
    "\n",
    "trainer = myTrainingManager(\n",
    "    # training items\n",
    "    training_step=lambda _: training_step(\n",
    "        sampler=sampler,\n",
    "        network=network,\n",
    "        optimizer=optimizer,\n",
    "        # scaler=GradScaler(),\n",
    "        scheduler=scheduler,\n",
    "        device=device,\n",
    "        criterion=criterion,\n",
    "        dataset_loader=dataset_loader,\n",
    "        ignore_frames=params[\"ignore_frames_loss\"],\n",
    "    ),\n",
    "    save_every=c.getint(\"training\", \"save_every\", fallback=5000),\n",
    "    load_path=load_path,\n",
    "    save_path=output_path,\n",
    "    managed_objects=unet.managed_objects(managed_objects),\n",
    "    # testing items\n",
    "    test_function=lambda _: test_function(\n",
    "        network=network,\n",
    "        device=device,\n",
    "        criterion=criterion,\n",
    "        testing_datasets=testing_datasets,\n",
    "        ignore_frames=params[\"ignore_frames_loss\"],\n",
    "        training_name=params[\"run_name\"],\n",
    "        output_dir=preds_output_dir,\n",
    "        batch_size=params[\"batch_size\"],\n",
    "        training_mode=True,\n",
    "        debug=debug_mode,\n",
    "    ),\n",
    "    test_every=c.getint(\"training\", \"test_every\", fallback=1000),\n",
    "    plot_every=c.getint(\"training\", \"test_every\", fallback=1000),\n",
    "    summary_writer=summary_writer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ init random seeds #############################\n",
    "\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for load_epoch in [10000,20000,30000,40000,50000,60000,70000,80000,90000,100000]:\n",
    "# for load_epoch in [100000]:\n",
    "#     trainer.load(load_epoch)\n",
    "#     logger.info(\"Starting final validation\")\n",
    "#     trainer.run_validation(wandb_log=wandb_log)\n",
    "# if wandb_log:\n",
    "#     wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################## load model ##############################\n",
    "if params[\"load_epoch\"] != 0:\n",
    "    # trainer.load(10000)\n",
    "    trainer.load(params[\"load_epoch\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:43:16] [  INFO  ] [  __main__  ] < 6  > -- Starting training\n",
      "[15:43:40] [  INFO  ] [training_inference_tools] <102 > -- Iteration 0...\n",
      "[15:43:40] [  INFO  ] [training_inference_tools] <103 > -- \tTraining loss: 1.41\n",
      "[15:43:40] [  INFO  ] [training_inference_tools] <104 > -- \tTime elapsed: 25.67s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\dotti\\sparks_project\\sparks\\DEBUG training.ipynb Cell 14\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mif\u001b[39;00m c\u001b[39m.\u001b[39mgetboolean(\u001b[39m\"\u001b[39m\u001b[39mgeneral\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m\"\u001b[39m, fallback\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):  \u001b[39m# Run training procedure on data\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m# logger.info(\"Validate network before training\")\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m# trainer.run_validation(wandb_log=wandb_log)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mStarting training\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X16sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     trainer\u001b[39m.\u001b[39;49mtrain(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X16sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         params[\u001b[39m\"\u001b[39;49m\u001b[39mtrain_epochs\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X16sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         print_every\u001b[39m=\u001b[39;49mc\u001b[39m.\u001b[39;49mgetint(\u001b[39m\"\u001b[39;49m\u001b[39mtraining\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mprint_every\u001b[39;49m\u001b[39m\"\u001b[39;49m, fallback\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X16sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         wandb_log\u001b[39m=\u001b[39;49mwandb_log,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X16sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\dotti\\sparks_project\\sparks\\training_inference_tools.py:79\u001b[0m, in \u001b[0;36mmyTrainingManager.train\u001b[1;34m(self, num_iters, print_every, maxtime, wandb_log)\u001b[0m\n\u001b[0;32m     75\u001b[0m     loss_sum \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     77\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_iters):\n\u001b[1;32m---> 79\u001b[0m     step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter)\n\u001b[0;32m     81\u001b[0m     \u001b[39mif\u001b[39;00m wandb_log:\n\u001b[0;32m     82\u001b[0m         loss_sum \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m step_output[\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[1;32mc:\\Users\\dotti\\sparks_project\\sparks\\DEBUG training.ipynb Cell 14\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X16sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39mif\u001b[39;00m scheduler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X16sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     managed_objects[\u001b[39m\"\u001b[39m\u001b[39mscheduler\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m scheduler\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X16sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m trainer \u001b[39m=\u001b[39m myTrainingManager(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X16sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     \u001b[39m# training items\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X16sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m     training_step\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m _: training_step(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X16sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m         sampler\u001b[39m=\u001b[39;49msampler,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X16sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m         network\u001b[39m=\u001b[39;49mnetwork,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X16sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m         optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X16sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m         \u001b[39m# scaler=GradScaler(),\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X16sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m         scheduler\u001b[39m=\u001b[39;49mscheduler,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X16sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m         device\u001b[39m=\u001b[39;49mdevice,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X16sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m         criterion\u001b[39m=\u001b[39;49mcriterion,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X16sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m         dataset_loader\u001b[39m=\u001b[39;49mdataset_loader,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X16sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m         ignore_frames\u001b[39m=\u001b[39;49mparams[\u001b[39m\"\u001b[39;49m\u001b[39mignore_frames_loss\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X16sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m     ),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X16sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m     save_every\u001b[39m=\u001b[39mc\u001b[39m.\u001b[39mgetint(\u001b[39m\"\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msave_every\u001b[39m\u001b[39m\"\u001b[39m, fallback\u001b[39m=\u001b[39m\u001b[39m5000\u001b[39m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X16sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m     load_path\u001b[39m=\u001b[39mload_path,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X16sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m     save_path\u001b[39m=\u001b[39moutput_path,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X16sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m     managed_objects\u001b[39m=\u001b[39munet\u001b[39m.\u001b[39mmanaged_objects(managed_objects),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X16sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m     \u001b[39m# testing items\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X16sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m     test_function\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m _: test_function(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X16sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m         network\u001b[39m=\u001b[39mnetwork,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X16sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m         device\u001b[39m=\u001b[39mdevice,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X16sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m         criterion\u001b[39m=\u001b[39mcriterion,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X16sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m         testing_datasets\u001b[39m=\u001b[39mtesting_datasets,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X16sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m         ignore_frames\u001b[39m=\u001b[39mparams[\u001b[39m\"\u001b[39m\u001b[39mignore_frames_loss\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X16sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m         training_name\u001b[39m=\u001b[39mparams[\u001b[39m\"\u001b[39m\u001b[39mrun_name\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X16sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m         output_dir\u001b[39m=\u001b[39mpreds_output_dir,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X16sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m         batch_size\u001b[39m=\u001b[39mparams[\u001b[39m\"\u001b[39m\u001b[39mbatch_size\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X16sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m         training_mode\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X16sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m         debug\u001b[39m=\u001b[39mdebug_mode,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X16sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m     ),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X16sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m     test_every\u001b[39m=\u001b[39mc\u001b[39m.\u001b[39mgetint(\u001b[39m\"\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtest_every\u001b[39m\u001b[39m\"\u001b[39m, fallback\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X16sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m     plot_every\u001b[39m=\u001b[39mc\u001b[39m.\u001b[39mgetint(\u001b[39m\"\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtest_every\u001b[39m\u001b[39m\"\u001b[39m, fallback\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X16sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m     summary_writer\u001b[39m=\u001b[39msummary_writer,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X16sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\dotti\\sparks_project\\sparks\\training_inference_tools.py:190\u001b[0m, in \u001b[0;36mtraining_step\u001b[1;34m(sampler, network, optimizer, scheduler, device, criterion, dataset_loader, ignore_frames)\u001b[0m\n\u001b[0;32m    187\u001b[0m loss \u001b[39m=\u001b[39m criterion(pred, target)\n\u001b[0;32m    189\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad(set_to_none\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m--> 190\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m    191\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m    193\u001b[0m \u001b[39m# scaler.scale(loss).backward()\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \u001b[39m# scaler.step(optimizer)\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[39m# scaler.update()\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dotti\\.conda\\envs\\sparks\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\dotti\\.conda\\envs\\sparks\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "############################## start training ##############################\n",
    "\n",
    "if c.getboolean(\n",
    "    \"general\", \"training\", fallback=False\n",
    "):  # Run training procedure on data\n",
    "    # logger.info(\"Validate network before training\")\n",
    "    # trainer.run_validation(wandb_log=wandb_log)\n",
    "    logger.info(\"Starting training\")\n",
    "    trainer.train(\n",
    "        params[\"train_epochs\"],\n",
    "        print_every=c.getint(\"training\", \"print_every\", fallback=100),\n",
    "        wandb_log=wandb_log,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:43:51] [  INFO  ] [  __main__  ] < 4  > -- Starting final validation\n",
      "[15:43:51] [  INFO  ] [training_inference_tools] < 46 > -- Validating network at iteration 6...\n",
      "[15:43:51] [ DEBUG  ] [training_inference_tools] <801 > -- Testing function: running sample 34 in UNet\n",
      "[15:43:56] [  INFO  ] [training_inference_tools] <828 > -- DEBUG: max and min difference between preds[1] and preds[3]: 0.11100940406322479, 0.11004564166069031\n",
      "[15:43:56] [ DEBUG  ] [in_out_tools] <281 > -- Writing videos on directory c:\\Users\\dotti\\sparks_project\\sparks\\runs\\final_model_blur_frames_nll_loss_2\\predictions ..\n",
      "(904, 64, 512)\n",
      "runs\\final_model_blur_frames_nll_loss_2\\predictions\\final_model_blur_frames_nll_loss_2_34_xs.tif\n",
      "[15:43:57] [ DEBUG  ] [training_inference_tools] <870 > -- Time to run sample 34 in UNet: 5.55 s\n",
      "[15:43:57] [ DEBUG  ] [training_inference_tools] <877 > -- Testing function: re-organising annotations\n",
      "[15:43:59] [ DEBUG  ] [training_inference_tools] <906 > -- Time to re-organise annotations: 2.85 s\n",
      "[15:43:59] [ DEBUG  ] [training_inference_tools] <912 > -- Testing function: getting processed output (segmentation and instances)\n",
      "[15:44:00] [ DEBUG  ] [data_processing_tools] <459 > -- Events detection threshold: 0.757\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\dotti\\sparks_project\\sparks\\DEBUG training.ipynb Cell 15\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mif\u001b[39;00m c\u001b[39m.\u001b[39mgetboolean(\u001b[39m\"\u001b[39m\u001b[39mgeneral\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtesting\u001b[39m\u001b[39m\"\u001b[39m, fallback\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):  \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mStarting final validation\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     trainer\u001b[39m.\u001b[39;49mrun_validation(wandb_log\u001b[39m=\u001b[39;49mwandb_log)\n",
      "File \u001b[1;32mc:\\Users\\dotti\\sparks_project\\sparks\\training_inference_tools.py:48\u001b[0m, in \u001b[0;36mmyTrainingManager.run_validation\u001b[1;34m(self, wandb_log)\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m     46\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mValidating network at iteration \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m...\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39miter))\n\u001b[1;32m---> 48\u001b[0m test_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtest_function(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter)\n\u001b[0;32m     50\u001b[0m \u001b[39mif\u001b[39;00m wandb_log:\n\u001b[0;32m     51\u001b[0m     wandb\u001b[39m.\u001b[39mlog({m: val \u001b[39mfor\u001b[39;00m m, val \u001b[39min\u001b[39;00m test_output\u001b[39m.\u001b[39mitems()\n\u001b[0;32m     52\u001b[0m                \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mconfusion_matrix\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m m}, step\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39miter)\n",
      "\u001b[1;32mc:\\Users\\dotti\\sparks_project\\sparks\\DEBUG training.ipynb Cell 15\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X20sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39mif\u001b[39;00m scheduler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X20sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     managed_objects[\u001b[39m\"\u001b[39m\u001b[39mscheduler\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m scheduler\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X20sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m trainer \u001b[39m=\u001b[39m myTrainingManager(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X20sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     \u001b[39m# training items\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X20sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m     training_step\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m _: training_step(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X20sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m         sampler\u001b[39m=\u001b[39msampler,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X20sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m         network\u001b[39m=\u001b[39mnetwork,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X20sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m         optimizer\u001b[39m=\u001b[39moptimizer,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X20sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m         \u001b[39m# scaler=GradScaler(),\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X20sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m         scheduler\u001b[39m=\u001b[39mscheduler,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X20sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m         device\u001b[39m=\u001b[39mdevice,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X20sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m         criterion\u001b[39m=\u001b[39mcriterion,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X20sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m         dataset_loader\u001b[39m=\u001b[39mdataset_loader,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X20sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m         ignore_frames\u001b[39m=\u001b[39mparams[\u001b[39m\"\u001b[39m\u001b[39mignore_frames_loss\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X20sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m     ),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X20sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m     save_every\u001b[39m=\u001b[39mc\u001b[39m.\u001b[39mgetint(\u001b[39m\"\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msave_every\u001b[39m\u001b[39m\"\u001b[39m, fallback\u001b[39m=\u001b[39m\u001b[39m5000\u001b[39m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X20sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m     load_path\u001b[39m=\u001b[39mload_path,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X20sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m     save_path\u001b[39m=\u001b[39moutput_path,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X20sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m     managed_objects\u001b[39m=\u001b[39munet\u001b[39m.\u001b[39mmanaged_objects(managed_objects),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X20sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m     \u001b[39m# testing items\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X20sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m     test_function\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m _: test_function(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X20sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m         network\u001b[39m=\u001b[39;49mnetwork,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X20sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m         device\u001b[39m=\u001b[39;49mdevice,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X20sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m         criterion\u001b[39m=\u001b[39;49mcriterion,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X20sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m         testing_datasets\u001b[39m=\u001b[39;49mtesting_datasets,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X20sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m         ignore_frames\u001b[39m=\u001b[39;49mparams[\u001b[39m\"\u001b[39;49m\u001b[39mignore_frames_loss\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X20sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m         training_name\u001b[39m=\u001b[39;49mparams[\u001b[39m\"\u001b[39;49m\u001b[39mrun_name\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X20sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m         output_dir\u001b[39m=\u001b[39;49mpreds_output_dir,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X20sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m         batch_size\u001b[39m=\u001b[39;49mparams[\u001b[39m\"\u001b[39;49m\u001b[39mbatch_size\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X20sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m         training_mode\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X20sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m         debug\u001b[39m=\u001b[39;49mdebug_mode,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X20sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m     ),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X20sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m     test_every\u001b[39m=\u001b[39mc\u001b[39m.\u001b[39mgetint(\u001b[39m\"\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtest_every\u001b[39m\u001b[39m\"\u001b[39m, fallback\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X20sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m     plot_every\u001b[39m=\u001b[39mc\u001b[39m.\u001b[39mgetint(\u001b[39m\"\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtest_every\u001b[39m\u001b[39m\"\u001b[39m, fallback\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X20sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m     summary_writer\u001b[39m=\u001b[39msummary_writer,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dotti/sparks_project/sparks/DEBUG%20training.ipynb#X20sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\dotti\\sparks_project\\sparks\\training_inference_tools.py:916\u001b[0m, in \u001b[0;36mtest_function\u001b[1;34m(network, device, criterion, ignore_frames, testing_datasets, training_name, output_dir, batch_size, training_mode, debug)\u001b[0m\n\u001b[0;32m    912\u001b[0m logger\u001b[39m.\u001b[39mdebug(\n\u001b[0;32m    913\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mTesting function: getting processed output (segmentation and instances)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    915\u001b[0m \u001b[39m# get predicted segmentation and event instances\u001b[39;00m\n\u001b[1;32m--> 916\u001b[0m preds_instances, preds_segmentation, _ \u001b[39m=\u001b[39m get_processed_result(\n\u001b[0;32m    917\u001b[0m     sparks\u001b[39m=\u001b[39;49mpreds[\u001b[39m1\u001b[39;49m],\n\u001b[0;32m    918\u001b[0m     puffs\u001b[39m=\u001b[39;49mpreds[\u001b[39m3\u001b[39;49m],\n\u001b[0;32m    919\u001b[0m     waves\u001b[39m=\u001b[39;49mpreds[\u001b[39m2\u001b[39;49m],\n\u001b[0;32m    920\u001b[0m     xs\u001b[39m=\u001b[39;49mxs,\n\u001b[0;32m    921\u001b[0m     conn_mask\u001b[39m=\u001b[39;49mconn_mask,\n\u001b[0;32m    922\u001b[0m     connectivity\u001b[39m=\u001b[39;49mconnectivity,\n\u001b[0;32m    923\u001b[0m     max_gap\u001b[39m=\u001b[39;49mmax_gap,\n\u001b[0;32m    924\u001b[0m     sigma\u001b[39m=\u001b[39;49msigma,\n\u001b[0;32m    925\u001b[0m     wave_min_width\u001b[39m=\u001b[39;49mwave_min_width,\n\u001b[0;32m    926\u001b[0m     puff_min_t\u001b[39m=\u001b[39;49mpuff_min_t,\n\u001b[0;32m    927\u001b[0m     spark_min_t\u001b[39m=\u001b[39;49mspark_min_t,\n\u001b[0;32m    928\u001b[0m     spark_min_width\u001b[39m=\u001b[39;49mspark_min_width,\n\u001b[0;32m    929\u001b[0m     training_mode\u001b[39m=\u001b[39;49mtraining_mode,\n\u001b[0;32m    930\u001b[0m     debug\u001b[39m=\u001b[39;49mdebug\n\u001b[0;32m    931\u001b[0m )\n\u001b[0;32m    933\u001b[0m \u001b[39m# get number of predicted events per class\u001b[39;00m\n\u001b[0;32m    934\u001b[0m \u001b[39m# for ca_event in ca_release_events:\u001b[39;00m\n\u001b[0;32m    935\u001b[0m \u001b[39m#     # n_preds_per_class[ca_event] += (\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    948\u001b[0m \n\u001b[0;32m    949\u001b[0m \u001b[39m# stack annotations and remove marginal frames\u001b[39;00m\n\u001b[0;32m    950\u001b[0m ys_concat\u001b[39m.\u001b[39mappend(empty_marginal_frames(\n\u001b[0;32m    951\u001b[0m     video\u001b[39m=\u001b[39mys, n_frames\u001b[39m=\u001b[39mignore_frames))\n",
      "File \u001b[1;32mc:\\Users\\dotti\\sparks_project\\sparks\\data_processing_tools.py:825\u001b[0m, in \u001b[0;36mget_processed_result\u001b[1;34m(sparks, puffs, waves, xs, conn_mask, connectivity, max_gap, sigma, wave_min_width, puff_min_t, spark_min_t, spark_min_width, training_mode, debug)\u001b[0m\n\u001b[0;32m    820\u001b[0m preds_segmentation, _ \u001b[39m=\u001b[39m get_argmax_segmentation_otsu(\n\u001b[0;32m    821\u001b[0m     preds\u001b[39m=\u001b[39mpreds, get_classes\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, debug\u001b[39m=\u001b[39mdebug\n\u001b[0;32m    822\u001b[0m )\n\u001b[0;32m    824\u001b[0m \u001b[39m# Separate events in predictions\u001b[39;00m\n\u001b[1;32m--> 825\u001b[0m preds_instances, sparks_loc \u001b[39m=\u001b[39m get_separated_events(\n\u001b[0;32m    826\u001b[0m     argmax_preds\u001b[39m=\u001b[39;49mpreds_segmentation,\n\u001b[0;32m    827\u001b[0m     movie\u001b[39m=\u001b[39;49mxs,\n\u001b[0;32m    828\u001b[0m     sigma\u001b[39m=\u001b[39;49msigma,\n\u001b[0;32m    829\u001b[0m     connectivity\u001b[39m=\u001b[39;49mconnectivity,\n\u001b[0;32m    830\u001b[0m     connectivity_mask\u001b[39m=\u001b[39;49mconn_mask,\n\u001b[0;32m    831\u001b[0m     return_sparks_loc\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    832\u001b[0m     debug\u001b[39m=\u001b[39;49mdebug,\n\u001b[0;32m    833\u001b[0m     training_mode\u001b[39m=\u001b[39;49mtraining_mode\n\u001b[0;32m    834\u001b[0m )\n\u001b[0;32m    836\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m    837\u001b[0m \u001b[39m# Remove small events and merge events that belong together\u001b[39;00m\n\u001b[0;32m    838\u001b[0m \u001b[39m# Waves\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dotti\\sparks_project\\sparks\\data_processing_tools.py:516\u001b[0m, in \u001b[0;36mget_separated_events\u001b[1;34m(argmax_preds, movie, sigma, connectivity, connectivity_mask, return_sparks_loc, debug, training_mode)\u001b[0m\n\u001b[0;32m    507\u001b[0m ccs_class_preds \u001b[39m=\u001b[39m {\n\u001b[0;32m    508\u001b[0m     class_name: cc3d\u001b[39m.\u001b[39mconnected_components(\n\u001b[0;32m    509\u001b[0m         class_argmax_preds, connectivity\u001b[39m=\u001b[39mconnectivity, return_N\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    512\u001b[0m     \u001b[39mif\u001b[39;00m class_name \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msparks\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    513\u001b[0m }\n\u001b[0;32m    515\u001b[0m \u001b[39m# compute spark peaks locations\u001b[39;00m\n\u001b[1;32m--> 516\u001b[0m loc, mask_loc \u001b[39m=\u001b[39m simple_nonmaxima_suppression(\n\u001b[0;32m    517\u001b[0m     img\u001b[39m=\u001b[39;49mmovie,\n\u001b[0;32m    518\u001b[0m     maxima_mask\u001b[39m=\u001b[39;49margmax_preds[\u001b[39m\"\u001b[39;49m\u001b[39msparks\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    519\u001b[0m     min_dist\u001b[39m=\u001b[39;49mconnectivity_mask,\n\u001b[0;32m    520\u001b[0m     return_mask\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    521\u001b[0m     threshold\u001b[39m=\u001b[39;49m\u001b[39m0.0\u001b[39;49m,\n\u001b[0;32m    522\u001b[0m     sigma\u001b[39m=\u001b[39;49msigma,\n\u001b[0;32m    523\u001b[0m )\n\u001b[0;32m    525\u001b[0m logger\u001b[39m.\u001b[39mdebug(\n\u001b[0;32m    526\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNumber of sparks detected by nonmaxima suppression: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(loc)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    528\u001b[0m \u001b[39m# compute smooth version of input video\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dotti\\sparks_project\\sparks\\data_processing_tools.py:1140\u001b[0m, in \u001b[0;36msimple_nonmaxima_suppression\u001b[1;34m(img, maxima_mask, min_dist, return_mask, threshold, sigma)\u001b[0m\n\u001b[0;32m   1137\u001b[0m     smooth_img \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(maxima_mask, smooth_img, \u001b[39m0.0\u001b[39m)\n\u001b[0;32m   1139\u001b[0m \u001b[39m# search for local maxima\u001b[39;00m\n\u001b[1;32m-> 1140\u001b[0m dilated \u001b[39m=\u001b[39m ndi\u001b[39m.\u001b[39;49mmaximum_filter(smooth_img, footprint\u001b[39m=\u001b[39;49mmin_dist)\n\u001b[0;32m   1141\u001b[0m argmaxima \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlogical_and(smooth_img \u001b[39m==\u001b[39m dilated, smooth_img \u001b[39m>\u001b[39m threshold)\n\u001b[0;32m   1143\u001b[0m argwhere \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margwhere(argmaxima)\n",
      "File \u001b[1;32mc:\\Users\\dotti\\.conda\\envs\\sparks\\lib\\site-packages\\scipy\\ndimage\\_filters.py:1331\u001b[0m, in \u001b[0;36mmaximum_filter\u001b[1;34m(input, size, footprint, output, mode, cval, origin, axes)\u001b[0m\n\u001b[0;32m   1287\u001b[0m \u001b[39m@_ni_docstrings\u001b[39m\u001b[39m.\u001b[39mdocfiller\n\u001b[0;32m   1288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmaximum_filter\u001b[39m(\u001b[39minput\u001b[39m, size\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, footprint\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, output\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1289\u001b[0m                    mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mreflect\u001b[39m\u001b[39m\"\u001b[39m, cval\u001b[39m=\u001b[39m\u001b[39m0.0\u001b[39m, origin\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, \u001b[39m*\u001b[39m, axes\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   1290\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Calculate a multidimensional maximum filter.\u001b[39;00m\n\u001b[0;32m   1291\u001b[0m \n\u001b[0;32m   1292\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1329\u001b[0m \u001b[39m    >>> plt.show()\u001b[39;00m\n\u001b[0;32m   1330\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1331\u001b[0m     \u001b[39mreturn\u001b[39;00m _min_or_max_filter(\u001b[39minput\u001b[39;49m, size, footprint, \u001b[39mNone\u001b[39;49;00m, output, mode,\n\u001b[0;32m   1332\u001b[0m                               cval, origin, \u001b[39m0\u001b[39;49m, axes)\n",
      "File \u001b[1;32mc:\\Users\\dotti\\.conda\\envs\\sparks\\lib\\site-packages\\scipy\\ndimage\\_filters.py:1231\u001b[0m, in \u001b[0;36m_min_or_max_filter\u001b[1;34m(input, size, footprint, structure, output, mode, cval, origin, minimum, axes)\u001b[0m\n\u001b[0;32m   1227\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1228\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mA sequence of modes is not supported for non-separable \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1229\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mfootprints\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1230\u001b[0m     mode \u001b[39m=\u001b[39m _ni_support\u001b[39m.\u001b[39m_extend_mode_to_code(mode)\n\u001b[1;32m-> 1231\u001b[0m     _nd_image\u001b[39m.\u001b[39;49mmin_or_max_filter(\u001b[39minput\u001b[39;49m, footprint, structure, output,\n\u001b[0;32m   1232\u001b[0m                                 mode, cval, origins, minimum)\n\u001b[0;32m   1233\u001b[0m \u001b[39mif\u001b[39;00m temp_needed:\n\u001b[0;32m   1234\u001b[0m     temp[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m] \u001b[39m=\u001b[39m output\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "############################## run final validation ##############################\n",
    "\n",
    "if c.getboolean(\"general\", \"testing\", fallback=False):\n",
    "    logger.info(\"Starting final validation\")\n",
    "    trainer.run_validation(wandb_log=wandb_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if wandb_log:\n",
    "    wandb.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize UNet architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get number of trainable parameters\n",
    "# num_params = sum(p.numel() for p in network.parameters() if p.requires_grad)\n",
    "# logger.debug(f\"Number of trainable parameters: {num_params}\")\n",
    "# # get dummy unet input\n",
    "# batch = next(iter(dataset_loader))\n",
    "# x = batch[0].to(device)\n",
    "# yhat = network(x[:,None]) # Give dummy batch to forward()\n",
    "# from torchviz import make_dot\n",
    "# make_dot(yhat, params=dict(list(network.named_parameters()))).render(\"unet_model\", format=\"png\")\n",
    "# a = [0,1,2,3,4,5,6,7,8,9,10,11,12,13]\n",
    "\n",
    "# len(a[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sparks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d33eb8e81965b779f2871c6ab1ae98a760df4ff814358c9a5efa0a44482010f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
