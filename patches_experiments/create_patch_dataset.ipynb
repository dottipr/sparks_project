{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create patch dataset from real data\n",
    "\n",
    "**Author**: Prisca Dotti  \n",
    "**Last modified**: 14.06.24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload is used to reload modules automatically before entering the\n",
    "# execution of code typed at the IPython prompt.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# To import modules from parent directory in Jupyter Notebook\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import napari\n",
    "from config import config\n",
    "from utils.in_out_tools import load_annotations_ids, load_movies_ids\n",
    "from data.data_processing_tools import detect_spark_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select samples to include in dataset\n",
    "sample_ids = [\n",
    "    \"01\",\n",
    "    # \"02\",\n",
    "    # \"03\",\n",
    "    # \"04\",\n",
    "    \"05\",\n",
    "    # \"06\",\n",
    "    # \"07\",\n",
    "    # \"08\",\n",
    "    # \"09\",\n",
    "    # \"10\",\n",
    "    # \"11\",\n",
    "    # \"12\",\n",
    "    # \"13\",\n",
    "    # \"14\",\n",
    "    # \"15\",\n",
    "    # \"16\",\n",
    "    # \"17\",\n",
    "    # \"18\",\n",
    "    # \"19\",\n",
    "    # \"20\",\n",
    "    # \"21\",\n",
    "    # \"22\",\n",
    "    # \"23\",\n",
    "    # \"24\",\n",
    "    # \"25\",\n",
    "    # \"27\",\n",
    "    # \"28\",\n",
    "    # \"29\",\n",
    "    # \"30\",\n",
    "    # \"32\",\n",
    "    # \"33\",\n",
    "    \"34\",\n",
    "    # \"35\",\n",
    "    # \"36\",\n",
    "    # \"38\",\n",
    "    # \"39\",\n",
    "    # \"40\",\n",
    "    # \"41\",\n",
    "    # \"42\",\n",
    "    # \"43\",\n",
    "    # \"44\",\n",
    "    # \"45\",\n",
    "    # \"46\",\n",
    "]\n",
    "\n",
    "raw_data_dir = os.path.join(\"..\", \"data\", \"sparks_dataset\")\n",
    "out_dir = \"patch_dataset\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "patch_shape = (64, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fits_in_patch(spark, patch_start, patch_shape):\n",
    "    \"\"\"\n",
    "    Check if a spark coordinate fits within the bounds of a given patch.\n",
    "\n",
    "    Parameters:\n",
    "    spark (tuple): The (t, y, x) coordinates of the spark.\n",
    "    patch_start (tuple): The starting (t_start, y_start, x_start)\n",
    "        coordinates of the patch.\n",
    "    patch_shape (tuple): The shape (t_patch, y_patch, x_patch) of the patch.\n",
    "\n",
    "    Returns:\n",
    "    bool: True if the spark fits within the patch, False otherwise.\n",
    "    \"\"\"\n",
    "    t_patch, y_patch, x_patch = patch_shape\n",
    "    t, y, x = spark\n",
    "    t_start, y_start, x_start = patch_start\n",
    "    t_end = t_start + t_patch\n",
    "    y_end = y_start + y_patch\n",
    "    x_end = x_start + x_patch\n",
    "    return t_start <= t < t_end and y_start <= y < y_end and x_start <= x < x_end\n",
    "\n",
    "\n",
    "def create_patches_from_sparks(sparks_coord, video_shape, patch_shape):\n",
    "    \"\"\"\n",
    "    Create patches from spark coordinates, ensuring each spark is contained in\n",
    "    exactly one patch, and maximizing the number of patches.\n",
    "\n",
    "    Parameters:\n",
    "    sparks_coord (list): List of (t, y, x) coordinates of the sparks.\n",
    "    video_shape (tuple): The shape (t, y, x) of the video.\n",
    "    patch_shape (tuple): The shape (t_patch, y_patch, x_patch) of the patches.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of patch start coordinates (t_start, y_start, x_start).\n",
    "    \"\"\"\n",
    "    t_patch, y_patch, x_patch = patch_shape\n",
    "    patches = []\n",
    "    assigned_sparks = set()\n",
    "\n",
    "    def find_patch_for_spark(spark):\n",
    "        \"\"\"\n",
    "        Find an existing patch that can contain the given spark.\n",
    "\n",
    "        Parameters:\n",
    "        spark (tuple): The (t, y, x) coordinates of the spark.\n",
    "\n",
    "        Returns:\n",
    "        tuple or None: The starting coordinates (t_start, y_start, x_start) of\n",
    "        the patch if found, otherwise None.\n",
    "        \"\"\"\n",
    "        for patch_start in patches:\n",
    "            if fits_in_patch(spark, patch_start, patch_shape):\n",
    "                return patch_start\n",
    "        return None\n",
    "\n",
    "    def is_spark_assigned(spark):\n",
    "        \"\"\"\n",
    "        Check if a spark has already been assigned to a patch.\n",
    "\n",
    "        Parameters:\n",
    "        spark (tuple): The (t, y, x) coordinates of the spark.\n",
    "\n",
    "        Returns:\n",
    "        bool: True if the spark is already assigned, False otherwise.\n",
    "        \"\"\"\n",
    "        return spark in assigned_sparks\n",
    "\n",
    "    for spark in sparks_coord:\n",
    "        if is_spark_assigned(spark):\n",
    "            continue\n",
    "\n",
    "        patch_start = find_patch_for_spark(spark)\n",
    "        if patch_start is None:\n",
    "            t, y, x = spark\n",
    "            t_start = max(0, t - t_patch // 2)\n",
    "            y_start = max(0, y - y_patch // 2)\n",
    "            x_start = max(0, x - x_patch // 2)\n",
    "\n",
    "            if t_start + t_patch > video_shape[0]:\n",
    "                t_start = video_shape[0] - t_patch\n",
    "            if y_start + y_patch > video_shape[1]:\n",
    "                y_start = video_shape[1] - y_patch\n",
    "            if x_start + x_patch > video_shape[2]:\n",
    "                x_start = video_shape[2] - x_patch\n",
    "\n",
    "            patch_start = (t_start, y_start, x_start)\n",
    "            patches.append(patch_start)\n",
    "\n",
    "        # Mark all sparks in the current patch as assigned\n",
    "        t_start, y_start, x_start = patch_start\n",
    "        t_end = t_start + t_patch\n",
    "        y_end = y_start + y_patch\n",
    "        x_end = x_start + x_patch\n",
    "\n",
    "        for t, y, x in sparks_coord:\n",
    "            if t_start <= t < t_end and y_start <= y < y_end and x_start <= x < x_end:\n",
    "                assigned_sparks.add((t, y, x))\n",
    "\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting patches from sample 01...\n",
      "  Loaded video with shape: (500, 64, 512)\n",
      "  Type of events in sample 01: [1 3 4]\n",
      "  Removing patch (37, 5, 187) due to puff or wave pixels\n",
      "  Removing patch (198, 3, 195) due to puff or wave pixels\n",
      "  Removing patch (286, 0, 192) due to puff or wave pixels\n",
      "  Removing patch (243, 0, 213) due to puff or wave pixels\n",
      "  Patch 1:\n",
      "    T: (48, 112), Y: (30, 62), X: (227, 259)\n",
      "  Patch 2:\n",
      "    T: (143, 207), Y: (29, 61), X: (246, 278)\n",
      "  Patch 3:\n",
      "    T: (336, 400), Y: (8, 40), X: (219, 251)\n",
      "  Patch 4:\n",
      "    T: (1, 65), Y: (10, 42), X: (166, 198)\n",
      "  Patch 5:\n",
      "    T: (163, 227), Y: (9, 41), X: (181, 213)\n",
      "  Patch 6:\n",
      "    T: (202, 266), Y: (19, 51), X: (146, 178)\n",
      "  Patch 7:\n",
      "    T: (436, 500), Y: (23, 55), X: (171, 203)\n",
      "  Patch 8:\n",
      "    T: (33, 97), Y: (10, 42), X: (166, 198)\n",
      "  Patch 9:\n",
      "    T: (29, 93), Y: (0, 32), X: (212, 244)\n",
      "Extracting patches from sample 05...\n",
      "  Loaded video with shape: (500, 64, 512)\n",
      "  Type of events in sample 05: [1 3 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n",
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Removing patch (75, 0, 102) due to puff or wave pixels\n",
      "  Removing patch (47, 0, 178) due to puff or wave pixels\n",
      "  Removing patch (322, 29, 147) due to puff or wave pixels\n",
      "  Removing patch (164, 6, 182) due to puff or wave pixels\n",
      "  Removing patch (374, 32, 154) due to puff or wave pixels\n",
      "  Removing patch (6, 31, 51) due to puff or wave pixels\n",
      "  Removing patch (196, 32, 154) due to puff or wave pixels\n",
      "  Removing patch (271, 5, 122) due to puff or wave pixels\n",
      "  Removing patch (92, 10, 69) due to puff or wave pixels\n",
      "  Removing patch (9, 22, 73) due to puff or wave pixels\n",
      "  Removing patch (267, 20, 187) due to puff or wave pixels\n",
      "  Patch 1:\n",
      "    T: (164, 228), Y: (25, 57), X: (287, 319)\n",
      "  Patch 2:\n",
      "    T: (154, 218), Y: (32, 64), X: (126, 158)\n",
      "  Patch 3:\n",
      "    T: (26, 90), Y: (9, 41), X: (92, 124)\n",
      "  Patch 4:\n",
      "    T: (45, 109), Y: (25, 57), X: (86, 118)\n",
      "  Patch 5:\n",
      "    T: (251, 315), Y: (4, 36), X: (320, 352)\n",
      "  Patch 6:\n",
      "    T: (63, 127), Y: (32, 64), X: (127, 159)\n",
      "  Patch 7:\n",
      "    T: (339, 403), Y: (0, 32), X: (239, 271)\n",
      "  Patch 8:\n",
      "    T: (280, 344), Y: (0, 32), X: (97, 129)\n",
      "  Patch 9:\n",
      "    T: (413, 477), Y: (32, 64), X: (59, 91)\n",
      "  Patch 10:\n",
      "    T: (294, 358), Y: (4, 36), X: (217, 249)\n",
      "  Patch 11:\n",
      "    T: (179, 243), Y: (21, 53), X: (66, 98)\n",
      "  Patch 12:\n",
      "    T: (0, 64), Y: (32, 64), X: (106, 138)\n",
      "  Patch 13:\n",
      "    T: (422, 486), Y: (24, 56), X: (281, 313)\n",
      "  Patch 14:\n",
      "    T: (230, 294), Y: (16, 48), X: (275, 307)\n",
      "  Patch 15:\n",
      "    T: (277, 341), Y: (12, 44), X: (70, 102)\n",
      "  Patch 16:\n",
      "    T: (109, 173), Y: (6, 38), X: (181, 213)\n",
      "  Patch 17:\n",
      "    T: (393, 457), Y: (32, 64), X: (93, 125)\n",
      "  Patch 18:\n",
      "    T: (69, 133), Y: (5, 37), X: (289, 321)\n",
      "  Patch 19:\n",
      "    T: (16, 80), Y: (28, 60), X: (147, 179)\n",
      "  Patch 20:\n",
      "    T: (0, 64), Y: (28, 60), X: (229, 261)\n",
      "  Patch 21:\n",
      "    T: (373, 437), Y: (0, 32), X: (346, 378)\n",
      "  Patch 22:\n",
      "    T: (383, 447), Y: (4, 36), X: (321, 353)\n",
      "  Patch 23:\n",
      "    T: (0, 64), Y: (0, 32), X: (365, 397)\n",
      "  Patch 24:\n",
      "    T: (50, 114), Y: (4, 36), X: (239, 271)\n",
      "  Patch 25:\n",
      "    T: (37, 101), Y: (23, 55), X: (281, 313)\n",
      "  Patch 26:\n",
      "    T: (10, 74), Y: (9, 41), X: (134, 166)\n",
      "  Patch 27:\n",
      "    T: (26, 90), Y: (0, 32), X: (335, 367)\n",
      "  Patch 28:\n",
      "    T: (370, 434), Y: (32, 64), X: (249, 281)\n",
      "  Patch 29:\n",
      "    T: (101, 165), Y: (31, 63), X: (166, 198)\n",
      "  Patch 30:\n",
      "    T: (436, 500), Y: (0, 32), X: (328, 360)\n",
      "  Patch 31:\n",
      "    T: (188, 252), Y: (0, 32), X: (323, 355)\n",
      "  Patch 32:\n",
      "    T: (110, 174), Y: (0, 32), X: (323, 355)\n",
      "  Patch 33:\n",
      "    T: (0, 64), Y: (0, 32), X: (206, 238)\n",
      "  Patch 34:\n",
      "    T: (436, 500), Y: (12, 44), X: (310, 342)\n",
      "  Patch 35:\n",
      "    T: (0, 64), Y: (32, 64), X: (193, 225)\n",
      "  Patch 36:\n",
      "    T: (267, 331), Y: (13, 45), X: (288, 320)\n",
      "  Patch 37:\n",
      "    T: (151, 215), Y: (0, 32), X: (117, 149)\n",
      "  Patch 38:\n",
      "    T: (386, 450), Y: (13, 45), X: (288, 320)\n",
      "  Patch 39:\n",
      "    T: (436, 500), Y: (3, 35), X: (238, 270)\n",
      "  Patch 40:\n",
      "    T: (173, 237), Y: (32, 64), X: (37, 69)\n",
      "Extracting patches from sample 34...\n",
      "  Loaded video with shape: (904, 64, 512)\n",
      "  Type of events in sample 34: [1 2 3 4]\n",
      "  Removing patch (673, 28, 325) due to puff or wave pixels\n",
      "  Removing patch (401, 27, 355) due to puff or wave pixels\n",
      "  Removing patch (554, 32, 127) due to puff or wave pixels\n",
      "  Removing patch (39, 32, 363) due to puff or wave pixels\n",
      "  Patch 1:\n",
      "    T: (758, 822), Y: (27, 59), X: (182, 214)\n",
      "  Patch 2:\n",
      "    T: (46, 110), Y: (22, 54), X: (161, 193)\n",
      "  Patch 3:\n",
      "    T: (112, 176), Y: (32, 64), X: (140, 172)\n",
      "  Patch 4:\n",
      "    T: (840, 904), Y: (26, 58), X: (315, 347)\n",
      "  Patch 5:\n",
      "    T: (334, 398), Y: (31, 63), X: (355, 387)\n",
      "  Patch 6:\n",
      "    T: (840, 904), Y: (32, 64), X: (134, 166)\n",
      "  Patch 7:\n",
      "    T: (126, 190), Y: (27, 59), X: (167, 199)\n",
      "  Patch 8:\n",
      "    T: (371, 435), Y: (32, 64), X: (293, 325)\n",
      "  Patch 9:\n",
      "    T: (444, 508), Y: (32, 64), X: (251, 283)\n"
     ]
    }
   ],
   "source": [
    "patches_dict = {}\n",
    "for sample_id in sample_ids:\n",
    "    print(f\"Extracting patches from sample {sample_id}...\")\n",
    "\n",
    "    video = load_movies_ids(\n",
    "        data_folder=raw_data_dir,\n",
    "        ids=[sample_id],\n",
    "        names_available=True,\n",
    "        movie_names=\"video\",\n",
    "    )[sample_id]\n",
    "    print(f\"  Loaded video with shape: {video.shape}\")\n",
    "\n",
    "    class_label = load_annotations_ids(\n",
    "        data_folder=raw_data_dir, ids=[sample_id], mask_names=\"class_label\"\n",
    "    )[sample_id]\n",
    "    events_in_sample = np.unique(class_label)\n",
    "    events_in_sample = events_in_sample[events_in_sample != 0]\n",
    "    print(f\"  Type of events in sample {sample_id}: {events_in_sample}\")\n",
    "\n",
    "    event_label = load_annotations_ids(\n",
    "        data_folder=raw_data_dir, ids=[sample_id], mask_names=\"event_label\"\n",
    "    )[sample_id]\n",
    "\n",
    "    sparks_event_label = np.where(class_label == 1, event_label, 0)\n",
    "\n",
    "    sparks_coord = detect_spark_peaks(\n",
    "        movie=video,\n",
    "        instances_mask=sparks_event_label,\n",
    "        sigma=config.sparks_sigma_dataset,\n",
    "        max_filter_size=10,\n",
    "    )\n",
    "\n",
    "    # Create patches from the spark coordinates\n",
    "    patches = create_patches_from_sparks(\n",
    "        sparks_coord=sparks_coord, video_shape=video.shape, patch_shape=patch_shape\n",
    "    )\n",
    "\n",
    "    # Filter out patches that contain too much puff or wave pixels\n",
    "    for patch_start in patches:\n",
    "        t_start, y_start, x_start = patch_start\n",
    "        t_end = t_start + patch_shape[0]\n",
    "        y_end = y_start + patch_shape[1]\n",
    "        x_end = x_start + patch_shape[2]\n",
    "        puff_pixels = np.sum(\n",
    "            class_label[t_start:t_end, y_start:y_end, x_start:x_end] == 2\n",
    "        )\n",
    "        wave_pixels = np.sum(\n",
    "            class_label[t_start:t_end, y_start:y_end, x_start:x_end] == 3\n",
    "        )\n",
    "        if (\n",
    "            puff_pixels > 0.1 * patch_shape[1] * patch_shape[2]\n",
    "            or wave_pixels > 0.1 * patch_shape[1] * patch_shape[2]\n",
    "        ):\n",
    "            print(f\"  Removing patch {patch_start} due to puff or wave pixels\")\n",
    "            patches.remove(patch_start)\n",
    "\n",
    "    # Output information about the patches\n",
    "    for i, patch_start in enumerate(patches):\n",
    "        t_start, y_start, x_start = patch_start\n",
    "        t_end = t_start + patch_shape[0]\n",
    "        y_end = y_start + patch_shape[1]\n",
    "        x_end = x_start + patch_shape[2]\n",
    "        print(f\"  Patch {i+1}:\")\n",
    "        print(\n",
    "            f\"    T: ({t_start}, {t_end}), Y: ({y_start}, {y_end}), X: ({x_start}, {x_end})\"\n",
    "        )\n",
    "        # peaks_in_patch = [\n",
    "        #     spark\n",
    "        #     for spark in sparks_coord\n",
    "        #     if fits_in_patch(spark, patch_start, patch_shape)\n",
    "        # ]\n",
    "        # classes_in_patch = np.unique(\n",
    "        #     class_label[t_start:t_end, y_start:y_end, x_start:x_end]\n",
    "        # )\n",
    "        # classes_in_patch = classes_in_patch[classes_in_patch != 0]\n",
    "        # sparks_in_patch = np.unique(\n",
    "        #     sparks_event_label[t_start:t_end, y_start:y_end, x_start:x_end]\n",
    "        # )\n",
    "        # sparks_in_patch = sparks_in_patch[sparks_in_patch != 0]\n",
    "        # print(f\"    Classes in patch: {classes_in_patch}\")\n",
    "        # print(f\"    Sparks in patch: {sparks_in_patch}\")\n",
    "        # print(f\"    Peaks in patch:\")\n",
    "        # for p in peaks_in_patch:\n",
    "        #     print(f\"      {p} (event ID: {event_label[p]})\")\n",
    "\n",
    "    patches_dict[sample_id] = patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of patches: 58\n"
     ]
    }
   ],
   "source": [
    "n_patches = sum(len(patches) for patches in patches_dict.values())\n",
    "print(f\"Total number of patches: {n_patches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n",
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patches for sample 34: 13\n"
     ]
    }
   ],
   "source": [
    "# Visualize selected patches using napari\n",
    "\n",
    "sample_id = \"34\"\n",
    "\n",
    "video = load_movies_ids(\n",
    "    data_folder=raw_data_dir,\n",
    "    ids=[sample_id],\n",
    "    names_available=True,\n",
    "    movie_names=\"video\",\n",
    ")[sample_id]\n",
    "\n",
    "class_label = load_annotations_ids(\n",
    "    data_folder=raw_data_dir, ids=[sample_id], mask_names=\"class_label\"\n",
    ")[sample_id]\n",
    "\n",
    "event_label = load_annotations_ids(\n",
    "    data_folder=raw_data_dir, ids=[sample_id], mask_names=\"event_label\"\n",
    ")[sample_id]\n",
    "\n",
    "sparks_event_label = np.where(class_label == 1, event_label, 0)\n",
    "\n",
    "sparks_coord = detect_spark_peaks(\n",
    "    movie=video,\n",
    "    instances_mask=sparks_event_label,\n",
    "    sigma=config.sparks_sigma_dataset,\n",
    "    max_filter_size=10,\n",
    ")\n",
    "\n",
    "patches = patches_dict[sample_id]\n",
    "print(f\"Number of patches for sample {sample_id}: {len(patches)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for patch_id, (t_start, y_start, x_start) in enumerate(patches):\n",
    "\n",
    "    # patch_id = 45 + patch_id\n",
    "\n",
    "    t_patch, y_patch, x_patch = patch_shape\n",
    "    t_end = t_start + t_patch\n",
    "    y_end = y_start + y_patch\n",
    "    x_end = x_start + x_patch\n",
    "\n",
    "    peaks_in_patch = [\n",
    "        (t - t_start, y - y_start, x - x_start)\n",
    "        for (t, y, x) in sparks_coord\n",
    "        if fits_in_patch((t, y, x), patches[patch_id], patch_shape)\n",
    "    ]\n",
    "\n",
    "    viewer = napari.Viewer()\n",
    "    viewer.add_image(video[t_start:t_end, y_start:y_end, x_start:x_end], name=\"video\")\n",
    "    viewer.add_labels(\n",
    "        class_label[t_start:t_end, y_start:y_end, x_start:x_end],\n",
    "        name=\"class_label\",\n",
    "        opacity=0.5,\n",
    "    )\n",
    "    # viewer.add_labels(\n",
    "    #     event_label[t_start:t_end, y_start:y_end, x_start:x_end],\n",
    "    #     name=\"event_label\",\n",
    "    #     opacity=0.5,\n",
    "    #     visible=False\n",
    "    #     )\n",
    "    # viewer.add_labels(\n",
    "    #     sparks_event_label[t_start:t_end],\n",
    "    #     name=\"sparks_event_label\",\n",
    "    #     opacity=0.5,\n",
    "    #     visible=False\n",
    "    #     )\n",
    "    viewer.add_points(peaks_in_patch, name=\"peaks_in_patch\", face_color=\"red\", size=2)\n",
    "    viewer.dims.current_step = (0, y_patch // 2, x_patch // 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sparks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
