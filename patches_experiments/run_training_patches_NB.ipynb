{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments on Patches of Confocal tyx-Image Series\n",
    "\n",
    "**Author**: Prisca Dotti\n",
    "\n",
    "**Last Edit**: 17.06.2024\n",
    "\n",
    "This notebook is used to run some experiments using the U-Net model on patches obtained from either real or fake confocal imaging data.\n",
    "\n",
    "The dataset used for training could be one of the following:\n",
    "- dataset of patches extracted in a meaningful way from confocal imaging recordings\n",
    "- dataset of recordings from which patches are extracted when processing them in the U-Net for memory management reasons and which are recombined as whole movies after inference\n",
    "- dataset of simulated confocal imaging patches --> this is similar to what I've been doing so far\n",
    "- a combination of real and fake patches of confocal imaging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload is used to reload modules automatically before entering the\n",
    "# execution of code typed at the IPython prompt.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# To import modules from parent directory in Jupyter Notebook\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import wandb\n",
    "from torch import nn, optim\n",
    "\n",
    "# from torch.cuda.amp import GradScaler\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "\n",
    "from config import TrainingConfig, config\n",
    "from data.datasets import PatchCaEventsDataset, PatchSparksDataset\n",
    "from models.UNet import unet\n",
    "from utils.training_inference_tools import (\n",
    "    MyTrainingManager,\n",
    "    TransformedSparkDataset,\n",
    "    random_flip,\n",
    "    random_flip_noise,\n",
    "    sampler,\n",
    "    test_function_patches,\n",
    "    training_step,\n",
    "    weights_init,\n",
    ")\n",
    "from utils.training_script_utils import (\n",
    "    get_sample_ids,\n",
    "    init_config_file_path,\n",
    "    init_criterion,\n",
    "    init_dataset,\n",
    "    init_model,\n",
    ")\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:03:36] [  INFO  ] [   config   ] <318 > -- Loading C:\\Users\\prisc\\Code\\sparks_project\\config_files\\config_sparks_patches.ini\n",
      "[18:03:37] [  INFO  ] [   config   ] <570 > --     training_config_file: C:\\Users\\prisc\\Code\\sparks_project\\config_files\\config_sparks_patches.ini\n",
      "[18:03:37] [  INFO  ] [   config   ] <570 > --              dataset_dir: C:\\Users\\prisc\\Code\\sparks_project\\data\\sparks_dataset\n",
      "[18:03:37] [  INFO  ] [   config   ] <570 > --                        c: <configparser.ConfigParser object at 0x000001C5D7D2BB80>\n",
      "[18:03:37] [  INFO  ] [   config   ] <570 > --                 run_name: sparks_patches\n",
      "[18:03:37] [  INFO  ] [   config   ] <570 > --            load_run_name: \n",
      "[18:03:37] [  INFO  ] [   config   ] <570 > --               load_epoch: 0\n",
      "[18:03:37] [  INFO  ] [   config   ] <570 > --             train_epochs: 100000\n",
      "[18:03:37] [  INFO  ] [   config   ] <570 > --                criterion: lovasz_softmax\n",
      "[18:03:37] [  INFO  ] [   config   ] <570 > --                 lr_start: 0.0001\n",
      "[18:03:37] [  INFO  ] [   config   ] <570 > --       ignore_frames_loss: 6\n",
      "[18:03:37] [  INFO  ] [   config   ] <570 > --                     cuda: True\n",
      "[18:03:37] [  INFO  ] [   config   ] <570 > --                scheduler: None\n",
      "[18:03:37] [  INFO  ] [   config   ] <570 > --                optimizer: adam\n",
      "[18:03:37] [  INFO  ] [   config   ] <570 > --             dataset_size: full\n",
      "[18:03:37] [  INFO  ] [   config   ] <570 > --               batch_size: 64\n",
      "[18:03:37] [  INFO  ] [   config   ] <570 > --              num_workers: 0\n",
      "[18:03:37] [  INFO  ] [   config   ] <570 > --            data_duration: 64\n",
      "[18:03:37] [  INFO  ] [   config   ] <570 > --              data_stride: 32\n",
      "[18:03:37] [  INFO  ] [   config   ] <570 > --               patch_size: [32, 32, 32]\n",
      "[18:03:37] [  INFO  ] [   config   ] <570 > --           data_smoothing: no\n",
      "[18:03:37] [  INFO  ] [   config   ] <570 > --               norm_video: abs_max\n",
      "[18:03:37] [  INFO  ] [   config   ] <570 > --        remove_background: no\n",
      "[18:03:37] [  INFO  ] [   config   ] <570 > --       mask_cell_exterior: False\n",
      "[18:03:37] [  INFO  ] [   config   ] <570 > --  noise_data_augmentation: False\n",
      "[18:03:37] [  INFO  ] [   config   ] <570 > --              sparks_type: raw\n",
      "[18:03:37] [  INFO  ] [   config   ] <570 > --                  new_fps: 0\n",
      "[18:03:37] [  INFO  ] [   config   ] <570 > --             sin_channels: False\n",
      "[18:03:37] [  INFO  ] [   config   ] <570 > --           n_sin_channels: [0, 0, 0]\n",
      "[18:03:37] [  INFO  ] [   config   ] <570 > --  inference_data_duration: 256\n",
      "[18:03:37] [  INFO  ] [   config   ] <570 > --    inference_data_stride: 32\n",
      "[18:03:37] [  INFO  ] [   config   ] <570 > --                inference: patches\n",
      "[18:03:37] [  INFO  ] [   config   ] <570 > --     inference_load_epoch: 100000\n",
      "[18:03:37] [  INFO  ] [   config   ] <570 > --     inference_batch_size: 32\n",
      "[18:03:37] [  INFO  ] [   config   ] <570 > --   inference_dataset_size: full\n",
      "[18:03:37] [  INFO  ] [   config   ] <570 > --          nn_architecture: pablos_unet\n",
      "[18:03:37] [  INFO  ] [   config   ] <570 > --               unet_steps: 4\n",
      "[18:03:37] [  INFO  ] [   config   ] <570 > --     first_layer_channels: 8\n",
      "[18:03:37] [  INFO  ] [   config   ] <570 > --             num_channels: 1\n",
      "[18:03:37] [  INFO  ] [   config   ] <570 > --                 dilation: 1\n",
      "[18:03:37] [  INFO  ] [   config   ] <570 > --              border_mode: same\n",
      "[18:03:37] [  INFO  ] [   config   ] <570 > --      batch_normalization: none\n",
      "[18:03:37] [  INFO  ] [   config   ] <570 > --       temporal_reduction: False\n",
      "[18:03:37] [  INFO  ] [   config   ] <570 > --       initialize_weights: False\n",
      "[18:03:37] [  INFO  ] [   config   ] <570 > --                wandb_log: False\n",
      "[18:03:37] [  INFO  ] [   config   ] <570 > --                   device: cuda\n",
      "[18:03:37] [  INFO  ] [   config   ] <570 > --               pin_memory: True\n",
      "[18:03:37] [  INFO  ] [   config   ] <570 > --                   n_gpus: 1\n"
     ]
    }
   ],
   "source": [
    "##################### Get training-specific parameters #####################\n",
    "\n",
    "# Initialize training-specific parameters\n",
    "# (get the configuration file path from ArgParse)\n",
    "config_filename = os.path.join(\"config_files\", \"config_sparks_patches.ini\")\n",
    "# config_filename = os.path.join(\"config_files\", \"config_final_model.ini\")\n",
    "\n",
    "params = TrainingConfig(training_config_file=config_filename)\n",
    "\n",
    "# Print parameters to console if needed\n",
    "params.print_params()\n",
    "\n",
    "######################### Initialize random seeds ##########################\n",
    "\n",
    "# We used these random seeds to ensure reproducibility of the results\n",
    "\n",
    "torch.manual_seed(0)  # <--------------------------------------------------!\n",
    "random.seed(0)  # <--------------------------------------------------------!\n",
    "np.random.seed(0)  # <-----------------------------------------------------!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:03:37] [  INFO  ] [   config   ] <566 > -- Using cuda\n"
     ]
    }
   ],
   "source": [
    "# params.set_device(\"cpu\")\n",
    "params.display_device_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file: 'C:\\Users\\prisc\\Code\\sparks_project\\data\\sparks_dataset\\02_video.tif'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 14\u001b[0m\n\u001b[0;32m      8\u001b[0m test_sample_ids \u001b[38;5;241m=\u001b[39m get_sample_ids(\n\u001b[0;32m      9\u001b[0m     train_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     10\u001b[0m     dataset_size\u001b[38;5;241m=\u001b[39mparams\u001b[38;5;241m.\u001b[39mdataset_size,\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Initialize training dataset\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mPatchSparksDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_sample_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_instances\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# this is needed to detect patches wrt spark peaks\u001b[39;49;00m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43minference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Apply transforms based on noise_data_augmentation setting\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# (transforms are applied when getting a sample from the dataset)\u001b[39;00m\n\u001b[0;32m     24\u001b[0m transforms \u001b[38;5;241m=\u001b[39m random_flip_noise \u001b[38;5;28;01mif\u001b[39;00m params\u001b[38;5;241m.\u001b[39mnoise_data_augmentation \u001b[38;5;28;01melse\u001b[39;00m random_flip\n",
      "File \u001b[1;32mc:\\Users\\prisc\\Code\\sparks_project\\patches_experiments\\..\\data\\datasets.py:1038\u001b[0m, in \u001b[0;36mPatchSparksDataset.__init__\u001b[1;34m(self, params, **kwargs)\u001b[0m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, params: TrainingConfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1037\u001b[0m     \u001b[38;5;66;03m# Initialize SparkDataset class\u001b[39;00m\n\u001b[1;32m-> 1038\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1040\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_duration, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_height, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_width)\n\u001b[0;32m   1041\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_patches_from_movies()\n",
      "File \u001b[1;32mc:\\Users\\prisc\\Code\\sparks_project\\patches_experiments\\..\\data\\datasets.py:118\u001b[0m, in \u001b[0;36mCaEventsDataset.__init__\u001b[1;34m(self, params, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m load_instances: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_instances\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    117\u001b[0m \u001b[38;5;66;03m### Get video samples and ground truth ###\u001b[39;00m\n\u001b[1;32m--> 118\u001b[0m movies \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_movies\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# dict of numpy arrays\u001b[39;00m\n\u001b[0;32m    119\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_labels()  \u001b[38;5;66;03m# list of numpy arrays\u001b[39;00m\n\u001b[0;32m    120\u001b[0m instances \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_instances() \u001b[38;5;28;01mif\u001b[39;00m load_instances \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[0;32m    122\u001b[0m )  \u001b[38;5;66;03m# list of numpy arrays\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\prisc\\Code\\sparks_project\\patches_experiments\\..\\data\\datasets.py:273\u001b[0m, in \u001b[0;36mCaEventsDataset._load_movies\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_movies\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[np\u001b[38;5;241m.\u001b[39mndarray]:\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;66;03m# Load movie data for each sample ID\u001b[39;00m\n\u001b[1;32m--> 273\u001b[0m     movies \u001b[38;5;241m=\u001b[39m \u001b[43mload_movies_ids\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnames_available\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmovie_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvideo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;66;03m# Extract and return the movie values as a list\u001b[39;00m\n\u001b[0;32m    281\u001b[0m     movies \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(movies\u001b[38;5;241m.\u001b[39mvalues())\n",
      "File \u001b[1;32mc:\\Users\\prisc\\Code\\sparks_project\\patches_experiments\\..\\utils\\in_out_tools.py:78\u001b[0m, in \u001b[0;36mload_movies_ids\u001b[1;34m(data_folder, ids, names_available, movie_names)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m xs_filenames:\n\u001b[0;32m     77\u001b[0m     video_id \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplit(f)[\u001b[38;5;241m1\u001b[39m][:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m---> 78\u001b[0m     xs_all_trainings[video_id] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\u001b[43mimageio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvolread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xs_all_trainings\n",
      "File \u001b[1;32mc:\\Users\\prisc\\anaconda3\\envs\\sparks\\lib\\site-packages\\imageio\\v2.py:358\u001b[0m, in \u001b[0;36mvolread\u001b[1;34m(uri, format, **kwargs)\u001b[0m\n\u001b[0;32m    356\u001b[0m imopen_args \u001b[38;5;241m=\u001b[39m decypher_format_arg(\u001b[38;5;28mformat\u001b[39m)\n\u001b[0;32m    357\u001b[0m imopen_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlegacy_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 358\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m imopen(uri, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mimopen_args) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m file\u001b[38;5;241m.\u001b[39mread(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\prisc\\anaconda3\\envs\\sparks\\lib\\site-packages\\imageio\\core\\imopen.py:118\u001b[0m, in \u001b[0;36mimopen\u001b[1;34m(uri, io_mode, plugin, extension, format_hint, legacy_mode, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m     request\u001b[38;5;241m.\u001b[39mformat_hint \u001b[38;5;241m=\u001b[39m format_hint\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m     request \u001b[38;5;241m=\u001b[39m \u001b[43mRequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mio_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_hint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextension\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m source \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<bytes>\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(uri, \u001b[38;5;28mbytes\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m uri\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m# fast-path based on plugin\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# (except in legacy mode)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\prisc\\anaconda3\\envs\\sparks\\lib\\site-packages\\imageio\\core\\request.py:248\u001b[0m, in \u001b[0;36mRequest.__init__\u001b[1;34m(self, uri, mode, extension, format_hint, **kwargs)\u001b[0m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Request.Mode: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    247\u001b[0m \u001b[38;5;66;03m# Parse what was given\u001b[39;00m\n\u001b[1;32m--> 248\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# Set extension\u001b[39;00m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extension \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\prisc\\anaconda3\\envs\\sparks\\lib\\site-packages\\imageio\\core\\request.py:407\u001b[0m, in \u001b[0;36mRequest._parse_uri\u001b[1;34m(self, uri)\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_read_request:\n\u001b[0;32m    405\u001b[0m     \u001b[38;5;66;03m# Reading: check that the file exists (but is allowed a dir)\u001b[39;00m\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(fn):\n\u001b[1;32m--> 407\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m fn)\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;66;03m# Writing: check that the directory to write to does exist\u001b[39;00m\n\u001b[0;32m    410\u001b[0m     dn \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(fn)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: No such file: 'C:\\Users\\prisc\\Code\\sparks_project\\data\\sparks_dataset\\02_video.tif'"
     ]
    }
   ],
   "source": [
    "############################ Configure datasets ############################\n",
    "\n",
    "# Select samples for training and testing based on dataset size\n",
    "train_sample_ids = get_sample_ids(\n",
    "    train_data=True,\n",
    "    dataset_size=params.dataset_size,\n",
    ")\n",
    "test_sample_ids = get_sample_ids(\n",
    "    train_data=False,\n",
    "    dataset_size=params.dataset_size,\n",
    ")\n",
    "\n",
    "# Initialize training dataset\n",
    "dataset = PatchSparksDataset(\n",
    "    params=params,\n",
    "    base_path=params.dataset_dir,\n",
    "    sample_ids=train_sample_ids,\n",
    "    load_instances=True,  # this is needed to detect patches wrt spark peaks\n",
    "    inference=None,\n",
    ")\n",
    "\n",
    "# Apply transforms based on noise_data_augmentation setting\n",
    "# (transforms are applied when getting a sample from the dataset)\n",
    "transforms = random_flip_noise if params.noise_data_augmentation else random_flip\n",
    "dataset = TransformedSparkDataset(dataset, transforms)\n",
    "\n",
    "logger.info(f\"Samples in dataset (patches): {len(dataset)}\")\n",
    "\n",
    "# Initialize testing datasets\n",
    "testing_dataset = PatchSparksDataset(\n",
    "    params=params,\n",
    "    base_path=params.dataset_dir,\n",
    "    sample_ids=test_sample_ids,\n",
    "    load_instances=True,  # this is needed to detect patches wrt spark peaks\n",
    "    inference=None,\n",
    ")\n",
    "\n",
    "logger.info(f\"Samples in test dataset (patches): {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import napari\n",
    "\n",
    "# viewer = napari.Viewer()\n",
    "\n",
    "# train_sample_id = 9\n",
    "# train_sample = dataset[train_sample_id]\n",
    "# train_data = train_sample[\"data\"].numpy()\n",
    "# train_labels = train_sample[\"labels\"].numpy()\n",
    "# viewer.add_image(train_data)\n",
    "# viewer.add_labels(train_labels)\n",
    "\n",
    "# test_sample_id = 0\n",
    "# test_sample = testing_dataset[test_sample_id]\n",
    "# test_data = test_sample[\"data\"].numpy()\n",
    "# test_labels = test_sample[\"labels\"].numpy()\n",
    "# viewer.add_image(test_data)\n",
    "# viewer.add_labels(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data loaders\n",
    "dataset_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=params.batch_size,\n",
    "    num_workers=params.num_workers,\n",
    "    pin_memory=params.pin_memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################## Configure UNet ##############################\n",
    "\n",
    "# Initialize the UNet model\n",
    "network = init_model(params=params)\n",
    "\n",
    "# Move the model to the GPU if available\n",
    "if params.device.type != \"cpu\":\n",
    "    network = nn.DataParallel(network).to(params.device, non_blocking=True)\n",
    "    # cudnn.benchmark = True\n",
    "\n",
    "# Watch the model with wandb for logging if enabled\n",
    "if params.wandb_log:\n",
    "    wandb.watch(network)\n",
    "\n",
    "# Initialize UNet weights if required\n",
    "if params.initialize_weights:\n",
    "    logger.info(\"Initializing UNet weights...\")\n",
    "    network.apply(weights_init)\n",
    "\n",
    "# The following line is commented as it does not work on Windows\n",
    "# torch.compile(network, mode=\"default\", backend=\"inductor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:07:57] [  INFO  ] [  __main__  ] < 26 > -- Output directory: C:\\Users\\prisc\\Code\\sparks_project\\models\\saved_models\\sparks_patches\n"
     ]
    }
   ],
   "source": [
    "########################### Initialize training ############################\n",
    "\n",
    "# Initialize the optimizer based on the specified type\n",
    "if params.optimizer == \"adam\":\n",
    "    optimizer = optim.Adam(network.parameters(), lr=params.lr_start)\n",
    "elif params.optimizer == \"adadelta\":\n",
    "    optimizer = optim.Adadelta(network.parameters(), lr=params.lr_start)\n",
    "elif params.optimizer == \"sgd\":\n",
    "    optimizer = optim.SGD(network.parameters(), lr=params.lr_start)\n",
    "else:\n",
    "    logger.error(f\"{params.optimizer} is not a valid optimizer.\")\n",
    "    exit()\n",
    "\n",
    "# Initialize the learning rate scheduler if specified\n",
    "if params.scheduler == \"step\":\n",
    "    scheduler = optim.lr_scheduler.StepLR(\n",
    "        optimizer,\n",
    "        step_size=params.scheduler_step_size,\n",
    "        gamma=params.scheduler_gamma,\n",
    "    )\n",
    "else:\n",
    "    scheduler = None\n",
    "\n",
    "# Define the output directory path\n",
    "output_path = os.path.join(config.output_dir, params.run_name)\n",
    "logger.info(f\"Output directory: {os.path.realpath(output_path)}\")\n",
    "\n",
    "# Initialize the summary writer for TensorBoard logging\n",
    "summary_writer = SummaryWriter(os.path.join(output_path, \"summary\"), purge_step=0)\n",
    "\n",
    "# Check if a pre-trained model should be loaded\n",
    "if params.load_run_name != \"\":\n",
    "    load_path = os.path.join(config.output_dir, params.load_run_name)\n",
    "    logger.info(f\"Model loaded from directory: {os.path.realpath(load_path)}\")\n",
    "else:\n",
    "    load_path = None\n",
    "\n",
    "# Initialize the loss function\n",
    "criterion = init_criterion(params=params, dataset=dataset)\n",
    "\n",
    "# Create a directory to save predicted class movies\n",
    "preds_output_dir = os.path.join(output_path, \"predictions\")\n",
    "os.makedirs(preds_output_dir, exist_ok=True)\n",
    "\n",
    "# Create a dictionary of managed objects\n",
    "managed_objects = {\"network\": network, \"optimizer\": optimizer}\n",
    "if scheduler is not None:\n",
    "    managed_objects[\"scheduler\"] = scheduler\n",
    "\n",
    "# Create a training manager with the specified training and testing functions\n",
    "trainer = MyTrainingManager(\n",
    "    # Training parameters\n",
    "    training_step=lambda _: training_step(\n",
    "        dataset_loader=dataset_loader,\n",
    "        params=params,\n",
    "        sampler=sampler,\n",
    "        network=network,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        scheduler=scheduler,\n",
    "        # scaler=GradScaler(),\n",
    "    ),\n",
    "    save_every=params.c.getint(\"training\", \"save_every\", fallback=5000),\n",
    "    load_path=load_path,\n",
    "    save_path=output_path,\n",
    "    managed_objects=unet.managed_objects(managed_objects),\n",
    "    # Testing parameters\n",
    "    test_function=lambda _: test_function_patches(\n",
    "        network=network,\n",
    "        device=params.device,\n",
    "        criterion=criterion,\n",
    "        params=params,\n",
    "        testing_dataset=testing_dataset,\n",
    "        training_name=params.run_name,\n",
    "        output_dir=preds_output_dir,\n",
    "        training_mode=True,\n",
    "    ),\n",
    "    test_every=params.c.getint(\"training\", \"test_every\", fallback=1000),\n",
    "    plot_every=params.c.getint(\"training\", \"test_every\", fallback=1000),\n",
    "    summary_writer=summary_writer,\n",
    ")\n",
    "\n",
    "# Load the model if a specific epoch is provided\n",
    "if params.load_epoch != 0:\n",
    "    trainer.load(params.load_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the network before training if resuming from a checkpoint\n",
    "# if params.load_epoch > 0:\n",
    "#     logger.info(\"Validate network before training\")\n",
    "#     trainer.run_validation(wandb_log=params.wandb_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the network in training mode\n",
    "network.train()\n",
    "\n",
    "# Train the model for the specified number of epochs\n",
    "logger.info(\"Starting training\")\n",
    "trainer.train(\n",
    "    params.train_epochs,\n",
    "    print_every=params.c.getint(\"training\", \"print_every\", fallback=100),\n",
    "    wandb_log=params.wandb_log,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:01:23] [  INFO  ] [  __main__  ] < 1  > -- Starting final validation\n",
      "[18:01:23] [  INFO  ] [utils.training_inference_tools] <1486> -- Validating network at iteration 0...\n",
      "[18:01:23] [ DEBUG  ] [utils.training_inference_tools] <1205> -- Test function: running samples in UNet\n",
      "[18:01:24] [ DEBUG  ] [utils.training_inference_tools] <1233> -- Time to run testing dataset in UNet: 0.97 s\n",
      "[18:01:24] [ DEBUG  ] [utils.training_inference_tools] <1235> -- Test function: computing loss\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1255> -- Processing patch 0/12\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1279> -- Test function: re-organising annotations\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1289> -- Time to re-organise annotations: 0.00 s\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1294> -- Test function: getting processed output (segmentation and instances)\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1311> -- Time to process predictions: 0.11 s\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1331> -- Test function: computing pairwise scores between 1 annotated events and 4 predicted events\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1344> -- Time to compute pairwise scores: 0.00 s\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1351> -- Test function: getting matches summary\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1373> -- Time to get matches summary: 0.00 s\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1255> -- Processing patch 1/12\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1279> -- Test function: re-organising annotations\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1289> -- Time to re-organise annotations: 0.00 s\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1294> -- Test function: getting processed output (segmentation and instances)\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1311> -- Time to process predictions: 0.09 s\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1331> -- Test function: computing pairwise scores between 2 annotated events and 3 predicted events\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1344> -- Time to compute pairwise scores: 0.01 s\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1351> -- Test function: getting matches summary\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1373> -- Time to get matches summary: 0.00 s\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1255> -- Processing patch 2/12\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1279> -- Test function: re-organising annotations\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1289> -- Time to re-organise annotations: 0.00 s\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1294> -- Test function: getting processed output (segmentation and instances)\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1311> -- Time to process predictions: 0.10 s\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1331> -- Test function: computing pairwise scores between 1 annotated events and 2 predicted events\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1344> -- Time to compute pairwise scores: 0.00 s\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1351> -- Test function: getting matches summary\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1373> -- Time to get matches summary: 0.00 s\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1255> -- Processing patch 3/12\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1279> -- Test function: re-organising annotations\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1289> -- Time to re-organise annotations: 0.00 s\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1294> -- Test function: getting processed output (segmentation and instances)\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1311> -- Time to process predictions: 0.10 s\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1331> -- Test function: computing pairwise scores between 1 annotated events and 4 predicted events\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1344> -- Time to compute pairwise scores: 0.00 s\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1351> -- Test function: getting matches summary\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1373> -- Time to get matches summary: 0.00 s\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1255> -- Processing patch 4/12\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1279> -- Test function: re-organising annotations\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1289> -- Time to re-organise annotations: 0.00 s\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1294> -- Test function: getting processed output (segmentation and instances)\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1311> -- Time to process predictions: 0.09 s\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1331> -- Test function: computing pairwise scores between 2 annotated events and 3 predicted events\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1344> -- Time to compute pairwise scores: 0.00 s\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1351> -- Test function: getting matches summary\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1373> -- Time to get matches summary: 0.00 s\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1255> -- Processing patch 5/12\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1279> -- Test function: re-organising annotations\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1289> -- Time to re-organise annotations: 0.00 s\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1294> -- Test function: getting processed output (segmentation and instances)\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1311> -- Time to process predictions: 0.10 s\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1331> -- Test function: computing pairwise scores between 1 annotated events and 3 predicted events\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1344> -- Time to compute pairwise scores: 0.00 s\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1351> -- Test function: getting matches summary\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1373> -- Time to get matches summary: 0.00 s\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1255> -- Processing patch 6/12\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1279> -- Test function: re-organising annotations\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1289> -- Time to re-organise annotations: 0.00 s\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1294> -- Test function: getting processed output (segmentation and instances)\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1311> -- Time to process predictions: 0.08 s\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1331> -- Test function: computing pairwise scores between 1 annotated events and 2 predicted events\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1344> -- Time to compute pairwise scores: 0.00 s\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1351> -- Test function: getting matches summary\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1373> -- Time to get matches summary: 0.00 s\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1255> -- Processing patch 7/12\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1279> -- Test function: re-organising annotations\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1289> -- Time to re-organise annotations: 0.02 s\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1294> -- Test function: getting processed output (segmentation and instances)\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1311> -- Time to process predictions: 0.08 s\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1331> -- Test function: computing pairwise scores between 1 annotated events and 2 predicted events\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1344> -- Time to compute pairwise scores: 0.00 s\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1351> -- Test function: getting matches summary\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1373> -- Time to get matches summary: 0.00 s\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1255> -- Processing patch 8/12\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1279> -- Test function: re-organising annotations\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1289> -- Time to re-organise annotations: 0.02 s\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1294> -- Test function: getting processed output (segmentation and instances)\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1311> -- Time to process predictions: 0.08 s\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1331> -- Test function: computing pairwise scores between 1 annotated events and 7 predicted events\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1344> -- Time to compute pairwise scores: 0.00 s\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1351> -- Test function: getting matches summary\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1373> -- Time to get matches summary: 0.00 s\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1255> -- Processing patch 9/12\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1279> -- Test function: re-organising annotations\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1289> -- Time to re-organise annotations: 0.02 s\n",
      "[18:01:25] [ DEBUG  ] [utils.training_inference_tools] <1294> -- Test function: getting processed output (segmentation and instances)\n",
      "[18:01:26] [ DEBUG  ] [utils.training_inference_tools] <1311> -- Time to process predictions: 0.08 s\n",
      "[18:01:26] [ DEBUG  ] [utils.training_inference_tools] <1331> -- Test function: computing pairwise scores between 1 annotated events and 4 predicted events\n",
      "[18:01:26] [ DEBUG  ] [utils.training_inference_tools] <1344> -- Time to compute pairwise scores: 0.00 s\n",
      "[18:01:26] [ DEBUG  ] [utils.training_inference_tools] <1351> -- Test function: getting matches summary\n",
      "[18:01:26] [ DEBUG  ] [utils.training_inference_tools] <1373> -- Time to get matches summary: 0.00 s\n",
      "[18:01:26] [ DEBUG  ] [utils.training_inference_tools] <1255> -- Processing patch 10/12\n",
      "[18:01:26] [ DEBUG  ] [utils.training_inference_tools] <1279> -- Test function: re-organising annotations\n",
      "[18:01:26] [ DEBUG  ] [utils.training_inference_tools] <1289> -- Time to re-organise annotations: 0.00 s\n",
      "[18:01:26] [ DEBUG  ] [utils.training_inference_tools] <1294> -- Test function: getting processed output (segmentation and instances)\n",
      "[18:01:26] [ DEBUG  ] [utils.training_inference_tools] <1311> -- Time to process predictions: 0.12 s\n",
      "[18:01:26] [ DEBUG  ] [utils.training_inference_tools] <1331> -- Test function: computing pairwise scores between 1 annotated events and 5 predicted events\n",
      "[18:01:26] [ DEBUG  ] [utils.training_inference_tools] <1344> -- Time to compute pairwise scores: 0.00 s\n",
      "[18:01:26] [ DEBUG  ] [utils.training_inference_tools] <1351> -- Test function: getting matches summary\n",
      "[18:01:26] [ DEBUG  ] [utils.training_inference_tools] <1373> -- Time to get matches summary: 0.00 s\n",
      "[18:01:26] [ DEBUG  ] [utils.training_inference_tools] <1255> -- Processing patch 11/12\n",
      "[18:01:26] [ DEBUG  ] [utils.training_inference_tools] <1279> -- Test function: re-organising annotations\n",
      "[18:01:26] [ DEBUG  ] [utils.training_inference_tools] <1289> -- Time to re-organise annotations: 0.02 s\n",
      "[18:01:26] [ DEBUG  ] [utils.training_inference_tools] <1294> -- Test function: getting processed output (segmentation and instances)\n",
      "[18:01:26] [ DEBUG  ] [utils.training_inference_tools] <1311> -- Time to process predictions: 0.08 s\n",
      "[18:01:26] [ DEBUG  ] [utils.training_inference_tools] <1331> -- Test function: computing pairwise scores between 1 annotated events and 1 predicted events\n",
      "[18:01:26] [ DEBUG  ] [utils.training_inference_tools] <1344> -- Time to compute pairwise scores: 0.00 s\n",
      "[18:01:26] [ DEBUG  ] [utils.training_inference_tools] <1351> -- Test function: getting matches summary\n",
      "[18:01:26] [ DEBUG  ] [utils.training_inference_tools] <1373> -- Time to get matches summary: 0.00 s\n",
      "[18:01:26] [ DEBUG  ] [utils.training_inference_tools] <1386> -- Test function: reducing metrics\n",
      "[18:01:26] [ DEBUG  ] [utils.training_inference_tools] <1462> -- Time to reduce metrics: 0.02 s\n",
      "[18:01:26] [  INFO  ] [utils.training_inference_tools] <1589> -- Metrics:\n",
      "[18:01:26] [  INFO  ] [utils.training_inference_tools] <1595> -- \tvalidation_loss: 0.5012\n",
      "[18:01:26] [  INFO  ] [utils.training_inference_tools] <1595> -- \tsparks/precision: 0.35\n",
      "[18:01:26] [  INFO  ] [utils.training_inference_tools] <1595> -- \tsparks/recall: 1\n",
      "[18:01:26] [  INFO  ] [utils.training_inference_tools] <1595> -- \tsparks/correctly_classified: 1\n",
      "[18:01:26] [  INFO  ] [utils.training_inference_tools] <1595> -- \tsparks/detected: 1\n",
      "[18:01:26] [  INFO  ] [utils.training_inference_tools] <1595> -- \tsparks/f1-score: 0.5185\n",
      "[18:01:26] [  INFO  ] [utils.training_inference_tools] <1595> -- \tsparks/labeled: 0.35\n",
      "[18:01:26] [  INFO  ] [utils.training_inference_tools] <1595> -- \ttotal/precision: 0.35\n",
      "[18:01:26] [  INFO  ] [utils.training_inference_tools] <1595> -- \ttotal/recall: 1\n",
      "[18:01:26] [  INFO  ] [utils.training_inference_tools] <1595> -- \ttotal/correctly_classified: 1\n",
      "[18:01:26] [  INFO  ] [utils.training_inference_tools] <1595> -- \ttotal/detected: 1\n",
      "[18:01:26] [  INFO  ] [utils.training_inference_tools] <1595> -- \ttotal/f1-score: 0.5185\n",
      "[18:01:26] [  INFO  ] [utils.training_inference_tools] <1595> -- \ttotal/labeled: 0.35\n",
      "[18:01:26] [  INFO  ] [utils.training_inference_tools] <1595> -- \taverage/precision: 0.35\n",
      "[18:01:26] [  INFO  ] [utils.training_inference_tools] <1595> -- \taverage/recall: 1\n",
      "[18:01:26] [  INFO  ] [utils.training_inference_tools] <1595> -- \taverage/correctly_classified: 1\n",
      "[18:01:26] [  INFO  ] [utils.training_inference_tools] <1595> -- \taverage/detected: 1\n",
      "[18:01:26] [  INFO  ] [utils.training_inference_tools] <1595> -- \taverage/f1-score: 0.5185\n",
      "[18:01:26] [  INFO  ] [utils.training_inference_tools] <1595> -- \taverage/labeled: 0.35\n",
      "[18:01:26] [  INFO  ] [utils.training_inference_tools] <1595> -- \tsegmentation/sparks_IoU: 0.03527\n",
      "[18:01:26] [  INFO  ] [utils.training_inference_tools] <1595> -- \tsegmentation/average_IoU: 0.03527\n",
      "[18:01:26] [  INFO  ] [utils.training_inference_tools] <1593> -- \tsegmentation_confusion_matrix:\n",
      "[[ 36652 343773]\n",
      " [     0  12568]]\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Starting final validation\")\n",
    "# Run the final validation/testing procedure\n",
    "trainer.run_validation(wandb_log=params.wandb_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the summary writer\n",
    "summary_writer.close()\n",
    "\n",
    "# Close the wandb run\n",
    "if params.wandb_log:\n",
    "    wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sparks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
