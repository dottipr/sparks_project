{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "628be7f8-32a6-4b00-8d25-b0113b344742",
   "metadata": {},
   "source": [
    "27/09/2022\n",
    "\n",
    "# Add colored segmentation on video\n",
    "\n",
    "Use this script to add colored annotations and predictions on given dataset movies.\n",
    "\n",
    "Used to generate examples for midterm exams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ea84405-7f9b-417b-b8b1-a57fe34f6bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "662b9d29-20c1-46fd-ae81-30c1fff4ffe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import imageio\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "from PIL import Image\n",
    "from scipy import spatial, optimize\n",
    "\n",
    "from metrics_tools import correspondences_precision_recall, get_sparks_locations_from_mask, process_spark_prediction\n",
    "from preds_processing_tools import paste_segmentation_on_video, add_colored_annotations_to_video, l2_dist, ball, color_ball"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1b52ff-59e0-4cd6-a817-0ea04caf4a9f",
   "metadata": {},
   "source": [
    "## Load movies, annotations & training predictions\n",
    "\n",
    "Predictions need to be first saved running `load_trainings_predict.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9645b82c-010d-4b6b-ba40-959ff433011c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_tools import load_annotations_ids,load_movies_ids,load_predictions_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a1f9439-f9b4-47a8-b2fd-2936095ed201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming these are movie IDs whose predictions are available...\n",
    "movie_ids_train = [\"01\",\"02\",\"03\",\"04\",\"06\",\"07\",\"08\",\"09\",\n",
    "                            \"11\",\"12\",\"13\",\"14\",\"16\",\"17\",\"18\",\"19\",\n",
    "                            \"21\",\"22\",\"23\",\"24\",\"27\",\"28\",\"29\",\n",
    "                            \"30\",\"33\",\"35\",\"36\",\"38\",\"39\",\n",
    "                            \"41\",\"42\",\"43\",\"44\",\"46\"]\n",
    "\n",
    "movie_ids_test  = [\"05\",\"10\",\"15\",\"20\",\"25\",\"32\",\"34\",\"40\",\"45\"]\n",
    "\n",
    "movie_ids = movie_ids_train+movie_ids_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67be34ef-3900-450e-b298-34fcb6650c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_name = 'TEMP_new_annotated_peaks_physio'\n",
    "epoch = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af2a2c48-5b36-4f81-9d7b-71e19ccc63a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(\"..\",\"data\",\"sparks_dataset\")\n",
    "\n",
    "preds_dir = os.path.join(\"trainings_validation\", \n",
    "                        training_name)\n",
    "\n",
    "out_dir = os.path.join(\"trainings_validation\", \n",
    "                        training_name, \n",
    "                        \"colored_segmentation\")\n",
    "os.makedirs(out_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a2b0a5a-9322-4b85-b9f2-8fff385f3e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n",
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n",
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n",
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n"
     ]
    }
   ],
   "source": [
    "### Load movies\n",
    "xs = load_movies_ids(data_folder=data_dir,\n",
    "                     ids=movie_ids,\n",
    "                     names_available = True,\n",
    "                     movie_names = 'video')\n",
    "\n",
    "### Load annotations\n",
    "ys = load_annotations_ids(data_folder=data_dir,\n",
    "                          ids=movie_ids,\n",
    "                          mask_names=\"class_label\")\n",
    "\n",
    "### Load annotated event instances\n",
    "annotated_events = load_annotations_ids(data_folder=data_dir,\n",
    "                                        ids=movie_ids,\n",
    "                                        mask_names=\"event_label\"\n",
    "                                        )\n",
    "\n",
    "### Load predictions\n",
    "# Predictions created from selected model\n",
    "sparks_filenames = {movie_id: os.path.join(preds_dir, training_name+\"_\"+str(epoch)+\"_\"+movie_id+\"_sparks.tif\") for movie_id in movie_ids}\n",
    "puffs_filenames = {movie_id: os.path.join(preds_dir, training_name+\"_\"+str(epoch)+\"_\"+movie_id+\"_puffs.tif\") for movie_id in movie_ids}\n",
    "waves_filenames = {movie_id: os.path.join(preds_dir, training_name+\"_\"+str(epoch)+\"_\"+movie_id+\"_waves.tif\") for movie_id in movie_ids}\n",
    "\n",
    "sparks = {movie_id: np.asarray(imageio.volread(f)) for movie_id, f in sparks_filenames.items()}\n",
    "puffs = {movie_id: np.asarray(imageio.volread(f)) for movie_id, f in puffs_filenames.items()}\n",
    "waves = {movie_id: np.asarray(imageio.volread(f)) for movie_id, f in waves_filenames.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4fcb980f-a978-4f95-b123-62e2eb37a8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# physiological params\n",
    "PIXEL_SIZE = 0.2 # 1 pixel = 0.2 um x 0.2 um\n",
    "global MIN_DIST_XY\n",
    "MIN_DIST_XY = round(1.8 / PIXEL_SIZE) # min distance in space between sparks\n",
    "TIME_FRAME = 6.8 # 1 frame = 6.8 ms\n",
    "global MIN_DIST_T\n",
    "MIN_DIST_T = round(20 / TIME_FRAME) # min distance in time between sparks\n",
    "\n",
    "# parameters\n",
    "ignore_frames = 6\n",
    "\n",
    "t_detection_sparks = 0.65\n",
    "min_radius_sparks = 1\n",
    "\n",
    "transparency = 45\n",
    "\n",
    "sigma = 1.5"
   ]
  },
  {
   "cell_type": "raw",
   "id": "61cc089e-a236-4ca1-b881-ad29be3660e9",
   "metadata": {},
   "source": [
    "# visualisation params\n",
    "color_dict = {'sparks': [178, 255, 102],\n",
    "              'puffs': [255, 102, 102],\n",
    "              'waves': [178, 102, 255],\n",
    "              'ignore': [224, 224, 224]\n",
    "             }\n",
    "\n",
    "transparency = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5dd84d8d-0327-440c-addf-2e92d1100626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset params\n",
    "classes = ['sparks', 'puffs', 'waves', 'ignore']\n",
    "classes_nb = {'sparks': 1,\n",
    "              'puffs': 3,\n",
    "              'waves': 2,\n",
    "              'ignore': 4\n",
    "             }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714154ff-4c30-40e0-baf2-0fcc7fb53603",
   "metadata": {},
   "source": [
    "## Get predictions segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8633f724-3adf-49ec-b915-7e2043d90902",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preds_processing_tools import get_argmax_segmentation_otsu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa177d12-a3f2-486f-b50f-7b42ecb594fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4790e384-b9fe-456c-a7b1-3a644436716b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for movie_id in movie_ids:\n",
    "    raw_preds = {'sparks': sparks[movie_id],\n",
    "                 'puffs': puffs[movie_id],\n",
    "                 'waves': waves[movie_id],\n",
    "                 'background': 1-sparks[movie_id]-puffs[movie_id]-waves[movie_id]\n",
    "                }\n",
    "    preds[movie_id] = get_argmax_segmentation_otsu(preds=raw_preds,\n",
    "                                                   get_classes=False,\n",
    "                                                   debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f20c2e-efbf-43c9-81e5-22ada5f2e91d",
   "metadata": {},
   "source": [
    "## Add segmentation to original movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "102cb192-86e5-46bb-9b06-cd9bb3a608ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preds_processing_tools import add_colored_segmentation_to_video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea7bf32-2ef0-4ac4-94ab-3ce404fa8ec6",
   "metadata": {},
   "source": [
    "### add transparent segmentation on original movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a9a98261-adc6-4479-9572-c054dda92d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualisation params\n",
    "color_dict = {'sparks': [178, 255, 102],\n",
    "              'puffs': [255, 102, 102],\n",
    "              'waves': [178, 102, 255],\n",
    "              'ignore': [224, 224, 224]\n",
    "             }\n",
    "\n",
    "transparency = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f065c58d-e182-45ab-8e64-3871cf294d9e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video 01 ...\n",
      "Processing video 02 ...\n",
      "Processing video 03 ...\n",
      "Processing video 04 ...\n",
      "Processing video 06 ...\n",
      "Processing video 07 ...\n",
      "Processing video 08 ...\n",
      "Processing video 09 ...\n",
      "Processing video 11 ...\n",
      "Processing video 12 ...\n",
      "Processing video 13 ...\n",
      "Processing video 14 ...\n",
      "Processing video 16 ...\n",
      "Processing video 17 ...\n",
      "Processing video 18 ...\n",
      "Processing video 19 ...\n",
      "Processing video 21 ...\n",
      "Processing video 22 ...\n",
      "Processing video 23 ...\n",
      "Processing video 24 ...\n",
      "Processing video 27 ...\n",
      "Processing video 28 ...\n",
      "Processing video 29 ...\n",
      "Processing video 30 ...\n",
      "Processing video 33 ...\n",
      "Processing video 35 ...\n",
      "Processing video 36 ...\n",
      "Processing video 38 ...\n",
      "Processing video 39 ...\n",
      "Processing video 41 ...\n",
      "Processing video 42 ...\n",
      "Processing video 43 ...\n",
      "Processing video 44 ...\n",
      "Processing video 46 ...\n",
      "Processing video 05 ...\n",
      "Processing video 10 ...\n",
      "Processing video 15 ...\n",
      "Processing video 20 ...\n",
      "Processing video 25 ...\n",
      "Processing video 32 ...\n",
      "Processing video 34 ...\n",
      "Processing video 40 ...\n",
      "Processing video 45 ...\n"
     ]
    }
   ],
   "source": [
    "for movie_id in movie_ids:\n",
    "    print(\"Processing video\", movie_id, \"...\")\n",
    "    \n",
    "    # normalize sample movie\n",
    "    original_movie = 255*(xs[movie_id]/xs[movie_id].max())\n",
    "    \n",
    "    colored_preds_video = np.copy(original_movie)\n",
    "    colored_labels_video = np.copy(original_movie)\n",
    "\n",
    "    # convert video to RGB\n",
    "    original_movie_rgb = [Image.fromarray(frame).convert('RGB') \n",
    "                          for frame in original_movie]\n",
    "    colored_preds_video = [Image.fromarray(frame).convert('RGB') \n",
    "                           for frame in colored_preds_video]\n",
    "    colored_labels_video = [Image.fromarray(frame).convert('RGB') \n",
    "                            for frame in colored_labels_video]\n",
    "\n",
    "\n",
    "    for event_class in classes:\n",
    "        if classes_nb[event_class] in preds[movie_id]:\n",
    "            binary_preds = preds[movie_id] == classes_nb[event_class]\n",
    "            colored_preds_video = add_colored_segmentation_to_video(segmentation=binary_preds,\n",
    "                                                                    video=colored_preds_video,\n",
    "                                                                    color=color_dict[event_class],\n",
    "                                                                    transparency=transparency)\n",
    "\n",
    "        if classes_nb[event_class] in ys[movie_id]:\n",
    "            binary_labels = ys[movie_id] == classes_nb[event_class]\n",
    "            colored_labels_video = add_colored_segmentation_to_video(segmentation=binary_labels,\n",
    "                                                                     video=colored_labels_video,\n",
    "                                                                     color=color_dict[event_class],\n",
    "                                                                     transparency=transparency)\n",
    "\n",
    "\n",
    "    # convert to numpy array and remove first and last frames\n",
    "    original_movie_rgb = [np.array(frame) \n",
    "                          for frame in original_movie_rgb[ignore_frames:-ignore_frames]]\n",
    "    colored_preds_video = [np.array(frame) \n",
    "                           for frame in colored_preds_video[ignore_frames:-ignore_frames]]\n",
    "    colored_labels_video = [np.array(frame) \n",
    "                            for frame in colored_labels_video[ignore_frames:-ignore_frames]]\n",
    "    \n",
    "    \n",
    "    imageio.volwrite(os.path.join(out_dir, \n",
    "                                  training_name+\"_\"+str(epoch)+\"_\"+movie_id+\"_original_movie.tif\"),\n",
    "                     original_movie_rgb)\n",
    "\n",
    "    imageio.volwrite(os.path.join(out_dir, \n",
    "                                  training_name+\"_\"+str(epoch)+\"_\"+movie_id+\"_colored_labels.tif\"),\n",
    "                     colored_labels_video)\n",
    "\n",
    "    imageio.volwrite(os.path.join(out_dir, \n",
    "                                  training_name+\"_\"+str(epoch)+\"_\"+movie_id+\"_colored_preds.tif\"),\n",
    "                     colored_preds_video)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac3358c-adc0-426a-bbb1-abacbd39d442",
   "metadata": {},
   "source": [
    "### create masks with colored segmentation and white background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0664a394-38e8-4fd9-a2d0-616ec464b4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualisation params\n",
    "color_dict = {'sparks': [0, 255, 0], # green\n",
    "              'puffs': [220, 20, 60], # red\n",
    "              'waves': [138, 43, 226], # purple\n",
    "              'ignore': [80,80,80] # gray\n",
    "             }\n",
    "\n",
    "transparency = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "86fdcf1e-ac92-4bc7-b091-043d58962ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video 01 ...\n",
      "Processing video 02 ...\n",
      "Processing video 03 ...\n",
      "Processing video 04 ...\n",
      "Processing video 06 ...\n",
      "Processing video 07 ...\n",
      "Processing video 08 ...\n",
      "Processing video 09 ...\n",
      "Processing video 11 ...\n",
      "Processing video 12 ...\n",
      "Processing video 13 ...\n",
      "Processing video 14 ...\n",
      "Processing video 16 ...\n",
      "Processing video 17 ...\n",
      "Processing video 18 ...\n",
      "Processing video 19 ...\n",
      "Processing video 21 ...\n",
      "Processing video 22 ...\n",
      "Processing video 23 ...\n",
      "Processing video 24 ...\n",
      "Processing video 27 ...\n",
      "Processing video 28 ...\n",
      "Processing video 29 ...\n",
      "Processing video 30 ...\n",
      "Processing video 33 ...\n",
      "Processing video 35 ...\n",
      "Processing video 36 ...\n",
      "Processing video 38 ...\n",
      "Processing video 39 ...\n",
      "Processing video 41 ...\n",
      "Processing video 42 ...\n",
      "Processing video 43 ...\n",
      "Processing video 44 ...\n",
      "Processing video 46 ...\n",
      "Processing video 05 ...\n",
      "Processing video 10 ...\n",
      "Processing video 15 ...\n",
      "Processing video 20 ...\n",
      "Processing video 25 ...\n",
      "Processing video 32 ...\n",
      "Processing video 34 ...\n",
      "Processing video 40 ...\n",
      "Processing video 45 ...\n"
     ]
    }
   ],
   "source": [
    "for movie_id in movie_ids:\n",
    "    print(\"Processing video\", movie_id, \"...\")\n",
    "    \n",
    "    # normalize sample movie\n",
    "    original_movie = 255*(xs[movie_id]/xs[movie_id].max())\n",
    "    \n",
    "    # THIS IS DIFFERENT\n",
    "    colored_preds_video = 255*np.ones_like(original_movie)\n",
    "    colored_labels_video = 255*np.ones_like(original_movie)\n",
    "\n",
    "    # convert video to RGB\n",
    "    original_movie_rgb = [Image.fromarray(frame).convert('RGB') \n",
    "                          for frame in original_movie]\n",
    "    colored_preds_video = [Image.fromarray(frame).convert('RGB') \n",
    "                           for frame in colored_preds_video]\n",
    "    colored_labels_video = [Image.fromarray(frame).convert('RGB') \n",
    "                            for frame in colored_labels_video]\n",
    "\n",
    "\n",
    "    for event_class in classes:\n",
    "        if classes_nb[event_class] in preds[movie_id]:\n",
    "            binary_preds = preds[movie_id] == classes_nb[event_class]\n",
    "            colored_preds_video = add_colored_segmentation_to_video(segmentation=binary_preds,\n",
    "                                                                    video=colored_preds_video,\n",
    "                                                                    color=color_dict[event_class],\n",
    "                                                                    transparency=transparency)\n",
    "\n",
    "        if classes_nb[event_class] in ys[movie_id]:\n",
    "            binary_labels = ys[movie_id] == classes_nb[event_class]\n",
    "            colored_labels_video = add_colored_segmentation_to_video(segmentation=binary_labels,\n",
    "                                                                     video=colored_labels_video,\n",
    "                                                                     color=color_dict[event_class],\n",
    "                                                                     transparency=transparency)\n",
    "\n",
    "\n",
    "    # convert to numpy array and remove first and last frames\n",
    "    original_movie_rgb = [np.array(frame) \n",
    "                          for frame in original_movie_rgb[ignore_frames:-ignore_frames]]\n",
    "    colored_preds_video = [np.array(frame) \n",
    "                           for frame in colored_preds_video[ignore_frames:-ignore_frames]]\n",
    "    colored_labels_video = [np.array(frame) \n",
    "                            for frame in colored_labels_video[ignore_frames:-ignore_frames]]\n",
    "    \n",
    "    \n",
    "    imageio.volwrite(os.path.join(out_dir, \n",
    "                                  training_name+\"_\"+str(epoch)+\"_\"+movie_id+\"_original_movie.tif\"),\n",
    "                     original_movie_rgb)\n",
    "\n",
    "    imageio.volwrite(os.path.join(out_dir, \n",
    "                                  training_name+\"_\"+str(epoch)+\"_\"+movie_id+\"_colored_labels_white_background.tif\"),\n",
    "                     colored_labels_video)\n",
    "\n",
    "    imageio.volwrite(os.path.join(out_dir, \n",
    "                                  training_name+\"_\"+str(epoch)+\"_\"+movie_id+\"_colored_preds_white_background.tif\"),\n",
    "                     colored_preds_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2a4ece-fc7b-4236-a50f-d837870e1b0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
