{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "628be7f8-32a6-4b00-8d25-b0113b344742",
   "metadata": {},
   "source": [
    "27/09/2022\n",
    "\n",
    "# Add colored segmentation on video\n",
    "\n",
    "Use this script to add colored annotations and predictions on given dataset movies.\n",
    "\n",
    "Used to generate examples for midterm exams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ea84405-7f9b-417b-b8b1-a57fe34f6bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "790cf70f-20bc-4de9-808c-bf3963de199d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import imageio\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from data_processing_tools import get_processed_result\n",
    "from in_out_tools import (load_annotations_ids,\n",
    "                          load_movies_ids,\n",
    "                          write_colored_events_videos_on_disk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e565ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "############################# configure logger #############################\n",
    "\n",
    "# set verbosity\n",
    "verbosity = 3 \n",
    "\n",
    "level_map = {\n",
    "    3: logging.DEBUG,\n",
    "    2: logging.INFO,\n",
    "    1: logging.WARNING,\n",
    "    0: logging.ERROR,\n",
    "}\n",
    "log_level = level_map[verbosity]\n",
    "log_handlers = (logging.StreamHandler(sys.stdout),)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=log_level,\n",
    "    format=\"[{asctime}] [{levelname:^8s}] [{name:^12s}] <{lineno:^4d}> -- {message:s}\",\n",
    "    style=\"{\",\n",
    "    datefmt=\"%H:%M:%S\",\n",
    "    handlers=log_handlers,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1b52ff-59e0-4cd6-a817-0ea04caf4a9f",
   "metadata": {},
   "source": [
    "## Load movies, annotations & training predictions\n",
    "\n",
    "Predictions need to be first saved running `load_trainings_predict.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a1f9439-f9b4-47a8-b2fd-2936095ed201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming these are movie IDs whose predictions are available...\n",
    "movie_ids_train = [\"01\",\"02\",\"03\",\"04\",\"06\",\"07\",\"08\",\"09\",\n",
    "                            \"11\",\"12\",\"13\",\"14\",\"16\",\"17\",\"18\",\"19\",\n",
    "                            \"21\",\"22\",\"23\",\"24\",\"27\",\"28\",\"29\",\n",
    "                            \"30\",\"33\",\"35\",\"36\",\"38\",\"39\",\n",
    "                            \"41\",\"42\",\"43\",\"44\",\"46\"]\n",
    "\n",
    "movie_ids_test  = [\"05\",\"10\",\"15\",\"20\",\"25\",\"32\",\"34\",\"40\",\"45\"]\n",
    "\n",
    "#movie_ids = movie_ids_train+movie_ids_test\n",
    "movie_ids = movie_ids_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67be34ef-3900-450e-b298-34fcb6650c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_name = 'final_model_log_softmax'\n",
    "epoch = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af2a2c48-5b36-4f81-9d7b-71e19ccc63a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(\"..\",\"data\",\"sparks_dataset\")\n",
    "\n",
    "preds_dir = os.path.join(\"trainings_validation\",\n",
    "                         training_name)\n",
    "\n",
    "out_dir = os.path.join(\"trainings_validation\",\n",
    "                       training_name,\n",
    "                       \"colored_segmentation\")\n",
    "os.makedirs(out_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a2b0a5a-9322-4b85-b9f2-8fff385f3e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:17:34] [WARNING ] [tifffile.tifffile] <16549> -- TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n",
      "[14:17:34] [WARNING ] [tifffile.tifffile] <16549> -- TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n"
     ]
    }
   ],
   "source": [
    "### Load movies\n",
    "xs = load_movies_ids(data_folder=data_dir,\n",
    "                     ids=movie_ids,\n",
    "                     names_available = True,\n",
    "                     movie_names = 'video')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "197ffd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Load annotations -> using current annotations in dataset directory\n",
    "ys = load_annotations_ids(data_folder=data_dir,\n",
    "                          ids=movie_ids,\n",
    "                          mask_names=\"class_label\")\n",
    "\n",
    "### Load annotated event instances\n",
    "annotated_events = load_annotations_ids(data_folder=data_dir,\n",
    "                                        ids=movie_ids,\n",
    "                                        mask_names=\"event_label\"\n",
    "                                        )\n",
    "\n",
    "### Load predictions\n",
    "# Predictions created from selected model\n",
    "sparks_filenames = {movie_id: os.path.join(preds_dir, training_name+\"_\"+str(epoch)+\"_\"+movie_id+\"_sparks.tif\") for movie_id in movie_ids}\n",
    "puffs_filenames = {movie_id: os.path.join(preds_dir, training_name+\"_\"+str(epoch)+\"_\"+movie_id+\"_puffs.tif\") for movie_id in movie_ids}\n",
    "waves_filenames = {movie_id: os.path.join(preds_dir, training_name+\"_\"+str(epoch)+\"_\"+movie_id+\"_waves.tif\") for movie_id in movie_ids}\n",
    "\n",
    "sparks = {movie_id: np.asarray(imageio.volread(f)) for movie_id, f in sparks_filenames.items()}\n",
    "puffs = {movie_id: np.asarray(imageio.volread(f)) for movie_id, f in puffs_filenames.items()}\n",
    "waves = {movie_id: np.asarray(imageio.volread(f)) for movie_id, f in waves_filenames.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714154ff-4c30-40e0-baf2-0fcc7fb53603",
   "metadata": {},
   "source": [
    "## Get predictions segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53161d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing_tools import sparks_connectivity_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54f895c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for raw prediction processing\n",
    "\n",
    "sigma = 3\n",
    "\n",
    "# spark instances detection parameters\n",
    "pixel_size = 0.2  # 1 pixel = 0.2 um x 0.2 um\n",
    "min_dist_xy = round(1.8 / pixel_size) # min distance in space\n",
    "time_frame = 6.8  # 1 frame = 6.8 ms\n",
    "min_dist_t = round(20 / time_frame)  # min distance in time\n",
    "\n",
    "min_dist_xy = min_dist_xy\n",
    "min_dist_t = min_dist_t\n",
    "conn_mask = sparks_connectivity_mask(min_dist_xy=min_dist_xy,\n",
    "                                     min_dist_t=min_dist_t)\n",
    "\n",
    "# TODO: use better parameters !!!\n",
    "pixel_size = 0.2\n",
    "spark_min_width = 3\n",
    "spark_min_t = 3\n",
    "puff_min_t = 5\n",
    "wave_min_width = round(15 / pixel_size)\n",
    "\n",
    "# connectivity for event instances detection\n",
    "connectivity = 26\n",
    "\n",
    "# maximal gap between two predicted puffs or waves that belong together\n",
    "max_gap = 2  # i.e., 2 empty frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa177d12-a3f2-486f-b50f-7b42ecb594fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_instances = {}\n",
    "preds_segmentation = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adf699b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing_tools import dict_to_int_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4790e384-b9fe-456c-a7b1-3a644436716b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:17:50] [ DEBUG  ] [data_processing_tools] <448 > -- Events detection threshold: 0.498\n",
      "[14:17:55] [ DEBUG  ] [data_processing_tools] <514 > -- Number of sparks detected by nonmaxima suppression: 139\n",
      "[14:18:09] [ DEBUG  ] [data_processing_tools] <875 > -- Time for removing small events: 11.51 s\n",
      "[14:18:09] [ DEBUG  ] [data_processing_tools] <448 > -- Events detection threshold: 0.498\n",
      "[14:18:14] [ DEBUG  ] [data_processing_tools] <514 > -- Number of sparks detected by nonmaxima suppression: 26\n",
      "[14:18:19] [ DEBUG  ] [data_processing_tools] <875 > -- Time for removing small events: 3.80 s\n",
      "[14:18:19] [ DEBUG  ] [data_processing_tools] <448 > -- Events detection threshold: 0.498\n",
      "[14:18:25] [ DEBUG  ] [data_processing_tools] <514 > -- Number of sparks detected by nonmaxima suppression: 30\n",
      "[14:18:29] [ DEBUG  ] [data_processing_tools] <875 > -- Time for removing small events: 3.56 s\n",
      "[14:18:30] [ DEBUG  ] [data_processing_tools] <448 > -- Events detection threshold: 0.498\n",
      "[14:18:35] [ DEBUG  ] [data_processing_tools] <514 > -- Number of sparks detected by nonmaxima suppression: 99\n",
      "[14:18:43] [ DEBUG  ] [data_processing_tools] <875 > -- Time for removing small events: 6.82 s\n",
      "[14:18:44] [ DEBUG  ] [data_processing_tools] <448 > -- Events detection threshold: 0.494\n",
      "[14:18:54] [ DEBUG  ] [data_processing_tools] <514 > -- Number of sparks detected by nonmaxima suppression: 67\n",
      "[14:19:06] [ DEBUG  ] [data_processing_tools] <875 > -- Time for removing small events: 8.47 s\n",
      "[14:19:06] [ DEBUG  ] [data_processing_tools] <448 > -- Events detection threshold: 0.498\n",
      "[14:19:16] [ DEBUG  ] [data_processing_tools] <514 > -- Number of sparks detected by nonmaxima suppression: 10\n",
      "[14:19:23] [ DEBUG  ] [data_processing_tools] <875 > -- Time for removing small events: 4.65 s\n",
      "[14:19:24] [ DEBUG  ] [data_processing_tools] <448 > -- Events detection threshold: 0.498\n",
      "[14:19:33] [ DEBUG  ] [data_processing_tools] <514 > -- Number of sparks detected by nonmaxima suppression: 85\n",
      "[14:19:51] [ DEBUG  ] [data_processing_tools] <875 > -- Time for removing small events: 15.80 s\n",
      "[14:19:52] [ DEBUG  ] [data_processing_tools] <448 > -- Events detection threshold: 0.498\n",
      "[14:20:02] [ DEBUG  ] [data_processing_tools] <514 > -- Number of sparks detected by nonmaxima suppression: 47\n",
      "[14:20:15] [ DEBUG  ] [data_processing_tools] <875 > -- Time for removing small events: 10.00 s\n",
      "[14:20:15] [ DEBUG  ] [data_processing_tools] <448 > -- Events detection threshold: 0.498\n",
      "[14:20:26] [ DEBUG  ] [data_processing_tools] <514 > -- Number of sparks detected by nonmaxima suppression: 15\n",
      "[14:20:36] [ DEBUG  ] [data_processing_tools] <875 > -- Time for removing small events: 7.12 s\n"
     ]
    }
   ],
   "source": [
    "for movie_id in movie_ids:\n",
    "    preds_instances[movie_id], preds_segmentation[movie_id], _ = get_processed_result(\n",
    "            sparks=sparks[movie_id],\n",
    "            puffs=puffs[movie_id],\n",
    "            waves=waves[movie_id],\n",
    "            xs=xs[movie_id],\n",
    "            conn_mask=conn_mask,\n",
    "            connectivity=connectivity,\n",
    "            max_gap=max_gap,\n",
    "            sigma=sigma,\n",
    "            wave_min_width=wave_min_width,\n",
    "            puff_min_t=puff_min_t,\n",
    "            spark_min_t=spark_min_t,\n",
    "            spark_min_width=spark_min_width,\n",
    "            training_mode=False,\n",
    "            debug=True\n",
    "    )\n",
    "    \n",
    "    # convert dict of prends to int masks\n",
    "    preds_segmentation[movie_id] = dict_to_int_mask(preds_segmentation[movie_id])\n",
    "    preds_instances[movie_id] = sum(preds_instances[movie_id].values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f20c2e-efbf-43c9-81e5-22ada5f2e91d",
   "metadata": {},
   "source": [
    "## Add segmentation to original movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6e8ec1-08ef-4c8d-92f5-d06768db09dd",
   "metadata": {},
   "source": [
    "### save original movie in RGB without ignored frames for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64251bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "ignore_frames = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "287c9613-09d1-4fa7-8af7-c0902cdedb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video 01 ...\n",
      "Processing video 02 ...\n",
      "Processing video 03 ...\n",
      "Processing video 04 ...\n",
      "Processing video 06 ...\n",
      "Processing video 07 ...\n",
      "Processing video 08 ...\n",
      "Processing video 09 ...\n",
      "Processing video 11 ...\n",
      "Processing video 12 ...\n",
      "Processing video 13 ...\n",
      "Processing video 14 ...\n",
      "Processing video 16 ...\n",
      "Processing video 17 ...\n",
      "Processing video 18 ...\n",
      "Processing video 19 ...\n",
      "Processing video 21 ...\n",
      "Processing video 22 ...\n",
      "Processing video 23 ...\n",
      "Processing video 24 ...\n",
      "Processing video 27 ...\n",
      "Processing video 28 ...\n",
      "Processing video 29 ...\n",
      "Processing video 30 ...\n",
      "Processing video 33 ...\n",
      "Processing video 35 ...\n",
      "Processing video 36 ...\n",
      "Processing video 38 ...\n",
      "Processing video 39 ...\n",
      "Processing video 41 ...\n",
      "Processing video 42 ...\n",
      "Processing video 43 ...\n",
      "Processing video 44 ...\n",
      "Processing video 46 ...\n",
      "Processing video 05 ...\n",
      "Processing video 10 ...\n",
      "Processing video 15 ...\n",
      "Processing video 20 ...\n",
      "Processing video 25 ...\n",
      "Processing video 32 ...\n",
      "Processing video 34 ...\n",
      "Processing video 40 ...\n",
      "Processing video 45 ...\n"
     ]
    }
   ],
   "source": [
    "for movie_id in movie_ids:\n",
    "    print(\"Processing video\", movie_id, \"...\")\n",
    "    \n",
    "    # convert movie to rgb and save on disk\n",
    "    movie_rgb = np.copy(xs[movie_id])\n",
    "    movie_rgb = 255*(movie_rgb/movie_rgb.max())\n",
    "    movie_rgb = [Image.fromarray(frame).convert('RGB') for frame in movie_rgb]\n",
    "    if ignore_frames > 0:\n",
    "        movie_rgb = [np.array(frame) \n",
    "                     for frame in movie_rgb[ignore_frames:-ignore_frames]]\n",
    "    else:\n",
    "        movie_rgb = [np.array(frame) for frame in movie_rgb]\n",
    "    \n",
    "    imageio.volwrite(os.path.join(out_dir, movie_id+\"_original_movie.tif\"),\n",
    "                     movie_rgb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eea7bf32-2ef0-4ac4-94ab-3ce404fa8ec6",
   "metadata": {},
   "source": [
    "### add transparent segmentation of classes on original movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c0e29f4-bc3d-4703-b6ac-08b616e68d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "ignore_frames = 6\n",
    "transparency = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f065c58d-e182-45ab-8e64-3871cf294d9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video 05 ...\n",
      "Processing video 10 ...\n",
      "Processing video 15 ...\n",
      "Processing video 20 ...\n",
      "Processing video 25 ...\n",
      "Processing video 32 ...\n",
      "Processing video 34 ...\n",
      "Processing video 40 ...\n",
      "Processing video 45 ...\n"
     ]
    }
   ],
   "source": [
    "for movie_id in movie_ids:\n",
    "    print(\"Processing video\", movie_id, \"...\")\n",
    "    \n",
    "    base_fn = training_name+\"_\"+str(epoch)+\"_\"+movie_id\n",
    "\n",
    "    write_colored_events_videos_on_disk(movie=xs[movie_id],\n",
    "                                        events_mask=preds_segmentation[movie_id],\n",
    "                                        out_dir=out_dir,\n",
    "                                        movie_fn=base_fn+\"_colored_classes_preds\",\n",
    "                                        transparency=transparency,\n",
    "                                        ignore_frames=ignore_frames,\n",
    "                                        white_bg=False,\n",
    "                                        instances=False)\n",
    "    \n",
    "    write_colored_events_videos_on_disk(movie=xs[movie_id],\n",
    "                                        events_mask=ys[movie_id],\n",
    "                                        out_dir=out_dir,\n",
    "                                        movie_fn=base_fn+\"_colored_classes_labels\",\n",
    "                                        transparency=transparency,\n",
    "                                        ignore_frames=ignore_frames,\n",
    "                                        white_bg=False,\n",
    "                                        instances=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4c40639",
   "metadata": {},
   "source": [
    "### add transparent segmentation of instances of events on movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dea86ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "ignore_frames = 6\n",
    "transparency = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2094ca9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video 05 ...\n",
      "Processing video 10 ...\n",
      "Processing video 15 ...\n",
      "Processing video 20 ...\n",
      "Processing video 25 ...\n",
      "Processing video 32 ...\n",
      "Processing video 34 ...\n",
      "Processing video 40 ...\n",
      "Processing video 45 ...\n"
     ]
    }
   ],
   "source": [
    "for movie_id in movie_ids:\n",
    "    print(\"Processing video\", movie_id, \"...\")\n",
    "    \n",
    "    base_fn = training_name+\"_\"+str(epoch)+\"_\"+movie_id\n",
    "\n",
    "    # write predictions on disk\n",
    "    write_colored_events_videos_on_disk(movie=xs[movie_id],\n",
    "                                    events_mask=preds_instances[movie_id],\n",
    "                                    out_dir=out_dir,\n",
    "                                    movie_fn=base_fn+\"_colored_instances_preds\",\n",
    "                                    transparency=transparency,\n",
    "                                    ignore_frames=ignore_frames,\n",
    "                                    white_bg=False,\n",
    "                                    instances=True)\n",
    "    # write labels on disk\n",
    "    write_colored_events_videos_on_disk(movie=xs[movie_id],\n",
    "                                    events_mask=annotated_events[movie_id],\n",
    "                                    out_dir=out_dir,\n",
    "                                    movie_fn=base_fn+\"_colored_instances_labels\",\n",
    "                                    transparency=transparency,\n",
    "                                    ignore_frames=ignore_frames,\n",
    "                                    white_bg=False,\n",
    "                                    instances=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d88bb8db",
   "metadata": {},
   "source": [
    "### create masks where annotations are denoted by border and preds are transparent on original movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b144e16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "ignore_frames = 6\n",
    "transparency = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17a90a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video 05 ...\n",
      "Processing video 10 ...\n",
      "Processing video 15 ...\n",
      "Processing video 20 ...\n",
      "Processing video 25 ...\n",
      "Processing video 32 ...\n",
      "Processing video 34 ...\n",
      "Processing video 40 ...\n",
      "Processing video 45 ...\n"
     ]
    }
   ],
   "source": [
    "for movie_id in movie_ids:\n",
    "    print(\"Processing video\", movie_id, \"...\")\n",
    "    \n",
    "    base_fn = training_name+\"_\"+str(epoch)+\"_\"+movie_id\n",
    "\n",
    "    write_colored_events_videos_on_disk(movie=xs[movie_id],\n",
    "                                        events_mask=preds_segmentation[movie_id],\n",
    "                                        out_dir=out_dir,\n",
    "                                        movie_fn=base_fn+\"_colored_preds_and_labels\",\n",
    "                                        transparency=transparency,\n",
    "                                        ignore_frames=ignore_frames,\n",
    "                                        white_bg=False,\n",
    "                                        instances=False,\n",
    "                                        label_contours=True,\n",
    "                                        label_mask=ys[movie_id])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eac3358c-adc0-426a-bbb1-abacbd39d442",
   "metadata": {},
   "source": [
    "### create masks with colored segmentation and white background (not updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86fdcf1e-ac92-4bc7-b091-043d58962ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video 01 ...\n",
      "Processing video 02 ...\n",
      "Processing video 03 ...\n",
      "Processing video 04 ...\n",
      "Processing video 06 ...\n",
      "Processing video 07 ...\n",
      "Processing video 08 ...\n",
      "Processing video 09 ...\n",
      "Processing video 11 ...\n",
      "Processing video 12 ...\n",
      "Processing video 13 ...\n",
      "Processing video 14 ...\n",
      "Processing video 16 ...\n",
      "Processing video 17 ...\n",
      "Processing video 18 ...\n",
      "Processing video 19 ...\n",
      "Processing video 21 ...\n",
      "Processing video 22 ...\n",
      "Processing video 23 ...\n",
      "Processing video 24 ...\n",
      "Processing video 27 ...\n",
      "Processing video 28 ...\n",
      "Processing video 29 ...\n",
      "Processing video 30 ...\n",
      "Processing video 33 ...\n",
      "Processing video 35 ...\n",
      "Processing video 36 ...\n",
      "Processing video 38 ...\n",
      "Processing video 39 ...\n",
      "Processing video 41 ...\n",
      "Processing video 42 ...\n",
      "Processing video 43 ...\n",
      "Processing video 44 ...\n",
      "Processing video 46 ...\n",
      "Processing video 05 ...\n",
      "Processing video 10 ...\n",
      "Processing video 15 ...\n",
      "Processing video 20 ...\n",
      "Processing video 25 ...\n",
      "Processing video 32 ...\n",
      "Processing video 34 ...\n",
      "Processing video 40 ...\n",
      "Processing video 45 ...\n"
     ]
    }
   ],
   "source": [
    "for movie_id in movie_ids:\n",
    "    print(\"Processing video\", movie_id, \"...\")\n",
    "    \n",
    "    base_fn = training_name+\"_\"+str(epoch)+\"_\"+movie_id+\"_white_bg\"\n",
    "    \n",
    "    # write predictions on disk\n",
    "    write_colored_events_videos_on_disk(movie=xs[movie_id],\n",
    "                                       classes_mask=preds[movie_id],\n",
    "                                       out_dir=out_dir,\n",
    "                                       movie_fn=base_fn+\"_colored_preds\",\n",
    "                                       transparency=transparency,\n",
    "                                       ignore_frames=ignore_frames,\n",
    "                                       white_bg=True)\n",
    "    \n",
    "    # write labels on disk\n",
    "    write_colored_events_videos_on_disk(movie=xs[movie_id],\n",
    "                                       classes_mask=ys[movie_id],\n",
    "                                       out_dir=out_dir,\n",
    "                                       movie_fn=base_fn+\"_colored_labels\",\n",
    "                                       transparency=transparency,\n",
    "                                       ignore_frames=ignore_frames,\n",
    "                                       white_bg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97324540",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea13a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5a6f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
