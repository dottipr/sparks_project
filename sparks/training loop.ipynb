{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "318df241-7712-41cc-8d97-8d04cd257d8b",
   "metadata": {},
   "source": [
    "15.08.2022\n",
    "\n",
    "### **GOAL**: training basato sul dataset usando l'architettura della UNet trovata su GitHub (https://github.com/ELEKTRONN/elektronn3).\n",
    "\n",
    "Uso questo notebook per creare il codice necessario a fare il training. Quando avrò finito, se funziona, lo copierò in uno script classico di Python (.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae55015f-71e3-42c3-b52f-5563521203fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b4eace0-8338-4377-abde-512d786f86b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import logging\n",
    "import argparse\n",
    "import configparser\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5139c83c-46d0-476d-817d-bed545d4ec96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e65a81d8-f206-4945-8d9a-667a29b73978",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import unet\n",
    "from dataset_tools import random_flip, random_flip_noise, compute_class_weights, weights_init\n",
    "from datasets import SparkDataset\n",
    "from training_tools import training_step, test_function, sampler\n",
    "from metrics_tools import take_closest\n",
    "from other_losses import FocalLoss, LovaszSoftmax3d, SumFocalLovasz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99a686e9-5f3e-4282-89c0-81eb2f9beadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd5fbe12-52a1-448c-9aa1-0bbab61f4d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from new_unet import UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f84b0c2-582a-415c-98ce-ad844e6b6cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASEDIR = os.path.abspath('')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e70c29df-93e2-4862-a80f-3394e564f9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parser = argparse.ArgumentParser(\"Spark & Puff detector using U-Net (ELEKTRONN3 model).\")\n",
    "\n",
    "############################# load config file #############################\n",
    "\n",
    "#parser.add_argument(\n",
    "#    'config',\n",
    "#    type=str,\n",
    "#    help=\"Input config file, used to configure training\"\n",
    "#)\n",
    "#args = parser.parse_args()\n",
    "\n",
    "config_directory = \"config_files\"\n",
    "#CONFIG_FILE = os.path.join(BASEDIR, \"config_files\", args.config)\n",
    "CONFIG_FILE = os.path.join(BASEDIR, \n",
    "                           \"config_files\", \n",
    "                           \"config_new_unet_architecture_physio.ini\")\n",
    "c = configparser.ConfigParser()\n",
    "if os.path.isfile(CONFIG_FILE):\n",
    "    logger.info(f\"Loading {CONFIG_FILE}\")\n",
    "    c.read(CONFIG_FILE)\n",
    "else:\n",
    "    logger.warning(f\"No config file found at {CONFIG_FILE}, trying to use fallback values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc2764b7-ff7f-4d37-8d68-a40ed8a012c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################## set parameters ##############################\n",
    "\n",
    "params = {}\n",
    "\n",
    "# general params\n",
    "params['name'] = c.get(\"general\", \"run_name\", fallback=\"run\") # Run name\n",
    "params['load_name'] = c.get(\"general\", \"load_run_name\", fallback=None)\n",
    "\n",
    "# training params\n",
    "params['load_epoch'] = c.getint(\"state\", \"load_epoch\", fallback=0)\n",
    "params['train_epochs'] = c.getint(\"training\", \"epochs\", fallback=5000)\n",
    "params['training'] = c.getboolean(\"general\", \"training\") # Run training procedure on data\n",
    "params['testing'] = c.getboolean(\"general\", \"testing\") # Run training procedure on data\n",
    "params['loss_function'] = c.get(\"training\", \"criterion\", fallback=\"nll_loss\")\n",
    "if (params['loss_function'] == 'focal_loss') or( params['loss_function'] == \"sum_losses\"):\n",
    "    params['gamma'] = c.getfloat(\"training\", \"gamma\", fallback=2.0)\n",
    "if params['loss_function'] == 'sum_losses':\n",
    "    params['w'] = c.getfloat(\"training\", \"w\", fallback=0.5)\n",
    "params['lr_start'] = c.getfloat(\"training\", \"lr_start\", fallback=1e-4)\n",
    "\n",
    "# data params\n",
    "params['dataset_basedir'] = c.get(\"data\", \"relative_path\")\n",
    "params['dataset_size'] = c.get(\"data\", \"size\", fallback=\"full\")\n",
    "params['batch_size'] = c.getint(\"general\", \"batch_size\", fallback=\"1\")\n",
    "params['data_duration'] = c.getint(\"data\", \"chunks_duration\")\n",
    "params['data_step'] = c.getint(\"data\", \"step\")\n",
    "params['ignore_frames_loss'] = c.getint(\"data\", \"ignore_frames_loss\")\n",
    "params['data_smoothing'] = c.get(\"data\", \"smoothing\", fallback=\"2d\")\n",
    "params['norm_video'] = c.get(\"data\", \"norm_video\", fallback=\"chunk\")\n",
    "params['remove_background'] = c.get(\"data\", \"remove_background\", fallback='average')\n",
    "params['only_sparks'] = c.getboolean(\"data\", \"only_sparks\", fallback=False)\n",
    "params['noise_data_augmentation'] = c.getboolean(\"data\", \"noise_data_augmentation\", fallback=False)\n",
    "params['sparks_type'] = c.get(\"data\", \"sparks_type\", fallback=\"peaks\")\n",
    "\n",
    "# UNet params\n",
    "params['unet_steps'] = c.getint(\"network\", \"step\")\n",
    "params['first_layer_channels'] = c.getint(\"network\", \"first_layer_channels\")\n",
    "params['temporal_reduction'] = c.getboolean(\"network\", \"temporal_reduction\", fallback=False)\n",
    "params['num_channels'] = c.getint(\"network\", \"num_channels\", fallback=1)\n",
    "\n",
    "# Testing params\n",
    "params['t_detection_sparks'] = c.getfloat(\"testing\", \"t_sparks\")\n",
    "params['t_detection_puffs'] = c.getfloat(\"testing\", \"t_puffs\")\n",
    "params['t_detection_waves'] = c.getfloat(\"testing\", \"t_waves\")\n",
    "params['sparks_min_radius'] = c.getint(\"testing\", \"sparks_min_radius\")\n",
    "params['puffs_min_radius'] = c.getint(\"testing\", \"puffs_min_radius\")\n",
    "params['waves_min_radius'] = c.getint(\"testing\", \"waves_min_radius\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "911e9452-6bfd-48ff-81d2-68b0c8dc09fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# configure logger #############################\n",
    "\n",
    "level_map = {3: logging.DEBUG, 2: logging.INFO, 1: logging.WARNING, 0: logging.ERROR}\n",
    "log_level = level_map[c.getint(\"general\", \"verbosity\", fallback=\"0\")]\n",
    "log_handlers = (logging.StreamHandler(sys.stdout), )\n",
    "\n",
    "logfile = c.get(\"general\", \"logfile\", fallback=None)\n",
    "\n",
    "if logfile:\n",
    "    if not os.path.isdir(os.path.basename(logfile)):\n",
    "        logger.info(\"Creating parent directory for logs\")\n",
    "        os.mkdir(os.path.basename(logfile))\n",
    "\n",
    "    if os.path.isdir(logfile):\n",
    "        logfile_path = os.path.abspath(os.path.join(logfile, f\"{__name__}.log\"))\n",
    "    else:\n",
    "        logfile_path = os.path.abspath(logfile)\n",
    "\n",
    "    logger.info(f\"Storing logs in {logfile_path}\")\n",
    "    file_handler = logging.RotatingFileHandler(\n",
    "        filename=logfile_path,\n",
    "        maxBytes=(1024 * 1024 * 8),  # 8 MB\n",
    "        backupCount=4,\n",
    "    )\n",
    "    log_handlers += (file_handler, )\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=log_level,\n",
    "    format='[{asctime}] [{levelname:^8s}] [{name:^12s}] <{lineno:^4d}> -- {message:s}',\n",
    "    style='{',\n",
    "    datefmt=\"%H:%M:%S\",\n",
    "    handlers=log_handlers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c257c95-0acd-455b-a7bb-2e09b8061397",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# configure wandb ##############################\n",
    "\n",
    "if c.getboolean(\"general\", \"wandb_enable\", fallback=False):\n",
    "    wandb.init(project=c.get(\"general\", \"wandb_project_name\"), name=params['name'])\n",
    "    logging.getLogger('wandb').setLevel(logging.DEBUG)\n",
    "    #wandb.save(CONFIG_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42e4adc3-2ae7-403b-a135-7df16e91581a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:01:16] [  INFO  ] [  __main__  ] < 3  > -- Command parameters:\n",
      "[12:01:16] [  INFO  ] [  __main__  ] < 5  > --               name: new_unet_architecture_physio\n",
      "[12:01:16] [  INFO  ] [  __main__  ] < 5  > --          load_name: None\n",
      "[12:01:16] [  INFO  ] [  __main__  ] < 5  > --         load_epoch: 0\n",
      "[12:01:16] [  INFO  ] [  __main__  ] < 5  > --       train_epochs: 100000\n",
      "[12:01:16] [  INFO  ] [  __main__  ] < 5  > --           training: True\n",
      "[12:01:16] [  INFO  ] [  __main__  ] < 5  > --            testing: True\n",
      "[12:01:16] [  INFO  ] [  __main__  ] < 5  > --      loss_function: lovasz_softmax\n",
      "[12:01:16] [  INFO  ] [  __main__  ] < 5  > --           lr_start: 0.0001\n",
      "[12:01:16] [  INFO  ] [  __main__  ] < 5  > --    dataset_basedir: ../data/sparks_dataset\n",
      "[12:01:16] [  INFO  ] [  __main__  ] < 5  > --       dataset_size: full\n",
      "[12:01:16] [  INFO  ] [  __main__  ] < 5  > --         batch_size: 4\n",
      "[12:01:16] [  INFO  ] [  __main__  ] < 5  > --      data_duration: 256\n",
      "[12:01:16] [  INFO  ] [  __main__  ] < 5  > --          data_step: 32\n",
      "[12:01:16] [  INFO  ] [  __main__  ] < 5  > -- ignore_frames_loss: 6\n",
      "[12:01:16] [  INFO  ] [  __main__  ] < 5  > --     data_smoothing: no\n",
      "[12:01:16] [  INFO  ] [  __main__  ] < 5  > --         norm_video: abs_max\n",
      "[12:01:16] [  INFO  ] [  __main__  ] < 5  > --  remove_background: no\n",
      "[12:01:16] [  INFO  ] [  __main__  ] < 5  > --        only_sparks: False\n",
      "[12:01:16] [  INFO  ] [  __main__  ] < 5  > -- noise_data_augmentation: False\n",
      "[12:01:16] [  INFO  ] [  __main__  ] < 5  > --        sparks_type: raw\n",
      "[12:01:16] [  INFO  ] [  __main__  ] < 5  > --         unet_steps: 6\n",
      "[12:01:16] [  INFO  ] [  __main__  ] < 5  > -- first_layer_channels: 32\n",
      "[12:01:16] [  INFO  ] [  __main__  ] < 5  > -- temporal_reduction: False\n",
      "[12:01:16] [  INFO  ] [  __main__  ] < 5  > --       num_channels: 1\n",
      "[12:01:16] [  INFO  ] [  __main__  ] < 5  > -- t_detection_sparks: 0.65\n",
      "[12:01:16] [  INFO  ] [  __main__  ] < 5  > --  t_detection_puffs: 0.65\n",
      "[12:01:16] [  INFO  ] [  __main__  ] < 5  > --  t_detection_waves: 0.6\n",
      "[12:01:16] [  INFO  ] [  __main__  ] < 5  > --  sparks_min_radius: 0\n",
      "[12:01:16] [  INFO  ] [  __main__  ] < 5  > --   puffs_min_radius: 5\n",
      "[12:01:16] [  INFO  ] [  __main__  ] < 5  > --   waves_min_radius: 0\n"
     ]
    }
   ],
   "source": [
    "############################# print parameters #############################\n",
    "\n",
    "logger.info(\"Command parameters:\")\n",
    "for k, v in params.items():\n",
    "    logger.info(f\"{k:>18s}: {v}\")\n",
    "    # TODO: AGGIUNGERE TUTTI I PARAMS NECESSARI DA PRINTARE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f96ed99-3176-4b00-aa76-23d6844879fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ init random seeds #############################\n",
    "\n",
    "torch.manual_seed(0)\n",
    "#random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbf10176-1a02-4647-abaa-be13bda54515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:16:22] [  INFO  ] [  __main__  ] < 9  > -- Using torch device cuda, with 1 GPUs\n"
     ]
    }
   ],
   "source": [
    "########################### detect CUDA devices ############################\n",
    "if c.getboolean(\"general\", \"cuda\", fallback=True):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    pin_memory = True\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    pin_memory = False\n",
    "n_gpus = torch.cuda.device_count()\n",
    "logger.info(f\"Using torch device {device}, with {n_gpus} GPUs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78786cd9-b873-4637-80e4-266f83821c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:16:22] [  INFO  ] [  __main__  ] < 28 > -- Normalizing whole video using 16-bit absolute max\n"
     ]
    }
   ],
   "source": [
    "############################ configure datasets ############################\n",
    "\n",
    "# select samples that are used for training and testing\n",
    "if params['dataset_size'] == 'full':\n",
    "    train_sample_ids = [\"01\",\"02\",\"03\",\"04\",\"06\",\"07\",\"08\",\"09\",\n",
    "                        \"11\",\"12\",\"13\",\"14\",\"16\",\"17\",\"18\",\"19\",\n",
    "                        \"21\",\"22\",\"23\",\"24\",\"27\",\"28\",\"29\",\n",
    "                        \"30\",\"33\",\"35\",\"36\",\"38\",\"39\",\n",
    "                        \"41\",\"42\",\"43\",\"44\",\"46\"]\n",
    "    test_sample_ids = [\"05\",\"10\",\"15\",\"20\",\"25\",\"32\",\"34\",\"40\",\"45\"]\n",
    "elif params['dataset_size'] == 'minimal':\n",
    "    train_sample_ids = [\"01\"]\n",
    "    test_sample_ids = [\"34\"]\n",
    "else:\n",
    "    logger.error(f\"{params['dataset_size']} is not a valid dataset size.\")\n",
    "    exit()\n",
    "\n",
    "# set if temporal reduction is used\n",
    "if params['temporal_reduction']:\n",
    "    logger.info(f\"Using temporal reduction with {params['num_channels']} channels\")\n",
    "\n",
    "# normalize whole videos or chunks individually\n",
    "if params['norm_video'] == 'chunk':\n",
    "    logger.info(\"Normalizing each chunk using min and max\")\n",
    "elif params['norm_video'] == 'movie':\n",
    "    logger.info(\"Normalizing whole video using min and max\")\n",
    "elif params['norm_video'] == 'abs_max':\n",
    "    logger.info(\"Normalizing whole video using 16-bit absolute max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1765a3c1-4d4f-444f-b189-fd0734109758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:16:22] [  INFO  ] [  __main__  ] < 4  > -- Using C:\\Users\\dotti\\sparks_project\\data\\sparks_dataset as dataset root path\n",
      "[16:16:22] [  INFO  ] [  datasets  ] <267 > -- Added padding of 12 frames to video with unsuitable duration\n"
     ]
    }
   ],
   "source": [
    "# initialize training dataset\n",
    "dataset_path = os.path.realpath(f\"{BASEDIR}/{params['dataset_basedir']}\")\n",
    "assert os.path.isdir(dataset_path), f\"\\\"{dataset_path}\\\" is not a directory\"\n",
    "logger.info(f\"Using {dataset_path} as dataset root path\")\n",
    "dataset = SparkDataset(\n",
    "    base_path=dataset_path,\n",
    "    sample_ids=train_sample_ids,\n",
    "    testing=False,\n",
    "    smoothing=params['data_smoothing'],\n",
    "    step=params['data_step'],\n",
    "    duration=params['data_duration'],\n",
    "    remove_background=params['remove_background'],\n",
    "    temporal_reduction=params['temporal_reduction'],\n",
    "    num_channels=params['num_channels'],\n",
    "    normalize_video=params['norm_video'],\n",
    "    only_sparks=params['only_sparks'],\n",
    "    sparks_type=params['sparks_type']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a1757d6-cb7c-435a-97e8-e3356c8c86ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified since not importing Pablo's code for UNet\n",
    "from torch.utils.data import Dataset\n",
    "class TransformedDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, source_dataset, transform):\n",
    "        self.source_dataset = source_dataset\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.source_dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        value = self.source_dataset[idx]\n",
    "        \n",
    "        if isinstance(value, tuple):\n",
    "            return self.transform(*value)\n",
    "        \n",
    "        return self.transform(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3be6602-6444-4750-9794-928f1ebca850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:16:22] [  INFO  ] [  __main__  ] < 8  > -- Samples in training dataset: 9\n"
     ]
    }
   ],
   "source": [
    "# modified since not importing Pablo's code for UNet\n",
    "# apply transforms\n",
    "if params['noise_data_augmentation']:\n",
    "    dataset = TransformedDataset(dataset, random_flip_noise)\n",
    "else:\n",
    "    dataset = TransformedDataset(dataset, random_flip)\n",
    "\n",
    "logger.info(f\"Samples in training dataset: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c25c772-a398-4a2b-a6f1-7beaf21073c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:16:22] [WARNING ] [tifffile.tifffile] <16549> -- TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n",
      "[16:16:23] [  INFO  ] [  datasets  ] <167 > -- Computing spark peaks...\n",
      "[16:16:29] [  INFO  ] [  datasets  ] <173 > -- Sample 34 contains 16 sparks.\n",
      "[16:16:29] [  INFO  ] [  datasets  ] <267 > -- Added padding of 24 frames to video with unsuitable duration\n",
      "[16:16:29] [  INFO  ] [  __main__  ] < 23 > -- Testing dataset 0 contains 22 samples\n"
     ]
    }
   ],
   "source": [
    "# initialize testing dataset\n",
    "pattern_test_filenames = os.path.join(f\"{dataset_path}\",\"videos_test\",\n",
    "                                       \"[0-9][0-9]_video.tif\")\n",
    "\n",
    "testing_datasets = [\n",
    "            SparkDataset(\n",
    "            base_path=dataset_path,\n",
    "            sample_ids=[sample_id],\n",
    "            testing=True,\n",
    "            smoothing=params['data_smoothing'],\n",
    "            step=params['data_step'],\n",
    "            duration=params['data_duration'],\n",
    "            remove_background=params['remove_background'],\n",
    "            temporal_reduction=params['temporal_reduction'],\n",
    "            num_channels=params['num_channels'],\n",
    "            normalize_video=params['norm_video'],\n",
    "            only_sparks=params['only_sparks'],\n",
    "            sparks_type=params['sparks_type'],\n",
    "            ignore_frames=params['ignore_frames_loss']\n",
    "            ) for sample_id in test_sample_ids]\n",
    "\n",
    "for i, tds in enumerate(testing_datasets):\n",
    "    logger.info(f\"Testing dataset {i} contains {len(tds)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e29aaa6e-d134-4830-a6d5-6df78167cf08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:16:29] [  INFO  ] [  __main__  ] < 3  > -- Using class weights: 0.25127315521240234, 314.40069580078125, 0.0, 58.52518844604492\n"
     ]
    }
   ],
   "source": [
    "# class weights\n",
    "class_weights = compute_class_weights(dataset)\n",
    "logger.info(\"Using class weights: {}\".format(', '.join(str(w.item()) for w in class_weights)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34a021c3-5ed3-4c06-8829-22103a71086a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize data loaders\n",
    "dataset_loader = DataLoader(dataset,\n",
    "                            batch_size=params['batch_size'],\n",
    "                            shuffle=True,\n",
    "                            num_workers=c.getint(\"training\", \"num_workers\"),\n",
    "                            pin_memory=pin_memory)\n",
    "testing_dataset_loaders = [\n",
    "    DataLoader(test_dataset,\n",
    "               batch_size=params['batch_size'],\n",
    "               shuffle=False,\n",
    "               num_workers=c.getint(\"training\", \"num_workers\"))\n",
    "    for test_dataset in testing_datasets\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de8a7b2c-4f42-4f1d-bd5a-d8394cee4a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################## configure UNet ##############################\n",
    "\n",
    "#unet_config = unet.UNetConfig(\n",
    "#    steps=params['unet_steps'],\n",
    "#    first_layer_channels=params['first_layer_channels'],\n",
    "#    num_classes=c.getint(\"network\", \"num_classes\"),\n",
    "#    ndims=c.getint(\"network\", \"ndims\"),\n",
    "#    dilation=c.getint(\"network\", \"dilation\", fallback=1),\n",
    "#    border_mode=c.get(\"network\", \"border_mode\"),\n",
    "#    batch_normalization=c.getboolean(\"network\", \"batch_normalization\"),\n",
    "#    num_input_channels=params['num_channels'],\n",
    "#)\n",
    "\n",
    "#if not params['temporal_reduction']:\n",
    "#    network = unet.UNetClassifier(unet_config)\n",
    "#else:\n",
    "#    assert params['data_duration'] % params['num_channels'] == 0, \\\n",
    "#    \"using temporal reduction chunks_duration must be a multiple of num_channels\"\n",
    "#    network = TempRedUNet(unet_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7024b70c-7469-4d3e-9b66-23362f302a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from new_unet import UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4aa9d9b9-78f9-43c9-9533-714f26ffe446",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################## configure UNet ##############################\n",
    "out_channels = c.getint(\"network\", \"num_classes\")\n",
    "network = UNet(\n",
    "    in_channels=params['num_channels'],\n",
    "    out_channels=out_channels,\n",
    "    n_blocks=params['unet_steps'],\n",
    "    start_filts=params['first_layer_channels'],\n",
    "    #up_mode = ... # TESTARE DIVERSE POSSIBILTÀ, e.g.'resizeconv_nearest' to avoid checkerboard artifacts\n",
    "    merge_mode='concat', # Default, dicono che funziona meglio\n",
    "    #planar_blocks=(0,), # magari capire cos'è e testarlo ??\n",
    "    activation='relu',\n",
    "    normalization='batch', # Penso che nell'implementazione di Pablo è 'none'\n",
    "    attention=False, # magari da testare con 'True' ??\n",
    "    #full_norm=False,  # Uncomment to restore old sparse normalization scheme\n",
    "    dim=c.getint(\"network\", \"ndims\"),\n",
    "    #conv_mode='valid',  # magari testare, ha dei vantaggi a quanto pare...\n",
    "    #up_mode='resizeconv_nearest',  # Enable to avoid checkerboard artifacts\n",
    ").to(device)\n",
    "\n",
    "# DOC: https://elektronn3.readthedocs.io/en/latest/source/elektronn3.models.unet.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "75559c1e-4dcf-42fc-a4df-7ba4c72de398",
   "metadata": {},
   "outputs": [],
   "source": [
    "if device != \"cpu\":\n",
    "    network = nn.DataParallel(network).to(device)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "if c.getboolean(\"general\", \"wandb_enable\"):\n",
    "    wandb.watch(network)\n",
    "\n",
    "if c.getboolean(\"network\", \"initialize_weights\", fallback=False):\n",
    "    logger.info(\"Initializing UNet weights...\")\n",
    "    network.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "838d9140-e8e8-4b95-a587-cf7bb80efd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### set testing function ###########################\n",
    "\n",
    "#thresholds = np.linspace(0, 1, num=21) # thresholds for events detection\n",
    "                                       # TODO: maybe change because\n",
    "                                       # nonmaxima supression is computed\n",
    "                                       # for every threshold (slow)\n",
    "fixed_threshold = c.getfloat(\"testing\", \"fixed_threshold\", fallback = 0.9)\n",
    "#closest_t = take_closest(thresholds, fixed_threshold) # Compute idx of t in\n",
    "                                                      # thresholds list that\n",
    "                                                      # is closest to\n",
    "                                                      # fixed_threshold\n",
    "#idx_fixed_t = list(thresholds).index(closest_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8f61faad-b76c-4a75-8ab3-b0e10d3dd197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:08:18] [  INFO  ] [  __main__  ] < 8  > -- Output directory: runs/TEST_new_unet_architecture_physio\n"
     ]
    }
   ],
   "source": [
    "########################### initialize training ############################\n",
    "\n",
    "optimizer = optim.Adam(network.parameters(), lr=params['lr_start'])\n",
    "network.train()\n",
    "\n",
    "output_path = os.path.join(c.get(\"network\", \"output_relative_path\"),\n",
    "                           params['name'])\n",
    "logger.info(f\"Output directory: {output_path}\")\n",
    "\n",
    "summary_writer = SummaryWriter(os.path.join(output_path, \"summary\"),\n",
    "                               purge_step=0)\n",
    "\n",
    "if params['load_name'] != None:\n",
    "    load_path = os.path.join(c.get(\"network\", \"output_relative_path\"),\n",
    "                               params['load_name'])\n",
    "    logger.info(f\"Model loaded from directory: {load_path}\")\n",
    "else:\n",
    "    load_path = None\n",
    "\n",
    "\n",
    "if params['loss_function'] == \"nll_loss\":\n",
    "    criterion = nn.NLLLoss(ignore_index=c.getint(\"data\", \"ignore_index\"),\n",
    "                           weight=class_weights.to(device))\n",
    "elif params['loss_function'] == \"focal_loss\":\n",
    "    criterion = FocalLoss(reduction='mean',\n",
    "                          ignore_index=c.getint(\"data\", \"ignore_index\"),\n",
    "                          alpha=class_weights,\n",
    "                          gamma=params['gamma'])\n",
    "elif params['loss_function'] == 'lovasz_softmax':\n",
    "    criterion = LovaszSoftmax3d(classes='present',\n",
    "                                per_image=False,\n",
    "                                ignore=c.getint(\"data\", \"ignore_index\"))\n",
    "elif params['loss_function'] == 'sum_losses':\n",
    "    criterion = SumFocalLovasz(classes ='present',\n",
    "                               per_image = False,\n",
    "                               ignore = c.getint(\"data\", \"ignore_index\"),\n",
    "                               alpha = class_weights,\n",
    "                               gamma = params['gamma'],\n",
    "                               reduction = 'mean',\n",
    "                               w = params['w'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "30ee9c28-1f61-4818-b3e9-84737cfbaf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from training_tools import test_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d3e9fac4-eb5c-4ec6-bb8f-f7d18f265998",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = unet.TrainingManager(\n",
    "    # training items\n",
    "    training_step=lambda _: training_step(\n",
    "        sampler,\n",
    "        network,\n",
    "        optimizer,\n",
    "        device,\n",
    "        criterion,\n",
    "        dataset_loader,\n",
    "        ignore_frames=params['ignore_frames_loss'],\n",
    "        wandb_log=c.getboolean(\"general\", \"wandb_enable\", fallback=False)\n",
    "    ),\n",
    "    save_every=c.getint(\"training\", \"save_every\", fallback=5000),\n",
    "    #load_path=load_path,\n",
    "    save_path=output_path,\n",
    "    managed_objects=unet.managed_objects({\n",
    "        'network': network,\n",
    "        'optimizer': optimizer\n",
    "    }),\n",
    "    # testing items\n",
    "    test_function=lambda _: test_function(\n",
    "        #network=network,\n",
    "        network=network,\n",
    "        device=device,\n",
    "        criterion=criterion,\n",
    "        testing_datasets=testing_datasets,\n",
    "        logger=logger,\n",
    "        ignore_frames=params['ignore_frames_loss'],\n",
    "        wandb_log=c.getboolean(\"general\", \"wandb_enable\", fallback=False),\n",
    "        training_name=c.get(\"general\", \"run_name\"),\n",
    "        training_mode=True\n",
    "    ),\n",
    "    test_every=c.getint(\"training\", \"test_every\", fallback=1000),\n",
    "    plot_every=c.getint(\"training\", \"plot_every\", fallback=1000),\n",
    "    summary_writer=summary_writer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "05362795-3079-4644-a03b-abda822f48bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################## start training ##############################\n",
    "\n",
    "if params['load_epoch'] != 0:\n",
    "    trainer.load(params['load_epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4fc5ad-00bd-4021-848a-f5e85e5ac068",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if params['training']:\n",
    "    logger.info(\"Validate network before training\")\n",
    "    trainer.run_validation()\n",
    "    logger.info(\"Starting training\")\n",
    "    trainer.train(params['train_epochs'], print_every=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3d4960d1-6cdb-4f7a-880d-b097ab9f3d11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:14:40] [  INFO  ] [  __main__  ] < 2  > -- Starting final validation\n",
      "[17:14:40] [  INFO  ] [unet.trainer] <137 > -- Validating network at iteration 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dotti\\.conda\\envs\\sparks\\lib\\site-packages\\torch\\nn\\functional.py:878: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool3d in a future release.\n",
      "  warnings.warn(\"Note that order of the arguments: ceil_mode and return_indices will change\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest coordinates: \n",
      "[[728.  25. 294.]\n",
      " [728.  23. 289.]]\n",
      "[17:17:00] [  INFO  ] [  __main__  ] <547 > -- \tvalidation loss: 2.388\n",
      "[17:17:00] [  INFO  ] [  __main__  ] <628 > -- \tvalidation_loss: 2.388\n",
      "[17:17:00] [  INFO  ] [  __main__  ] <628 > -- \tsparks/pixel_prec: 0.000168\n",
      "[17:17:00] [  INFO  ] [  __main__  ] <628 > -- \tsparks/pixel_rec: 0.00393\n",
      "[17:17:00] [  INFO  ] [  __main__  ] <628 > -- \tsparks/precision: 0.0007133\n",
      "[17:17:00] [  INFO  ] [  __main__  ] <628 > -- \tsparks/recall: 0.4375\n",
      "[17:17:00] [  INFO  ] [  __main__  ] <628 > -- \tsparks/f1_score: 0.001424\n",
      "[17:17:00] [  INFO  ] [  __main__  ] <628 > -- \twaves/iou: 0\n",
      "[17:17:00] [  INFO  ] [  __main__  ] <628 > -- \twaves/pixel_prec: 0\n",
      "[17:17:00] [  INFO  ] [  __main__  ] <628 > -- \twaves/pixel_rec: 0\n",
      "[17:17:00] [  INFO  ] [  __main__  ] <628 > -- \tpuffs/iou: 8.206e-05\n",
      "[17:17:00] [  INFO  ] [  __main__  ] <628 > -- \tpuffs/pixel_prec: 8.928e-05\n",
      "[17:17:00] [  INFO  ] [  __main__  ] <628 > -- \tpuffs/pixel_rec: 0.001014\n"
     ]
    }
   ],
   "source": [
    "if params['testing']:\n",
    "    logger.info(\"Starting final validation\")\n",
    "    trainer.run_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "853e5426-efee-41cd-9834-75a1fe476477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel(\n",
      "  (module): UNet(\n",
      "    (down_convs): ModuleList(\n",
      "      (0): DownConv(\n",
      "        (conv1): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (conv2): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (pool): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "        (act1): ReLU()\n",
      "        (act2): ReLU()\n",
      "        (norm0): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): DownConv(\n",
      "        (conv1): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (pool): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "        (act1): ReLU()\n",
      "        (act2): ReLU()\n",
      "        (norm0): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): DownConv(\n",
      "        (conv1): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (pool): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "        (act1): ReLU()\n",
      "        (act2): ReLU()\n",
      "        (norm0): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): DownConv(\n",
      "        (conv1): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (pool): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "        (act1): ReLU()\n",
      "        (act2): ReLU()\n",
      "        (norm0): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (4): DownConv(\n",
      "        (conv1): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (pool): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "        (act1): ReLU()\n",
      "        (act2): ReLU()\n",
      "        (norm0): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (5): DownConv(\n",
      "        (conv1): Conv3d(512, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (conv2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (pool): Identity()\n",
      "        (act1): ReLU()\n",
      "        (act2): ReLU()\n",
      "        (norm0): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (up_convs): ModuleList(\n",
      "      (0): UpConv(\n",
      "        (upconv): ConvTranspose3d(1024, 512, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
      "        (conv1): Conv3d(1024, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (act0): ReLU()\n",
      "        (act1): ReLU()\n",
      "        (act2): ReLU()\n",
      "        (norm0): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (attention): DummyAttention()\n",
      "      )\n",
      "      (1): UpConv(\n",
      "        (upconv): ConvTranspose3d(512, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
      "        (conv1): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (act0): ReLU()\n",
      "        (act1): ReLU()\n",
      "        (act2): ReLU()\n",
      "        (norm0): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (attention): DummyAttention()\n",
      "      )\n",
      "      (2): UpConv(\n",
      "        (upconv): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
      "        (conv1): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (act0): ReLU()\n",
      "        (act1): ReLU()\n",
      "        (act2): ReLU()\n",
      "        (norm0): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (attention): DummyAttention()\n",
      "      )\n",
      "      (3): UpConv(\n",
      "        (upconv): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
      "        (conv1): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (act0): ReLU()\n",
      "        (act1): ReLU()\n",
      "        (act2): ReLU()\n",
      "        (norm0): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (attention): DummyAttention()\n",
      "      )\n",
      "      (4): UpConv(\n",
      "        (upconv): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
      "        (conv1): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (conv2): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (act0): ReLU()\n",
      "        (act1): ReLU()\n",
      "        (act2): ReLU()\n",
      "        (norm0): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (norm2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (attention): DummyAttention()\n",
      "      )\n",
      "    )\n",
      "    (logsoftmax): LogSoftmax(dim=1)\n",
      "    (conv_final): Conv3d(32, 4, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7895f640-32e3-4219-9497-af78529a82ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "530ab8c1-e92a-4c61-be6b-41321beb2e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_config = unet.UNetConfig(\n",
    "        steps=params['unet_steps'],\n",
    "        first_layer_channels=params['first_layer_channels'],\n",
    "        num_classes=c.getint(\"network\", \"num_classes\"),\n",
    "        ndims=c.getint(\"network\", \"ndims\"),\n",
    "        dilation=c.getint(\"network\", \"dilation\", fallback=1),\n",
    "        border_mode=c.get(\"network\", \"border_mode\"),\n",
    "        batch_normalization=c.getboolean(\"network\", \"batch_normalization\"),\n",
    "        num_input_channels=params['num_channels'],\n",
    "    )\n",
    "\n",
    "if not params['temporal_reduction']:\n",
    "    network2 = unet.UNetClassifier(unet_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b0c9378e-e6f8-425f-b0e0-2b161d1dc3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNetClassifier(\n",
      "  (max_pool): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (down_path): Sequential(\n",
      "    (0): UNetLayer(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): Identity()\n",
      "        (3): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (4): ReLU()\n",
      "        (5): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): UNetLayer(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): Identity()\n",
      "        (3): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (4): ReLU()\n",
      "        (5): Identity()\n",
      "      )\n",
      "    )\n",
      "    (2): UNetLayer(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): Identity()\n",
      "        (3): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (4): ReLU()\n",
      "        (5): Identity()\n",
      "      )\n",
      "    )\n",
      "    (3): UNetLayer(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): Identity()\n",
      "        (3): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (4): ReLU()\n",
      "        (5): Identity()\n",
      "      )\n",
      "    )\n",
      "    (4): UNetLayer(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): Identity()\n",
      "        (3): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (4): ReLU()\n",
      "        (5): Identity()\n",
      "      )\n",
      "    )\n",
      "    (5): UNetLayer(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv3d(512, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): Identity()\n",
      "        (3): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (4): ReLU()\n",
      "        (5): Identity()\n",
      "      )\n",
      "    )\n",
      "    (6): UNetLayer(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv3d(1024, 2048, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): Identity()\n",
      "        (3): Conv3d(2048, 2048, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (4): ReLU()\n",
      "        (5): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (up_path): Sequential(\n",
      "    (0): ConvTranspose3d(2048, 1024, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
      "    (1): UNetLayer(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv3d(2048, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): Identity()\n",
      "        (3): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (4): ReLU()\n",
      "        (5): Identity()\n",
      "      )\n",
      "    )\n",
      "    (2): ConvTranspose3d(1024, 512, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
      "    (3): UNetLayer(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv3d(1024, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): Identity()\n",
      "        (3): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (4): ReLU()\n",
      "        (5): Identity()\n",
      "      )\n",
      "    )\n",
      "    (4): ConvTranspose3d(512, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
      "    (5): UNetLayer(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): Identity()\n",
      "        (3): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (4): ReLU()\n",
      "        (5): Identity()\n",
      "      )\n",
      "    )\n",
      "    (6): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
      "    (7): UNetLayer(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): Identity()\n",
      "        (3): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (4): ReLU()\n",
      "        (5): Identity()\n",
      "      )\n",
      "    )\n",
      "    (8): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
      "    (9): UNetLayer(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): Identity()\n",
      "        (3): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (4): ReLU()\n",
      "        (5): Identity()\n",
      "      )\n",
      "    )\n",
      "    (10): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
      "    (11): UNetLayer(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): Identity()\n",
      "        (3): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (4): ReLU()\n",
      "        (5): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (final_layer): Conv3d(32, 4, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "  (logsoftmax): LogSoftmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(network2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f2c3c58-74d7-4f29-a6d0-3cb8981c12b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_config = unet.UNetConfig(\n",
    "        steps=params['unet_steps'],\n",
    "        first_layer_channels=64,\n",
    "        num_classes=c.getint(\"network\", \"num_classes\"),\n",
    "        ndims=c.getint(\"network\", \"ndims\"),\n",
    "        dilation=c.getint(\"network\", \"dilation\", fallback=1),\n",
    "        border_mode=c.get(\"network\", \"border_mode\"),\n",
    "        batch_normalization=c.getboolean(\"network\", \"batch_normalization\"),\n",
    "        num_input_channels=params['num_channels'],\n",
    "    )\n",
    "\n",
    "if not params['temporal_reduction']:\n",
    "    network3 = unet.UNetClassifier(unet_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43a17b89-597c-4fdd-a5c1-1d92cad22623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNetClassifier(\n",
      "  (max_pool): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (down_path): Sequential(\n",
      "    (0): UNetLayer(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv3d(1, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): Identity()\n",
      "        (3): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (4): ReLU()\n",
      "        (5): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): UNetLayer(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): Identity()\n",
      "        (3): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (4): ReLU()\n",
      "        (5): Identity()\n",
      "      )\n",
      "    )\n",
      "    (2): UNetLayer(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): Identity()\n",
      "        (3): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (4): ReLU()\n",
      "        (5): Identity()\n",
      "      )\n",
      "    )\n",
      "    (3): UNetLayer(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): Identity()\n",
      "        (3): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (4): ReLU()\n",
      "        (5): Identity()\n",
      "      )\n",
      "    )\n",
      "    (4): UNetLayer(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv3d(512, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): Identity()\n",
      "        (3): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (4): ReLU()\n",
      "        (5): Identity()\n",
      "      )\n",
      "    )\n",
      "    (5): UNetLayer(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv3d(1024, 2048, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): Identity()\n",
      "        (3): Conv3d(2048, 2048, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (4): ReLU()\n",
      "        (5): Identity()\n",
      "      )\n",
      "    )\n",
      "    (6): UNetLayer(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv3d(2048, 4096, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): Identity()\n",
      "        (3): Conv3d(4096, 4096, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (4): ReLU()\n",
      "        (5): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (up_path): Sequential(\n",
      "    (0): ConvTranspose3d(4096, 2048, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
      "    (1): UNetLayer(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv3d(4096, 2048, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): Identity()\n",
      "        (3): Conv3d(2048, 2048, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (4): ReLU()\n",
      "        (5): Identity()\n",
      "      )\n",
      "    )\n",
      "    (2): ConvTranspose3d(2048, 1024, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
      "    (3): UNetLayer(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv3d(2048, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): Identity()\n",
      "        (3): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (4): ReLU()\n",
      "        (5): Identity()\n",
      "      )\n",
      "    )\n",
      "    (4): ConvTranspose3d(1024, 512, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
      "    (5): UNetLayer(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv3d(1024, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): Identity()\n",
      "        (3): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (4): ReLU()\n",
      "        (5): Identity()\n",
      "      )\n",
      "    )\n",
      "    (6): ConvTranspose3d(512, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
      "    (7): UNetLayer(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): Identity()\n",
      "        (3): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (4): ReLU()\n",
      "        (5): Identity()\n",
      "      )\n",
      "    )\n",
      "    (8): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
      "    (9): UNetLayer(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): Identity()\n",
      "        (3): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (4): ReLU()\n",
      "        (5): Identity()\n",
      "      )\n",
      "    )\n",
      "    (10): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
      "    (11): UNetLayer(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): Identity()\n",
      "        (3): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "        (4): ReLU()\n",
      "        (5): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (final_layer): Conv3d(64, 4, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "  (logsoftmax): LogSoftmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(network3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723cf919-f12d-4a12-b84b-d8f8f3bcaf2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
