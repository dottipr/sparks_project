{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "628be7f8-32a6-4b00-8d25-b0113b344742",
   "metadata": {},
   "source": [
    "### Add colored sparks on video\n",
    "\n",
    "Add colored annotations and predictions (with transparency) on top of sample video\n",
    "\n",
    "Created the 29th November 2019\n",
    "\n",
    "For a given sample video needs:\n",
    "- sample video\n",
    "- mask with sparks annotations\n",
    "- mask with network predicitions for sparks\n",
    "\n",
    "UPDATES:\n",
    "- 28/03/2022 Now using most recent annotations used for training (independently from training name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ea84405-7f9b-417b-b8b1-a57fe34f6bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "662b9d29-20c1-46fd-ae81-30c1fff4ffe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import imageio\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "from PIL import Image\n",
    "from scipy import spatial, optimize\n",
    "\n",
    "from metrics_tools import correspondences_precision_recall, get_sparks_locations_from_mask, process_spark_prediction\n",
    "from dataset_tools import load_movies_ids, load_predictions, load_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b681a06-fcde-475a-a2f3-8e6f17c6d21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paste_annotations_on_video(video, colored_mask):\n",
    "    # video is a RGB video, list of PIL images\n",
    "    # colored_mask is a RGBA video, list of PIL images\n",
    "    for frame,ann in zip(video, colored_mask):\n",
    "        frame.paste(ann, mask = ann.split()[3])\n",
    "\n",
    "def add_colored_annotations_to_video(annotations,video,color,transparency=50,radius=4):\n",
    "    # annotations is a list of t,x,y coordinates\n",
    "    # video is a RGB video, list of PIL images\n",
    "    # color is a list of 3 RGB elements\n",
    "    mask_shape = (len(video), video[0].size[1], video[0].size[0], 4)\n",
    "    colored_mask = np.zeros(mask_shape, dtype=np.uint8)\n",
    "    for pt in annotations:\n",
    "        colored_mask = color_ball(colored_mask,pt,radius,color,transparency)\n",
    "    colored_mask = [Image.fromarray(frame).convert('RGBA') for frame in colored_mask]\n",
    "\n",
    "    paste_annotations_on_video(video, colored_mask)\n",
    "    return video\n",
    "\n",
    "def l2_dist(p1,p2):\n",
    "    # p1 = (t1,y1,x1)\n",
    "    # p2 = (t2,y2,x2)\n",
    "    t1,y1,x1 = p1\n",
    "    t2,y2,x2 = p2\n",
    "    return math.sqrt(math.pow((t1-t2),2)+math.pow((y1-y2),2)+math.pow((x1-x2),2))\n",
    "\n",
    "def ball(c,r):\n",
    "    # r scalar\n",
    "    # c = (t,y,x)\n",
    "    # returns coordinates c' around c st dist(c,c') <= r\n",
    "    t,y,x = c\n",
    "    t_vect = np.linspace(t-r,t+r, 2*r+1, dtype = int)\n",
    "    y_vect = np.linspace(y-r,y+r, 2*r+1, dtype = int)\n",
    "    x_vect = np.linspace(x-r,x+r, 2*r+1, dtype = int)\n",
    "\n",
    "    cube_idxs = list(itertools.product(t_vect,y_vect,x_vect))\n",
    "    ball_idxs = [pt for pt in cube_idxs if l2_dist(c, pt) <= r]\n",
    "\n",
    "    return ball_idxs\n",
    "\n",
    "def color_ball(mask,c,r,color,transparency=50):\n",
    "    color_idx = ball(c,r)\n",
    "    # mask boundaries\n",
    "    duration, height, width, _ = np.shape(mask)\n",
    "\n",
    "    for t,y,x in color_idx:\n",
    "        if 0 <= t and t < duration and 0 <= y and y < height and 0 <= x and x < width:\n",
    "            mask[t,y,x] = [*color, transparency]\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1b52ff-59e0-4cd6-a817-0ea04caf4a9f",
   "metadata": {},
   "source": [
    "### Load movies, annotations & training predictions (only sparks needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a82dec54-7528-4abe-8202-014a74b9de91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('05', '10', '15', '20', '25', '32', '34', '40', '45')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n"
     ]
    }
   ],
   "source": [
    "# physiological params\n",
    "PIXEL_SIZE = 0.2 # 1 pixel = 0.2 um x 0.2 um\n",
    "global MIN_DIST_XY\n",
    "MIN_DIST_XY = round(1.8 / PIXEL_SIZE) # min distance in space between sparks\n",
    "TIME_FRAME = 6.8 # 1 frame = 6.8 ms\n",
    "global MIN_DIST_T\n",
    "MIN_DIST_T = round(20 / TIME_FRAME) # min distance in time between sparks\n",
    "\n",
    "# parameters\n",
    "ignore_frames = 6\n",
    "\n",
    "t_detection_sparks = 0.55\n",
    "min_radius_sparks = 1\n",
    "\n",
    "transparency = 45\n",
    "\n",
    "# sample training name\n",
    "training_name = \"focal_loss_gamma_5_ubelix\"\n",
    "epoch = 100000\n",
    "data_folder = os.path.join(\"trainings_validation\", training_name)\n",
    "output_folder = os.path.join(\"trainings_validation\",training_name,\"colored_sparks\")\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# load annotations and sparks\n",
    "ys, sparks, puffs, _ = load_predictions(training_name, epoch, data_folder)\n",
    "\n",
    "# load most recent annotation masks\n",
    "recent_annotations_path = os.path.join(\"..\", \"data\", \"sparks_dataset\", \"videos_test\")\n",
    "ys_recent = load_annotations(data_folder=recent_annotations_path)\n",
    "\n",
    "# get movies names as tuple\n",
    "movies_ids = tuple(ys.keys())\n",
    "print(movies_ids)\n",
    "\n",
    "# load movies\n",
    "data_folder = os.path.join(\"..\",\"data\",\"raw_data_and_processing\",\"original_movies\")\n",
    "xs = load_movies_ids(data_folder, movies_ids)\n",
    "\n",
    "# use this to consider sum of puffs and sparks preds inside of puffs\n",
    "sum_sparks_puffs = False\n",
    "\n",
    "# if white_background, add colored sparks to white background\n",
    "# if not white_bacjground, add colored sparks to original movies\n",
    "white_background = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f065c58d-e182-45ab-8e64-3871cf294d9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video 05 ...\n",
      "FALSE POSITIVES\n",
      "[[0.0, 32.0, 318.0], [2.0, 56.0, 177.0], [3.0, 10.0, 282.0], [4.0, 24.0, 371.0], [4.0, 46.0, 239.0], [5.0, 43.0, 314.0], [6.0, 19.0, 252.0], [10.0, 50.0, 54.0], [13.0, 44.0, 177.0], [14.0, 15.0, 106.0], [20.0, 14.0, 161.0], [24.0, 42.0, 162.0], [24.0, 57.0, 176.0], [30.0, 44.0, 245.0], [37.0, 41.0, 215.0], [37.0, 43.0, 115.0], [49.0, 41.0, 312.0], [59.0, 1.0, 327.0], [63.0, 8.0, 160.0], [63.0, 15.0, 324.0], [63.0, 47.0, 182.0], [78.0, 5.0, 388.0], [79.0, 30.0, 171.0], [80.0, 48.0, 67.0], [84.0, 7.0, 172.0], [85.0, 39.0, 181.0], [92.0, 60.0, 103.0], [94.0, 20.0, 337.0], [95.0, 33.0, 284.0], [97.0, 54.0, 176.0], [98.0, 11.0, 154.0], [107.0, 27.0, 259.0], [108.0, 21.0, 337.0], [112.0, 40.0, 103.0], [113.0, 2.0, 326.0], [116.0, 50.0, 49.0], [120.0, 47.0, 170.0], [123.0, 55.0, 205.0], [134.0, 10.0, 219.0], [140.0, 48.0, 78.0], [145.0, 43.0, 224.0], [147.0, 49.0, 51.0], [147.0, 56.0, 103.0], [156.0, 55.0, 143.0], [159.0, 24.0, 198.0], [160.0, 37.0, 225.0], [161.0, 49.0, 61.0], [162.0, 21.0, 137.0], [163.0, 54.0, 177.0], [164.0, 43.0, 115.0], [165.0, 26.0, 323.0], [167.0, 24.0, 122.0], [167.0, 25.0, 361.0], [171.0, 46.0, 73.0], [173.0, 5.0, 379.0], [174.0, 14.0, 211.0], [175.0, 2.0, 326.0], [175.0, 10.0, 133.0], [181.0, 32.0, 223.0], [182.0, 32.0, 321.0], [192.0, 5.0, 387.0], [206.0, 2.0, 326.0], [208.0, 10.0, 375.0], [220.0, 21.0, 108.0], [221.0, 59.0, 121.0], [226.0, 8.0, 358.0], [226.0, 30.0, 120.0], [226.0, 49.0, 55.0], [239.0, 10.0, 125.0], [243.0, 42.0, 117.0], [256.0, 51.0, 168.0], [261.0, 49.0, 51.0], [262.0, 28.0, 326.0], [269.0, 37.0, 115.0], [272.0, 51.0, 196.0], [278.0, 9.0, 126.0], [286.0, 53.0, 238.0], [291.0, 9.0, 207.0], [296.0, 30.0, 90.0], [298.0, 60.0, 214.0], [299.0, 42.0, 116.0], [304.0, 22.0, 360.0], [305.0, 35.0, 317.0], [307.0, 53.0, 136.0], [312.0, 46.0, 76.0], [317.0, 45.0, 181.0], [318.0, 33.0, 91.0], [319.0, 29.0, 192.0], [324.0, 26.0, 290.0], [328.0, 42.0, 114.0], [330.0, 41.0, 176.0], [335.0, 43.0, 188.0], [340.0, 18.0, 109.0], [341.0, 4.0, 407.0], [341.0, 34.0, 206.0], [348.0, 48.0, 62.0], [352.0, 57.0, 176.0], [354.0, 14.0, 104.0], [355.0, 47.0, 102.0], [358.0, 61.0, 218.0], [364.0, 58.0, 123.0], [367.0, 46.0, 187.0], [369.0, 9.0, 125.0], [371.0, 43.0, 304.0], [372.0, 20.0, 230.0], [372.0, 22.0, 145.0], [377.0, 24.0, 372.0], [378.0, 10.0, 125.0], [383.0, 21.0, 184.0], [389.0, 40.0, 156.0], [390.0, 9.0, 317.0], [391.0, 27.0, 240.0], [395.0, 26.0, 178.0], [395.0, 46.0, 308.0], [397.0, 48.0, 62.0], [397.0, 55.0, 156.0], [405.0, 50.0, 102.0], [406.0, 13.0, 248.0], [407.0, 10.0, 206.0], [409.0, 40.0, 98.0], [409.0, 49.0, 183.0], [411.0, 48.0, 75.0], [413.0, 28.0, 264.0], [413.0, 39.0, 145.0], [415.0, 28.0, 240.0], [418.0, 11.0, 374.0], [418.0, 21.0, 144.0], [418.0, 45.0, 309.0], [424.0, 0.0, 421.0], [424.0, 31.0, 281.0], [424.0, 46.0, 182.0], [426.0, 5.0, 320.0], [426.0, 47.0, 272.0], [432.0, 31.0, 282.0], [433.0, 61.0, 212.0], [435.0, 21.0, 185.0], [435.0, 36.0, 225.0], [435.0, 56.0, 169.0], [436.0, 10.0, 366.0], [442.0, 1.0, 418.0], [446.0, 56.0, 90.0], [447.0, 4.0, 420.0], [449.0, 39.0, 77.0], [450.0, 38.0, 186.0], [451.0, 42.0, 89.0], [451.0, 62.0, 217.0], [453.0, 18.0, 181.0], [453.0, 48.0, 176.0], [455.0, 13.0, 250.0], [465.0, 20.0, 138.0], [465.0, 43.0, 116.0], [467.0, 33.0, 74.0], [470.0, 9.0, 380.0], [473.0, 47.0, 211.0], [477.0, 23.0, 177.0], [478.0, 37.0, 175.0], [479.0, 52.0, 182.0], [483.0, 25.0, 101.0], [483.0, 44.0, 115.0], [483.0, 57.0, 142.0], [484.0, 10.0, 375.0], [487.0, 37.0, 264.0], [491.0, 29.0, 149.0], [494.0, 30.0, 227.0], [494.0, 44.0, 177.0], [494.0, 48.0, 137.0], [495.0, 3.0, 314.0], [498.0, 26.0, 82.0], [499.0, 0.0, 421.0], [499.0, 26.0, 128.0], [499.0, 53.0, 163.0]]\n",
      "\n",
      "FALSE POSITIVES AFTER\n",
      "[[6.0, 19.0, 252.0], [10.0, 50.0, 54.0], [13.0, 44.0, 177.0], [14.0, 15.0, 106.0], [20.0, 14.0, 161.0], [24.0, 42.0, 162.0], [24.0, 57.0, 176.0], [30.0, 44.0, 245.0], [37.0, 41.0, 215.0], [37.0, 43.0, 115.0], [49.0, 41.0, 312.0], [59.0, 1.0, 327.0], [63.0, 8.0, 160.0], [63.0, 15.0, 324.0], [63.0, 47.0, 182.0], [78.0, 5.0, 388.0], [79.0, 30.0, 171.0], [80.0, 48.0, 67.0], [84.0, 7.0, 172.0], [85.0, 39.0, 181.0], [92.0, 60.0, 103.0], [94.0, 20.0, 337.0], [95.0, 33.0, 284.0], [97.0, 54.0, 176.0], [98.0, 11.0, 154.0], [107.0, 27.0, 259.0], [108.0, 21.0, 337.0], [112.0, 40.0, 103.0], [113.0, 2.0, 326.0], [116.0, 50.0, 49.0], [120.0, 47.0, 170.0], [123.0, 55.0, 205.0], [134.0, 10.0, 219.0], [140.0, 48.0, 78.0], [145.0, 43.0, 224.0], [147.0, 49.0, 51.0], [147.0, 56.0, 103.0], [156.0, 55.0, 143.0], [159.0, 24.0, 198.0], [160.0, 37.0, 225.0], [161.0, 49.0, 61.0], [162.0, 21.0, 137.0], [163.0, 54.0, 177.0], [164.0, 43.0, 115.0], [165.0, 26.0, 323.0], [167.0, 24.0, 122.0], [167.0, 25.0, 361.0], [171.0, 46.0, 73.0], [173.0, 5.0, 379.0], [174.0, 14.0, 211.0], [175.0, 2.0, 326.0], [175.0, 10.0, 133.0], [181.0, 32.0, 223.0], [182.0, 32.0, 321.0], [192.0, 5.0, 387.0], [206.0, 2.0, 326.0], [208.0, 10.0, 375.0], [220.0, 21.0, 108.0], [221.0, 59.0, 121.0], [226.0, 8.0, 358.0], [226.0, 30.0, 120.0], [226.0, 49.0, 55.0], [239.0, 10.0, 125.0], [243.0, 42.0, 117.0], [256.0, 51.0, 168.0], [261.0, 49.0, 51.0], [262.0, 28.0, 326.0], [269.0, 37.0, 115.0], [272.0, 51.0, 196.0], [278.0, 9.0, 126.0], [286.0, 53.0, 238.0], [291.0, 9.0, 207.0], [296.0, 30.0, 90.0], [298.0, 60.0, 214.0], [299.0, 42.0, 116.0], [304.0, 22.0, 360.0], [305.0, 35.0, 317.0], [307.0, 53.0, 136.0], [312.0, 46.0, 76.0], [317.0, 45.0, 181.0], [318.0, 33.0, 91.0], [319.0, 29.0, 192.0], [324.0, 26.0, 290.0], [328.0, 42.0, 114.0], [330.0, 41.0, 176.0], [335.0, 43.0, 188.0], [340.0, 18.0, 109.0], [341.0, 4.0, 407.0], [341.0, 34.0, 206.0], [348.0, 48.0, 62.0], [352.0, 57.0, 176.0], [354.0, 14.0, 104.0], [355.0, 47.0, 102.0], [358.0, 61.0, 218.0], [364.0, 58.0, 123.0], [367.0, 46.0, 187.0], [369.0, 9.0, 125.0], [371.0, 43.0, 304.0], [372.0, 20.0, 230.0], [372.0, 22.0, 145.0], [377.0, 24.0, 372.0], [378.0, 10.0, 125.0], [383.0, 21.0, 184.0], [389.0, 40.0, 156.0], [390.0, 9.0, 317.0], [391.0, 27.0, 240.0], [395.0, 26.0, 178.0], [395.0, 46.0, 308.0], [397.0, 48.0, 62.0], [397.0, 55.0, 156.0], [405.0, 50.0, 102.0], [406.0, 13.0, 248.0], [407.0, 10.0, 206.0], [409.0, 40.0, 98.0], [409.0, 49.0, 183.0], [411.0, 48.0, 75.0], [413.0, 28.0, 264.0], [413.0, 39.0, 145.0], [415.0, 28.0, 240.0], [418.0, 11.0, 374.0], [418.0, 21.0, 144.0], [418.0, 45.0, 309.0], [424.0, 0.0, 421.0], [424.0, 31.0, 281.0], [424.0, 46.0, 182.0], [426.0, 5.0, 320.0], [426.0, 47.0, 272.0], [432.0, 31.0, 282.0], [433.0, 61.0, 212.0], [435.0, 21.0, 185.0], [435.0, 36.0, 225.0], [435.0, 56.0, 169.0], [436.0, 10.0, 366.0], [442.0, 1.0, 418.0], [446.0, 56.0, 90.0], [447.0, 4.0, 420.0], [449.0, 39.0, 77.0], [450.0, 38.0, 186.0], [451.0, 42.0, 89.0], [451.0, 62.0, 217.0], [453.0, 18.0, 181.0], [453.0, 48.0, 176.0], [455.0, 13.0, 250.0], [465.0, 20.0, 138.0], [465.0, 43.0, 116.0], [467.0, 33.0, 74.0], [470.0, 9.0, 380.0], [473.0, 47.0, 211.0], [477.0, 23.0, 177.0], [478.0, 37.0, 175.0], [479.0, 52.0, 182.0], [483.0, 25.0, 101.0], [483.0, 44.0, 115.0], [483.0, 57.0, 142.0], [484.0, 10.0, 375.0], [487.0, 37.0, 264.0], [491.0, 29.0, 149.0]]\n",
      "\n",
      "FALSE NEGATIVES\n",
      "[[27.0, 44.0, 244.0], [47.0, 44.0, 163.0], [58.0, 24.0, 108.0], [63.0, 50.0, 108.0], [66.0, 15.0, 108.0], [71.0, 46.0, 114.0], [81.0, 17.0, 195.0], [98.0, 25.0, 85.0], [125.0, 27.0, 85.0], [134.0, 25.0, 85.0], [136.0, 47.0, 182.0], [176.0, 48.0, 136.0], [198.0, 22.0, 198.0], [212.0, 37.0, 82.0], [258.0, 28.0, 326.0], [304.0, 21.0, 138.0], [310.0, 22.0, 137.0], [310.0, 27.0, 86.0], [323.0, 14.0, 108.0], [355.0, 45.0, 163.0], [418.0, 20.0, 336.0], [422.0, 20.0, 336.0], [499.0, 29.0, 328.0]]\n",
      "\n",
      "FALSE NEGATIVES AFTER\n",
      "[[27.0, 44.0, 244.0], [47.0, 44.0, 163.0], [58.0, 24.0, 108.0], [63.0, 50.0, 108.0], [66.0, 15.0, 108.0], [71.0, 46.0, 114.0], [81.0, 17.0, 195.0], [98.0, 25.0, 85.0], [125.0, 27.0, 85.0], [134.0, 25.0, 85.0], [136.0, 47.0, 182.0], [176.0, 48.0, 136.0], [198.0, 22.0, 198.0], [212.0, 37.0, 82.0], [258.0, 28.0, 326.0], [304.0, 21.0, 138.0], [310.0, 22.0, 137.0], [310.0, 27.0, 86.0], [323.0, 14.0, 108.0], [355.0, 45.0, 163.0], [418.0, 20.0, 336.0], [422.0, 20.0, 336.0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from metrics_tools import correspondences_precision_recall\n",
    "\n",
    "for movie_id in ['05']:# movies_ids:\n",
    "    print(\"Processing video\", movie_id, \"...\")\n",
    "    \n",
    "    # normalize sample movie\n",
    "    sample_video = xs[movie_id]\n",
    "    sample_video = 255*(sample_video/sample_video.max())\n",
    "    \n",
    "    # get movie duration\n",
    "    movie_duration = sample_video.shape[0]\n",
    "\n",
    "    # get annotated sparks locations (using most recent annotations)\n",
    "    coords_true = get_sparks_locations_from_mask(ys_recent[movie_id],\n",
    "                                                 min_dist_xy=MIN_DIST_XY,\n",
    "                                                 min_dist_t=MIN_DIST_T,\n",
    "                                                 ignore_frames=ignore_frames\n",
    "                                                )\n",
    "        \n",
    "    # get predicted sparks locations\n",
    "    spark_preds = sparks[movie_id]\n",
    "    if sum_sparks_puffs:\n",
    "        # set puff boundarier\n",
    "        t_puffs_lower = 0.3\n",
    "        t_puffs_upper = 0.65 # = t detection puffs\n",
    "        puff_preds = puffs[movie_id]\n",
    "        # compute region where 0.3 <= puffs <= 0.65\n",
    "        binary_puffs_sparks = np.logical_and(puff_preds <= t_puffs_upper,\n",
    "                                             puff_preds >= t_puffs_lower)\n",
    "        # sum value of sparks and puffs in this region\n",
    "        spark_preds = spark_preds + binary_puffs_sparks * puff_preds\n",
    "\n",
    "    coords_preds = process_spark_prediction(pred=spark_preds, \n",
    "                                            movie=sample_video,\n",
    "                                            t_detection=t_detection_sparks,\n",
    "                                            min_dist_xy=MIN_DIST_XY,\n",
    "                                            min_dist_t=MIN_DIST_T,\n",
    "                                            min_radius=min_radius_sparks,\n",
    "                                            ignore_frames=ignore_frames,\n",
    "                                            sigma=2\n",
    "                                           )\n",
    "\n",
    "    # Compute correspondences between annotations and predictions\n",
    "    ''' OLD\n",
    "    distances = spatial.distance_matrix(coords_true, coords_preds)\n",
    "    distances[distances > match_distance] = 9999999\n",
    "    row_ind, col_ind = optimize.linear_sum_assignment(distances)\n",
    "\n",
    "    paired_true = [coords_true[i].tolist() for i,j in zip(row_ind,col_ind) if distances[i,j]<=match_distance]\n",
    "    paired_preds = [coords_preds[j].tolist() for i,j in zip(row_ind,col_ind) if distances[i,j]<=match_distance]\n",
    "    '''\n",
    "    \n",
    "    paired_true, paired_preds, false_positives, false_negatives = correspondences_precision_recall(coords_true,\n",
    "                                                                                                   coords_preds,\n",
    "                                                                                                   MIN_DIST_T,\n",
    "                                                                                                   MIN_DIST_XY,\n",
    "                                                                                                   return_pairs_coords=True\n",
    "                                                                                                  )\n",
    "    \n",
    "    # Write sparks locations to file\n",
    "    file_path = os.path.join(output_folder,f\"{movie_id}_sparks_location.txt\")\n",
    "\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(f\"{datetime.datetime.now()}\\n\\n\")\n",
    "        f.write(f\"Paired annotations and preds:\\n\")\n",
    "        for p_true, p_preds in zip(paired_true, paired_preds):\n",
    "            f.write(f\"{list(map(int, p_true))} {list(map(int, p_preds))}\\n\")\n",
    "        f.write(f\"\\n\")\n",
    "        f.write(f\"Unpaired preds (false positives):\\n\")\n",
    "        for f_p in false_positives:\n",
    "            f.write(f\"{list(map(int, f_p))}\\n\")\n",
    "        f.write(f\"\\n\")\n",
    "        f.write(f\"Unpaired annotations (false negatives):\\n\")\n",
    "        for f_n in false_negatives:\n",
    "            f.write(f\"{list(map(int, f_n))}\\n\")\n",
    "\n",
    "    # Add colored annotations to video\n",
    "    \n",
    "    if white_background:\n",
    "        sample_video.fill(255) # the movie will be white\n",
    "\n",
    "    rgb_video = [Image.fromarray(frame).convert('RGB') for frame in sample_video]\n",
    "\n",
    "    annotated_video = add_colored_annotations_to_video(paired_true, rgb_video, [0,255,0], 0.8*transparency)\n",
    "    annotated_video = add_colored_annotations_to_video(paired_preds, annotated_video, [0,255,200], 0.8*transparency)\n",
    "    annotated_video = add_colored_annotations_to_video(false_positives, annotated_video, [255,255,0], transparency)\n",
    "    annotated_video = add_colored_annotations_to_video(false_negatives, annotated_video, [255,0,0], transparency)\n",
    "\n",
    "    annotated_video = [np.array(frame) for frame in annotated_video]\n",
    "    \n",
    "    # set saved movies filenames\n",
    "    white_background_fn = \"_white_backgroud\" if white_background else \"\"\n",
    "    sum_sparks_fn = \"_sum_puffs\" if sum_sparks_puffs else \"\"\n",
    "    \n",
    "    imageio.volwrite(os.path.join(output_folder,\n",
    "                                  training_name+\"_\"+str(epoch)+\"_\"+movie_id+\"_colored_sparks\"+sum_sparks_fn+white_background_fn+\".tif\"),\n",
    "                     annotated_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dbd94a-93b2-45d9-a92d-269f9e388881",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[1,2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da54c17-b7bf-4263-8bed-d10a30a0150a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860bc4ba-623d-46e7-8b7e-585aebf936be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0ba4e30-838a-48ba-ae9f-53c5c1ff97e3",
   "metadata": {},
   "source": [
    "### Write all script parameters to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba57f0a2-7d4b-4e39-a850-c8c9e7095f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(output_folder,f\"parameters{white_background_fn}.txt\")\n",
    "\n",
    "with open(file_path, 'w') as f:\n",
    "    f.write(f\"{datetime.datetime.now()}\\n\\n\")\n",
    "    \n",
    "    f.write(\"Phyisiological parameters\\n\")\n",
    "    f.write(f\"Pixel size: {PIXEL_SIZE} um\\n\")\n",
    "    f.write(f\"Min distance (x,y): {MIN_DIST_XY} pixels\\n\")\n",
    "    f.write(f\"Time frame: {TIME_FRAME} ms\\n\")\n",
    "    f.write(f\"Min distance t: {MIN_DIST_T} pixels\\n\\n\")\n",
    "    \n",
    "    f.write(\"Training parameters\\n\")\n",
    "    f.write(f\"Training name: {training_name}\\n\")\n",
    "    f.write(f\"Loaded epoch: {epoch}\\n\")\n",
    "    f.write(f\"Dataset folder: {data_folder}\\n\")\n",
    "    f.write(f\"Annotations folder: {recent_annotations_path}\\n\")\n",
    "    f.write(f\"Movies analysed for coloured sparks: {movies_ids}\\n\")\n",
    "    f.write(f\"Num frames ignored by loss function: {ignore_frames}\\n\\n\")\n",
    "    \n",
    "    f.write(\"Sparks detection parameters\\n\")\n",
    "    f.write(f\"Min threshold for sparks detection: {t_detection_sparks}\\n\")\n",
    "    f.write(f\"Min radius of valid spark predictions: {min_radius_sparks}\\n\")\n",
    "    f.write(f\"Using puffs values for sparks detection: {sum_sparks_puffs}\\n\")\n",
    "    if sum_sparks_puffs:\n",
    "        f.write(f\"Min puffs' threshold for sparks over puffs detection: {t_puffs_lower}\\n\")\n",
    "        f.write(f\"Max puffs' threshold for sparks over puffs detection: {t_puffs_upper}\\n\\n\")\n",
    "        \n",
    "    f.write(\"Coloured sparks parameters\\n\")\n",
    "    f.write(f\"Saved coloured sparks path: {output_folder}\\n\")\n",
    "    f.write(f\"Coloured sparks' transparency: {transparency}\\n\")\n",
    "    f.write(f\"Using white background instead of original movies: {white_background}\\n\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3dd910-6ee0-4e36-8f4c-6933cb318572",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
