{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.11.2022\n",
    "\n",
    "# Test Grad-CAM on UNet model\n",
    "\n",
    "Provo a usare una Grad-CAM su un modello salvato della UNet e il movie 34 (dove la fine della wave viene detettata come puff)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from architectures import TempRedUNet\n",
    "from datasets import SparkDataset\n",
    "from in_out_tools import write_videos_on_disk\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from training_inference_tools import run_samples_in_model\n",
    "\n",
    "import unet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing training 'TEMP_new_annotated_peaks_physio'...\n"
     ]
    }
   ],
   "source": [
    "training_name = 'TEMP_new_annotated_peaks_physio'\n",
    "config_file = 'config_temp_new_annotated_peaks_physio.ini'\n",
    "\n",
    "print(f\"Processing training '{training_name}'...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output files will be saved on 'trainings_validation\\TEMP_new_annotated_peaks_physio\\gradCAM'\n"
     ]
    }
   ],
   "source": [
    "output_folder = \"trainings_validation\" # same folder for train and test preds\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# subdirectory of output_folder where predictions are saved\n",
    "# change this to save results for same model with different inference approaches\n",
    "output_name = training_name\n",
    "\n",
    "save_folder = os.path.join(output_folder, output_name, \"gradCAM\")\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "print(f\"Output files will be saved on '{save_folder}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect GPU, if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device 'cuda' with 1 GPUs\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "n_gpus = torch.cuda.device_count()\n",
    "print(f\"Using device '{device}' with {n_gpus} GPUs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading config_files\\config_temp_new_annotated_peaks_physio.ini\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['config_files\\\\config_temp_new_annotated_peaks_physio.ini']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_folder = \"config_files\"\n",
    "CONFIG_FILE = os.path.join(config_folder, config_file)\n",
    "c = configparser.ConfigParser()\n",
    "\n",
    "print(f\"Loading {CONFIG_FILE}\")\n",
    "c.read(CONFIG_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config dataset and UNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Params ###\n",
    "load_epoch = c.getint(\"testing\", \"load_epoch\")\n",
    "\n",
    "batch_size = c.getint(\"testing\", \"batch_size\", fallback=\"1\")\n",
    "ignore_frames = c.getint(\"training\", \"ignore_frames_loss\")\n",
    "\n",
    "temporal_reduction = c.getboolean(\"network\", \"temporal_reduction\", fallback=False)\n",
    "num_channels = c.getint(\"network\", \"num_channels\", fallback=1) if temporal_reduction else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using C:\\Users\\prisc\\Code\\sparks_project\\data\\sparks_dataset as dataset root path\n"
     ]
    }
   ],
   "source": [
    "### Configure sample input ### \n",
    "\n",
    "sample_ids = [\"34\"]\n",
    "\n",
    "dataset_path = os.path.realpath(c.get(\"dataset\", \"relative_path\"))\n",
    "assert os.path.isdir(dataset_path), f\"\\\"{dataset_path}\\\" is not a directory\"\n",
    "print(f\"Using {dataset_path} as dataset root path\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Configure inference method and parameters ###\n",
    "\n",
    "data_step = c.getint(\"testing\", \"data_step\")\n",
    "data_duration = c.getint(\"testing\", \"data_duration\")\n",
    "inference = c.get(\"testing\", \"inference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Configure UNet ###\n",
    "\n",
    "batch_norm = {'batch': True, 'none': False}\n",
    "\n",
    "unet_config = unet.UNetConfig(\n",
    "    steps=c.getint(\"network\", \"unet_steps\"),\n",
    "    first_layer_channels=c.getint(\"network\", \"first_layer_channels\"),\n",
    "    num_classes=4,\n",
    "    ndims=3,\n",
    "    dilation=c.getint(\"network\", \"dilation\", fallback=1),\n",
    "    border_mode=c.get(\"network\", \"border_mode\"),\n",
    "    batch_normalization=batch_norm[c.get(\"network\", \"batch_normalization\")],\n",
    "    num_input_channels=num_channels,\n",
    ")\n",
    "if not temporal_reduction:\n",
    "    network = unet.UNetClassifier(unet_config)\n",
    "else:\n",
    "    assert c.getint(\"dataset\", \"data_duration\") % num_channels == 0, \\\n",
    "    \"using temporal reduction chunks_duration must be a multiple of num_channels\"\n",
    "    network = TempRedUNet(unet_config)\n",
    "\n",
    "network = nn.DataParallel(network).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trained model 'TEMP_new_annotated_peaks_physio' at epoch 100000...\n"
     ]
    }
   ],
   "source": [
    "### Load UNet model ###\n",
    "models_relative_path = 'runs/'\n",
    "model_path = os.path.join(models_relative_path, training_name)\n",
    "#logger.info(f\"Saved model path: {model_path}\")\n",
    "summary_writer = SummaryWriter(os.path.join(model_path, \"summary\"),\n",
    "                               purge_step=0)\n",
    "\n",
    "trainer = unet.TrainingManager(\n",
    "        # training items\n",
    "        training_step = None,\n",
    "        save_path=model_path,\n",
    "        managed_objects=unet.managed_objects({'network': network}),\n",
    "        summary_writer=summary_writer\n",
    "    )\n",
    "\n",
    "print(f\"Loading trained model '{training_name}' at epoch {load_epoch}...\")\n",
    "trainer.load(load_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Grad-CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(network, (1,32,64,512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = medcam.inject(network,\n",
    "                        output_dir='attention_maps',\n",
    "                        backend='gcam',\n",
    "                        layer='layer4',\n",
    "                        label='best',\n",
    "                        save_maps=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('sparks')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d21ea8e127dc18603ed933cb69d3f0e3fbc5bcbc2dd19f44b0f9b09cfcc47615"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
