{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "def load_movie_data(filepath):\n",
    "    # Dummy function to represent loading your specific dataset\n",
    "    # Replace this with actual code to load your movie data\n",
    "    return np.load(filepath)\n",
    "\n",
    "\n",
    "def preprocess_frames(frames):\n",
    "    # Assuming the first few frames can serve as a baseline for normalization\n",
    "    normalizing_frame = np.median(frames[:10], axis=0)\n",
    "    normalized_frames = frames / (normalizing_frame + 1e-6)  # Prevent division by zero\n",
    "    return normalized_frames\n",
    "\n",
    "\n",
    "def difference_and_threshold(normalized_frames, threshold=0.1):\n",
    "    # Custom threshold based on expected Ca²⁺ event intensities\n",
    "    diff_frames = np.diff(normalized_frames, axis=0)\n",
    "    thresholded_frames = (diff_frames > threshold).astype(np.uint8)\n",
    "    return thresholded_frames\n",
    "\n",
    "\n",
    "def find_spark_coordinates(thresholded_frames):\n",
    "    # Simplified for demonstration; real implementation may require more sophisticated analysis\n",
    "    coordinates = np.argwhere(thresholded_frames)\n",
    "    return coordinates\n",
    "\n",
    "\n",
    "def statistical_classification(coordinates, frames, pre_frames=10, alpha=0.05):\n",
    "    true_sparks = []\n",
    "    for idx, y, x in coordinates:\n",
    "        if idx < pre_frames:\n",
    "            continue  # Not enough frames for analysis\n",
    "        pre_fluorescence = frames[idx - pre_frames : idx, y, x].flatten()\n",
    "        m, s = np.mean(pre_fluorescence), np.std(pre_fluorescence)\n",
    "        spark_intensity = frames[idx, y, x]\n",
    "        t_score = (spark_intensity - m) / (s if s > 0 else 1)\n",
    "        p_value = stats.t.sf(np.abs(t_score), pre_frames - 1)  # Two-sided test\n",
    "        if p_value < alpha:\n",
    "            true_sparks.append((x, y, idx))\n",
    "    return true_sparks\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# filepath = 'path/to/your/movie/data.npy'\n",
    "# frames = load_movie_data(filepath)\n",
    "# Ensure your data is loaded such that frames is a numpy array of shape (duration, 64, 512)\n",
    "\n",
    "frames = np.random.rand(600, 64, 512)  # Dummy data for demonstration\n",
    "normalized_frames = preprocess_frames(frames)\n",
    "thresholded_frames = difference_and_threshold(normalized_frames)\n",
    "coordinates = find_spark_coordinates(thresholded_frames)\n",
    "true_sparks = statistical_classification(coordinates, normalized_frames)\n",
    "\n",
    "print(f\"Detected {len(true_sparks)} true Ca²⁺ sparks.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
