{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "06/10/2023\n",
    "\n",
    "Uso questo script per ricreare i datasets cercando di strutturarli meglio\n",
    "- dataset che prende movies e labels come inputs,\n",
    "- dataset che prende dataset_path e movie ids come inputs,\n",
    "- dataset che gestisce l'inference con o senza ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload modules automatically\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import logging\n",
    "import math\n",
    "import ntpath\n",
    "import os\n",
    "\n",
    "from typing import List, Dict, Union, Tuple, Any\n",
    "\n",
    "import imageio\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.ndimage import convolve\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import GaussianBlur\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from config import config, TrainingConfig\n",
    "from data.data_processing_tools import detect_spark_peaks\n",
    "from utils.in_out_tools import load_annotations_ids, load_movies_ids\n",
    "from utils.training_script_utils import init_model, init_dataset\n",
    "from utils.training_inference_tools import do_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:20:15] [WARNING ] [   config   ] <287 > -- No config file found at , trying to use fallback values.\n",
      "[21:20:16] [WARNING ] [tifffile.tifffile] <12146> -- TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n",
      "[21:20:19] [  INFO  ] [utils.training_script_utils] <141 > -- Samples in training dataset: 43\n"
     ]
    }
   ],
   "source": [
    "# Create a TrainingConfig object\n",
    "params = TrainingConfig()\n",
    "\n",
    "# Adapt parameters for debugging\n",
    "params.inference_dataset_size = \"minimal\"\n",
    "params.inference_batch_size = 2\n",
    "params.data_duration = 64\n",
    "params.set_device(device=\"cpu\")\n",
    "\n",
    "# Create a sparkdataset\n",
    "dataset = init_dataset(params=params, sample_ids=[\"05\", \"34\"], testing_dataset=True)\n",
    "\n",
    "# Create a dataloader\n",
    "dataset_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=params.inference_batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=params.num_workers,\n",
    "    pin_memory=params.pin_memory,\n",
    ")\n",
    "\n",
    "# Create a U-Net\n",
    "network = init_model(params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get item from dataloader\n",
    "batch = next(iter(dataset_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['movie_id', 'original_duration', 'data', 'labels', 'sample_id']),\n",
       " tensor([0, 0]),\n",
       " torch.Size([2, 64, 64, 512]),\n",
       " torch.Size([2, 64, 64, 512]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys(), batch[\"movie_id\"], batch[\"data\"].shape, batch[\"labels\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:  RIORGANIZZARE QUESTE FUNZIONI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to run a test sample (i.e., a test dataset) in the UNet\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_raw_preds_dict(\n",
    "    model: torch.nn.Module,\n",
    "    params: TrainingConfig,\n",
    "    test_dataset: torch.utils.data.Dataset,\n",
    "    criterion: Optional[torch.nn.Module] = None,\n",
    "    inference_types: Optional[List[str]] = None,\n",
    "):  # TODO\n",
    "    \"\"\"\n",
    "    Given a trained model and a test sample (i.e., a test dataset), run the\n",
    "    sample in the model and return the predictions.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The trained neural network model.\n",
    "        test_dataset (torch.utils.data.Dataset): The test dataset containing the\n",
    "            sample(s).\n",
    "        params (TrainingConfig): A TrainingConfig containing various parameters.\n",
    "        criterion (torch.nn.Module, optional): If provided, the loss criterion\n",
    "            for computing loss.\n",
    "        inference_types (list of str, optional): List of inference types to use,\n",
    "            or None to use the default type.\n",
    "\n",
    "    Returns:\n",
    "    TODO\n",
    "    \"\"\"\n",
    "    if inference_types is None:\n",
    "        assert params.inference in [\n",
    "            \"overlap\",\n",
    "            \"average\",\n",
    "            \"gaussian\",\n",
    "            \"max\",\n",
    "        ], f\"inference type '{params.inference}' not implemented yet\"\n",
    "        inference_types = [params.inference]\n",
    "\n",
    "    else:\n",
    "        assert all(\n",
    "            i in [\"overlap\", \"average\", \"gaussian\", \"max\"] for i in inference_types\n",
    "        ), \"Unsupported inference type.\"\n",
    "\n",
    "    # Create a dataloader\n",
    "    test_dataloader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=params.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    # Run movie in the network and perform inference\n",
    "    preds = do_inference(\n",
    "    network=model,\n",
    "    params=params,\n",
    "    dataloader=test_dataloader,\n",
    "    device=params.device,\n",
    "    compute_loss=True if criterion is not None else False,\n",
    "    inference_typesinference_types\n",
    ")\n",
    "\n",
    "    # Get original movie xs and annotations ys\n",
    "    xs = test_dataset.data[0]\n",
    "    if test_dataset.gt_available:\n",
    "        ys = test_dataset.annotations[0]\n",
    "\n",
    "    # Remove padded frames\n",
    "    pad = test_dataset.pad\n",
    "    if pad > 0:\n",
    "        start_pad = pad // 2\n",
    "        end_pad = -(pad // 2 + pad % 2)\n",
    "        xs = xs[start_pad:end_pad]\n",
    "\n",
    "        if test_dataset.temporal_reduction:\n",
    "            start_pad = start_pad // test_dataset.num_channels\n",
    "            end_pad = end_pad // test_dataset.num_channels\n",
    "\n",
    "        if params.nn_architecture != \"unet_lstm\":\n",
    "            if test_dataset.gt_available:\n",
    "                ys = ys[start_pad:end_pad]\n",
    "            if len(inference_types) == 1:\n",
    "                if not return_dict:\n",
    "                    preds = preds[:, start_pad:end_pad]\n",
    "                else:\n",
    "                    preds = {\n",
    "                        event_type: pred[start_pad:end_pad]\n",
    "                        for event_type, pred in preds.items()\n",
    "                    }\n",
    "            else:\n",
    "                if not return_dict:\n",
    "                    preds = {i: p[:, start_pad:end_pad] for i, p in preds.items()}\n",
    "                else:\n",
    "                    for i, preds_dict in preds.items():\n",
    "                        preds[i] = {\n",
    "                            event_type: pred[start_pad:end_pad]\n",
    "                            for event_type, pred in preds_dict.items()\n",
    "                        }\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    # If original sample was shorter than the current movie duration,\n",
    "    # remove additional padded frames\n",
    "    movie_duration = test_dataset.movie_duration\n",
    "    if movie_duration < xs.shape[0]:\n",
    "        pad = xs.shape[0] - movie_duration\n",
    "        start_pad = pad // 2\n",
    "        end_pad = -(pad // 2 + pad % 2)\n",
    "        xs = xs[start_pad:end_pad]\n",
    "\n",
    "        if test_dataset.temporal_reduction:\n",
    "            start_pad = start_pad // test_dataset.num_channels\n",
    "            end_pad = end_pad // test_dataset.num_channels\n",
    "\n",
    "        if ys is not None:\n",
    "            ys = ys[start_pad:end_pad]\n",
    "\n",
    "        if len(inference_types) == 1:\n",
    "            if not return_dict:\n",
    "                preds = preds[:, start_pad:end_pad]\n",
    "            else:\n",
    "                preds = {\n",
    "                    event_type: pred[start_pad:end_pad]\n",
    "                    for event_type, pred in preds.items()\n",
    "                }\n",
    "        else:\n",
    "            if not return_dict:\n",
    "                preds = {i: p[:, start_pad:end_pad] for i, p in preds.items()}\n",
    "            else:\n",
    "                for i, preds_dict in preds.items():\n",
    "                    preds[i] = {\n",
    "                        event_type: pred[start_pad:end_pad]\n",
    "                        for event_type, pred in preds_dict.items()\n",
    "                    }\n",
    "\n",
    "    if criterion is not None:\n",
    "        assert ys is not None, \"Cannot compute loss if annotations are not available.\"\n",
    "\n",
    "        if ys.ndim == 3:\n",
    "            if len(inference_types) == 1 and not return_dict:\n",
    "                preds_loss = preds[\n",
    "                    :, test_dataset.ignore_frames : -test_dataset.ignore_frames\n",
    "                ]\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "                # Still need to adapt code to compute loss for list of inference\n",
    "                # types, however usually loss should be computed only during\n",
    "                # training, and therefore inference_types should be None.\n",
    "                # Similarly, return_dict should be False.\n",
    "\n",
    "            ys_loss = ys[test_dataset.ignore_frames : -test_dataset.ignore_frames]\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        if params.criterion == \"dice_loss\":\n",
    "            # set regions in pred where label is ignored to 0\n",
    "            preds_loss = preds_loss * (ys_loss != 4)\n",
    "            ys_loss = ys_loss * (ys_loss != 4)\n",
    "        else:\n",
    "            ys_loss = ys_loss.long()[None, :]\n",
    "            preds_loss = preds_loss[None, :]\n",
    "\n",
    "        # Move criterion weights to cpu\n",
    "        if hasattr(criterion, \"weight\") and criterion.weight.is_cuda:\n",
    "            criterion.weight = criterion.weight.cpu()\n",
    "        if hasattr(criterion, \"NLLLoss\") and criterion.NLLLoss.weight.is_cuda:\n",
    "            criterion.NLLLoss.weight = criterion.NLLLoss.weight.cpu()\n",
    "\n",
    "        loss = criterion(preds_loss, ys_loss).item()\n",
    "        return xs.numpy(), ys.numpy(), preds.numpy(), loss\n",
    "\n",
    "    else:\n",
    "        if len(inference_types) == 1:\n",
    "            if not return_dict:\n",
    "                preds = preds.numpy()\n",
    "            else:\n",
    "                preds = {event_type: pred.numpy() for event_type, pred in preds.items()}\n",
    "        else:\n",
    "            if not return_dict:\n",
    "                preds = {i: p.numpy() for i, p in preds.items()}\n",
    "            else:\n",
    "                for i, preds_dict in preds.items():\n",
    "                    preds[i] = {\n",
    "                        event_type: pred.numpy()\n",
    "                        for event_type, pred in preds_dict.items()\n",
    "                    }\n",
    "\n",
    "    return xs.numpy(), ys.numpy(), preds if ys is not None else xs.numpy(), preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_preds_from_path(  # TODO: vedere se si puÃ² eliminare e tenere solo get_preds\n",
    "    model: nn.Module,\n",
    "    params: TrainingConfig,\n",
    "    movie_path: str,\n",
    "    output_dir: Optional[str] = None,\n",
    ") -> [Tuple[torch.Tensor, torch.Tensor]]:\n",
    "    \"\"\"\n",
    "    Function to get predictions from a movie path.\n",
    "\n",
    "    Args:\n",
    "    - model (torch.nn.Module): The trained neural network model.\n",
    "    - params (TrainingConfig): A TrainingConfig containing various parameters.\n",
    "    - movie_path: Path to the movie.\n",
    "    - return_dict (bool, optional): Whether to return a dictionary with\n",
    "        inference type as key and predictions as value, or a single tensor of\n",
    "        predictions. Defaults to False.\n",
    "    - output_dir: If not None, save raw predictions on disk.\n",
    "\n",
    "    Returns:\n",
    "    - If return_dict is True, return a dictionary with keys 'sparks', 'puffs',\n",
    "        'waves'; else return a tuple of numpy arrays with integral values for\n",
    "        classes and instances.\n",
    "    \"\"\"\n",
    "\n",
    "    ### Get sample as dataset ###\n",
    "    sample_dataset = SparkDatasetInference(\n",
    "        sample_path=movie_path,\n",
    "        params=params,\n",
    "        # resampling=False, # It could be implemented later\n",
    "        # resampling_rate=150,\n",
    "    )\n",
    "\n",
    "    ### Run sample in UNet ###\n",
    "    input_movie, preds_dict = get_raw_preds_dict(\n",
    "        model=model,\n",
    "        test_dataset=sample_dataset,\n",
    "        params=params,\n",
    "        inference_types=None,\n",
    "        return_dict=True,\n",
    "    )\n",
    "\n",
    "    ### Get processed output ###\n",
    "\n",
    "    # Get predicted segmentation and event instances\n",
    "    preds_instances, preds_segmentation, _ = process_raw_predictions(\n",
    "        raw_preds_dict=preds_dict,\n",
    "        input_movie=input_movie,\n",
    "        training_mode=False,\n",
    "        debug=False,\n",
    "    )\n",
    "    # preds_instances and preds_segmentations are dictionaries\n",
    "    # with keys 'sparks', 'puffs', 'waves'.\n",
    "\n",
    "    # Save raw preds on disk ### I don't know if this is necessary\n",
    "    if output_dir is not None:\n",
    "        # Create output directory if it does not exist\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        write_videos_on_disk(\n",
    "            training_name=None,\n",
    "            video_name=sample_dataset.video_name,\n",
    "            path=output_dir,\n",
    "            preds=[\n",
    "                None,\n",
    "                preds_dict[\"sparks\"],\n",
    "                preds_dict[\"waves\"],\n",
    "                preds_dict[\"puffs\"],\n",
    "            ],\n",
    "            ys=None,\n",
    "        )\n",
    "\n",
    "    if return_dict:\n",
    "        return preds_segmentation, preds_instances\n",
    "\n",
    "    else:\n",
    "        # Get integral values for classes and instances\n",
    "        preds_segmentation = preds_dict_to_mask(preds_segmentation)\n",
    "        preds_instances = sum(preds_instances.values())\n",
    "        # Instances already have different IDs\n",
    "\n",
    "        return preds_segmentation, preds_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = do_inference(\n",
    "    network=network,\n",
    "    params=params,\n",
    "    dataloader=dataset_loader,\n",
    "    device=params.device,\n",
    "    inference_types=[\"overlap\", \"average\", \"gaussian\", \"max\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 500, 64, 512]),\n",
       " torch.Size([4, 500, 64, 512]),\n",
       " torch.Size([4, 500, 64, 512]),\n",
       " torch.Size([4, 500, 64, 512]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0][\"overlap\"].shape, pred[0][\"average\"].shape, pred[0][\"gaussian\"].shape, pred[0][\n",
    "    \"max\"\n",
    "].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 904, 64, 512]),\n",
       " torch.Size([4, 904, 64, 512]),\n",
       " torch.Size([4, 904, 64, 512]),\n",
       " torch.Size([4, 904, 64, 512]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[1][\"overlap\"].shape, pred[1][\"average\"].shape, pred[1][\"gaussian\"].shape, pred[1][\n",
    "    \"max\"\n",
    "].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'Image [3]' at 0x298e8a50520>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize the predictions with napari\n",
    "import napari\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(pred[0][\"overlap\"].numpy())\n",
    "viewer.add_image(pred[0][\"average\"].numpy())\n",
    "viewer.add_image(pred[0][\"gaussian\"].numpy())\n",
    "viewer.add_image(pred[0][\"max\"].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sparks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
