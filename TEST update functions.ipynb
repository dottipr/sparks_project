{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "06/10/2023\n",
    "\n",
    "Uso questo script per ricreare i datasets cercando di strutturarli meglio\n",
    "- dataset che prende movies e labels come inputs,\n",
    "- dataset che prende dataset_path e movie ids come inputs,\n",
    "- dataset che gestisce l'inference con o senza ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# reload modules automatically\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import logging\n",
    "import math\n",
    "import ntpath\n",
    "import os\n",
    "\n",
    "from typing import List, Dict, Union, Tuple, Any\n",
    "\n",
    "import imageio\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.ndimage import convolve\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import GaussianBlur\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from config import config, TrainingConfig\n",
    "from data.data_processing_tools import detect_spark_peaks\n",
    "from utils.in_out_tools import load_annotations_ids, load_movies_ids\n",
    "from utils.training_script_utils import init_model, init_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:06:31] [WARNING ] [   config   ] <287 > -- No config file found at , trying to use fallback values.\n",
      "[19:06:32] [WARNING ] [tifffile.tifffile] <12146> -- TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n",
      "[19:06:35] [  INFO  ] [utils.training_script_utils] <132 > -- Samples in training dataset: 31\n"
     ]
    }
   ],
   "source": [
    "# create a TrainingConfig object\n",
    "params = TrainingConfig()\n",
    "params.inference_dataset_size = \"minimal\"\n",
    "params.inference_batch_size = 2\n",
    "\n",
    "# create a sparkdataset\n",
    "dataset = init_dataset(params=params, sample_ids=[\"05\", \"34\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataloader\n",
    "dataset_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=params.inference_batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=params.num_workers,\n",
    "    pin_memory=params.pin_memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get item from dataloader\n",
    "item = next(iter(dataset_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['movie_id', 'original_duration', 'data', 'labels', 'sample_id'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0]), torch.Size([2, 256, 64, 512]), torch.Size([2, 256, 64, 512]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item[\"movie_id\"], item[\"data\"].shape, item[\"labels\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a U-Net\n",
    "network = init_model(params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cuda'), 'overlap')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.device, params.inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: riorganizzare le fcts do_inference e get_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_batch_in_unet(\n",
    "    network: torch.nn.Module, batch_data: torch.Tensor, unet_steps: int\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Run a batch of data through a U-Net network, where the input is first padded\n",
    "    to suit U-Net's conditions on the input size, and the output is cropped to\n",
    "    the original size afterwards.\n",
    "\n",
    "    Args:\n",
    "        network (torch.nn.Module): The U-Net network to run the data through.\n",
    "        batch_data (torch.Tensor): The batch of data to run through the network.\n",
    "        unet_steps (int): TODO\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The output of the network after running the batch of data through it.\n",
    "    \"\"\"\n",
    "    # Calculate the required padding for both height and width:\n",
    "    _, _, h, w = batch_data.shape\n",
    "\n",
    "    h_pad = 2**unet_steps - h % 2**unet_steps if h % 2**unet_steps != 0 else 0\n",
    "    w_pad = 2**unet_steps - w % 2**unet_steps if w % 2**unet_steps != 0 else 0\n",
    "\n",
    "    # Pad the input tensor once with calculated padding values\n",
    "    batch_data = F.pad(\n",
    "        batch_data,\n",
    "        (w_pad // 2, w_pad // 2 + w_pad % 2, h_pad // 2, h_pad // 2 + h_pad % 2),\n",
    "    )\n",
    "\n",
    "    batch_preds = network(batch_data[:, None])\n",
    "    # b x 4 x d x 64 x 512 with 3D-UNet\n",
    "    # b x 4 x 64 x 512 with LSTM-UNet -> not implemented yet\n",
    "\n",
    "    # Crop the output tensor based on the padding\n",
    "    crop_h_start = h_pad // 2\n",
    "    crop_h_end = -(h_pad // 2 + h_pad % 2) if h_pad > 0 else None\n",
    "    crop_w_start = w_pad // 2\n",
    "    crop_w_end = -(w_pad // 2 + w_pad % 2) if w_pad > 0 else None\n",
    "    batch_preds = batch_preds[..., crop_h_start:crop_h_end, crop_w_start:crop_w_end]\n",
    "\n",
    "    return batch_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch data size before padding:  torch.Size([2, 256, 64, 512])\n",
      "batch data dtype torch.float32\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "conv3d() received an invalid combination of arguments - got (Tensor, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (Tensor, !Parameter!, !Parameter!, !tuple of (int, int, int)!, !tuple of (bool, bool, bool)!, !tuple of (bool, bool, bool)!, int)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (Tensor, !Parameter!, !Parameter!, !tuple of (int, int, int)!, !tuple of (bool, bool, bool)!, !tuple of (bool, bool, bool)!, int)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\prisc\\Code\\sparks_project\\TEST update functions.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/prisc/Code/sparks_project/TEST%20update%20functions.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m chunks_per_movie, predictions_per_movie, durations_per_movie \u001b[39m=\u001b[39m do_inference(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/prisc/Code/sparks_project/TEST%20update%20functions.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     network\u001b[39m=\u001b[39;49mnetwork, params\u001b[39m=\u001b[39;49mparams, test_dataloader\u001b[39m=\u001b[39;49mdataset_loader, device\u001b[39m=\u001b[39;49mparams\u001b[39m.\u001b[39;49mdevice\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/prisc/Code/sparks_project/TEST%20update%20functions.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\prisc\\anaconda3\\envs\\sparks_new\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;32mc:\\Users\\prisc\\Code\\sparks_project\\TEST update functions.ipynb Cell 13\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prisc/Code/sparks_project/TEST%20update%20functions.ipynb#X16sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m batch_data \u001b[39m=\u001b[39m batch[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mto(device, non_blocking\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prisc/Code/sparks_project/TEST%20update%20functions.ipynb#X16sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m# Run the network on the batch\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/prisc/Code/sparks_project/TEST%20update%20functions.ipynb#X16sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m batch_preds \u001b[39m=\u001b[39m run_batch_in_unet(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prisc/Code/sparks_project/TEST%20update%20functions.ipynb#X16sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     network\u001b[39m=\u001b[39;49mnetwork, batch_data\u001b[39m=\u001b[39;49mbatch_data, unet_steps\u001b[39m=\u001b[39;49mparams\u001b[39m.\u001b[39;49munet_steps\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prisc/Code/sparks_project/TEST%20update%20functions.ipynb#X16sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m )\u001b[39m.\u001b[39mcpu()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prisc/Code/sparks_project/TEST%20update%20functions.ipynb#X16sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m# add each movie_id in the batch to the dict if not already present\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prisc/Code/sparks_project/TEST%20update%20functions.ipynb#X16sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39mfor\u001b[39;00m movie_id \u001b[39min\u001b[39;00m batch_movie_ids:\n",
      "\u001b[1;32mc:\\Users\\prisc\\Code\\sparks_project\\TEST update functions.ipynb Cell 13\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prisc/Code/sparks_project/TEST%20update%20functions.ipynb#X16sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m batch_data \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mpad(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prisc/Code/sparks_project/TEST%20update%20functions.ipynb#X16sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     batch_data,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prisc/Code/sparks_project/TEST%20update%20functions.ipynb#X16sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     (w_pad \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m, w_pad \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m \u001b[39m+\u001b[39m w_pad \u001b[39m%\u001b[39m \u001b[39m2\u001b[39m, h_pad \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m, h_pad \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m \u001b[39m+\u001b[39m h_pad \u001b[39m%\u001b[39m \u001b[39m2\u001b[39m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prisc/Code/sparks_project/TEST%20update%20functions.ipynb#X16sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prisc/Code/sparks_project/TEST%20update%20functions.ipynb#X16sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mbatch data dtype\u001b[39m\u001b[39m\"\u001b[39m, batch_data\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/prisc/Code/sparks_project/TEST%20update%20functions.ipynb#X16sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m batch_preds \u001b[39m=\u001b[39m network(batch_data[:, \u001b[39mNone\u001b[39;49;00m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prisc/Code/sparks_project/TEST%20update%20functions.ipynb#X16sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m# b x 4 x d x 64 x 512 with 3D-UNet\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prisc/Code/sparks_project/TEST%20update%20functions.ipynb#X16sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m# b x 4 x 64 x 512 with LSTM-UNet -> not implemented yet\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prisc/Code/sparks_project/TEST%20update%20functions.ipynb#X16sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prisc/Code/sparks_project/TEST%20update%20functions.ipynb#X16sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m# Crop the output tensor based on the padding\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/prisc/Code/sparks_project/TEST%20update%20functions.ipynb#X16sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m crop_h_start \u001b[39m=\u001b[39m h_pad \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\prisc\\anaconda3\\envs\\sparks_new\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\prisc\\anaconda3\\envs\\sparks_new\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\prisc\\Code\\sparks_project\\models\\UNet\\unet\\network.py:321\u001b[0m, in \u001b[0;36mUNetClassifier.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m--> 321\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlinear_output(x)\n\u001b[0;32m    322\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogsoftmax(x)\n\u001b[0;32m    323\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\prisc\\Code\\sparks_project\\models\\UNet\\unet\\network.py:318\u001b[0m, in \u001b[0;36mUNetClassifier.linear_output\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlinear_output\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m--> 318\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mforward(x)\n",
      "File \u001b[1;32mc:\\Users\\prisc\\Code\\sparks_project\\models\\UNet\\unet\\network.py:276\u001b[0m, in \u001b[0;36mUNet.forward\u001b[1;34m(self, x, return_feature_maps)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, return_feature_maps\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 276\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdown_path[\u001b[39m0\u001b[39;49m](x)\n\u001b[0;32m    278\u001b[0m     feature_maps \u001b[39m=\u001b[39m []\n\u001b[0;32m    280\u001b[0m     down_outputs \u001b[39m=\u001b[39m [x]\n",
      "File \u001b[1;32mc:\\Users\\prisc\\anaconda3\\envs\\sparks_new\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\prisc\\anaconda3\\envs\\sparks_new\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\prisc\\Code\\sparks_project\\models\\UNet\\unet\\network.py:188\u001b[0m, in \u001b[0;36mUNetLayer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m--> 188\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayers(x)\n",
      "File \u001b[1;32mc:\\Users\\prisc\\anaconda3\\envs\\sparks_new\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\prisc\\anaconda3\\envs\\sparks_new\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\prisc\\anaconda3\\envs\\sparks_new\\lib\\site-packages\\torch\\nn\\modules\\container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    214\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 215\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\prisc\\anaconda3\\envs\\sparks_new\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\prisc\\anaconda3\\envs\\sparks_new\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\prisc\\anaconda3\\envs\\sparks_new\\lib\\site-packages\\torch\\nn\\modules\\conv.py:610\u001b[0m, in \u001b[0;36mConv3d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 610\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32mc:\\Users\\prisc\\anaconda3\\envs\\sparks_new\\lib\\site-packages\\torch\\nn\\modules\\conv.py:605\u001b[0m, in \u001b[0;36mConv3d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    593\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    594\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv3d(\n\u001b[0;32m    595\u001b[0m         F\u001b[39m.\u001b[39mpad(\n\u001b[0;32m    596\u001b[0m             \u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups,\n\u001b[0;32m    604\u001b[0m     )\n\u001b[1;32m--> 605\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv3d(\n\u001b[0;32m    606\u001b[0m     \u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups\n\u001b[0;32m    607\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: conv3d() received an invalid combination of arguments - got (Tensor, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (Tensor, !Parameter!, !Parameter!, !tuple of (int, int, int)!, !tuple of (bool, bool, bool)!, !tuple of (bool, bool, bool)!, int)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (Tensor, !Parameter!, !Parameter!, !tuple of (int, int, int)!, !tuple of (bool, bool, bool)!, !tuple of (bool, bool, bool)!, int)\n"
     ]
    }
   ],
   "source": [
    "chunks_per_movie, predictions_per_movie, durations_per_movie = do_inference(\n",
    "    network=network, params=params, test_dataloader=dataset_loader, device=params.device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def do_inference(\n",
    "    network: nn.Module,\n",
    "    params: TrainingConfig,\n",
    "    test_dataloader: torch.utils.data.DataLoader,\n",
    "    device: torch.device,\n",
    "    compute_loss: bool = False,\n",
    "    inference_types: List[str] = [],\n",
    "    return_dict: bool = False,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Given a trained network and a dataloader, run the data through the network\n",
    "    and perform inference.\n",
    "\n",
    "    TODO\n",
    "    \"\"\"\n",
    "    if len(inference_types) == 0:\n",
    "        inference_types = [params.inference]\n",
    "\n",
    "    network.to(device)\n",
    "    network.eval()\n",
    "\n",
    "    # Loop over batches and store results and counts of chunks for each movie\n",
    "    predictions_per_movie = {}\n",
    "    chunks_per_movie = {}\n",
    "    durations_per_movie = {}\n",
    "\n",
    "    for batch in test_dataloader:\n",
    "        batch_movie_ids = batch[\"movie_id\"]\n",
    "        batch_data = batch[\"data\"].to(device, non_blocking=True)\n",
    "\n",
    "        # Run the network on the batch\n",
    "        batch_preds = run_batch_in_unet(\n",
    "            network=network, batch_data=batch_data, unet_steps=params.unet_steps\n",
    "        ).cpu()\n",
    "        # add each movie_id in the batch to the dict if not already present\n",
    "        for movie_id in batch_movie_ids:\n",
    "            if movie_id not in predictions_per_movie:\n",
    "                predictions_per_movie[movie_id] = []\n",
    "                chunks_per_movie[movie_id] = 0\n",
    "                durations_per_movie[movie_id] = batch[\"original_duration\"][movie_id]\n",
    "\n",
    "            chunks_per_movie[movie_id] += 1\n",
    "            predictions_per_movie[movie_id].append(batch[int(movie_id)])\n",
    "\n",
    "    return chunks_per_movie, predictions_per_movie, durations_per_movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "??? maybe the padding of the input can be defined in the forward pass method of the network's definition ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sparks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
