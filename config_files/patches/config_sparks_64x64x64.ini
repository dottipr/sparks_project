; last training: NA
[general]
; comment to disable
wandb_enable = yes
wandb_notes = in this training I am not ignoring frames at the edges of the patches
; if training == 0 only run validation once:
training = yes
testing = yes
; debug_mode = yes


[training]
run_name = sparks_patches_64x64x64_no_ignore_frames
; load_run_name = TEST
; load_epoch = 100000
train_epochs = 100000
; criterion = nll_loss
; criterion = focal_loss
criterion = lovasz_softmax
lr_start = 1e-4
ignore_frames_loss = 0
; only for focal loss and summed losses:
; gamma = 5
; only for summed losses:
; w = 0.5
cuda = yes

save_every = 5000
test_every = 1000
print_every = 100


[dataset]
relative_path = data/sparks_dataset
dataset_size = full
; dataset_size = minimal
; batch_size = 64 <-- in the previous training I used this value
batch_size = 128
; num_workers = 0
; test following values for patch size: 64, 64, 64
data_duration = 64
data_stride = 32
patch_size = 64, 64, 64
data_smoothing = no
norm_video = abs_max
; norm_video = chunk
; remove_background = moving
; remove_background = average
remove_background = no
; only_sparks = no
; noise_data_augmentation = no
sparks_type = raw
; sparks_type = peaks
; mask_cell_exterior = yes


[network]
nn_architecture = pablos_unet
; nn_architecture = github_unet
unet_steps = 4
first_layer_channels = 8
; temporal_reduction = no
; num_channels = 1
; dilation = 1
border_mode = same
; batch_normalization = batch
batch_normalization = none
initialize_weights =
; attention = yes
up_mode = transpose


[inference]
; use this params to validate the unet
data_duration = 64
data_stride = 32
inference = patches
load_epoch = 100000
batch_size = 64
dataset_size = full
; dataset_size = minimal