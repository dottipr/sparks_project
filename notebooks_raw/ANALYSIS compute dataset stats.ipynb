{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Dataset Stats\n",
    "\n",
    "**Author:** Prisca Dotti\n",
    "\n",
    "**Last modified:** 30.03.2024\n",
    "\n",
    "Used this script for the following purposes:\n",
    "- Compute number of individual instances per type\n",
    "- ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload is used to reload modules automatically before entering the\n",
    "# execution of code typed at the IPython prompt.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# To import modules from parent directory in Jupyter Notebook\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from config import TrainingConfig, config\n",
    "from data.data_processing_tools import masks_to_instances_dict, process_raw_predictions\n",
    "from utils.in_out_tools import write_videos_on_disk\n",
    "from utils.training_inference_tools import do_inference\n",
    "from utils.training_script_utils import get_sample_ids, init_dataset, init_model\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "config.verbosity = 3  # To get debug messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:27:10] [WARNING ] [   config   ] <313 > -- No config file found at C:\\Users\\dotti\\Code\\sparks_project, trying to use fallback values.\n"
     ]
    }
   ],
   "source": [
    "############################ Get default parameters ############################\n",
    "\n",
    "test_ids = [\n",
    "    \"05\",\n",
    "    \"10\",\n",
    "    \"15\",\n",
    "    \"20\",\n",
    "    \"25\",\n",
    "    \"32\",\n",
    "    \"34\",\n",
    "    \"40\",\n",
    "    \"45\",\n",
    "]\n",
    "train_ids = [\n",
    "    \"01\",\n",
    "    \"02\",\n",
    "    \"03\",\n",
    "    \"04\",\n",
    "    \"06\",\n",
    "    \"07\",\n",
    "    \"08\",\n",
    "    \"09\",\n",
    "    \"11\",\n",
    "    \"12\",\n",
    "    \"13\",\n",
    "    \"14\",\n",
    "    \"16\",\n",
    "    \"17\",\n",
    "    \"18\",\n",
    "    \"19\",\n",
    "    \"21\",\n",
    "    \"22\",\n",
    "    \"23\",\n",
    "    \"24\",\n",
    "    \"27\",\n",
    "    \"28\",\n",
    "    \"29\",\n",
    "    \"30\",\n",
    "    \"33\",\n",
    "    \"35\",\n",
    "    \"36\",\n",
    "    \"38\",\n",
    "    \"39\",\n",
    "    \"41\",\n",
    "    \"42\",\n",
    "    \"43\",\n",
    "    \"44\",\n",
    "    \"46\",\n",
    "]\n",
    "sample_ids = test_ids + train_ids\n",
    "\n",
    "# Initialize general parameters with default values\n",
    "params = TrainingConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:27:10] [  INFO  ] [  __main__  ] < 3  > -- Loading samples ['05', '10', '15', '20', '25', '32', '34', '40', '45', '01', '02', '03', '04', '06', '07', '08', '09', '11', '12', '13', '14', '16', '17', '18', '19', '21', '22', '23', '24', '27', '28', '29', '30', '33', '35', '36', '38', '39', '41', '42', '43', '44', '46'].\n",
      "[11:27:10] [  INFO  ] [  __main__  ] < 4  > -- Using C:\\Users\\dotti\\Code\\sparks_project\\data\\sparks_dataset as dataset root path.\n"
     ]
    }
   ],
   "source": [
    "############################## Configure dataset ###############################\n",
    "\n",
    "logger.info(f\"Loading samples {sample_ids}.\")\n",
    "logger.info(f\"Using {params.dataset_dir} as dataset root path.\")\n",
    "\n",
    "# Create dataset\n",
    "dataset = init_dataset(\n",
    "    params=params,\n",
    "    sample_ids=sample_ids,\n",
    "    apply_data_augmentation=False,\n",
    "    print_dataset_info=True,\n",
    "    load_instances=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = dataset.get_instances()\n",
    "labels = dataset.get_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500, 64, 512),\n",
       " array([  0,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,  15,  16,\n",
       "         17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,\n",
       "         30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n",
       "         43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
       "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,\n",
       "         69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,\n",
       "         82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,\n",
       "         95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107,\n",
       "        108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
       "        121, 122], dtype=int8),\n",
       " (500, 64, 512),\n",
       " array([0, 1, 3, 4], dtype=int8))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "instances[0].shape, np.unique(instances[0]), labels[0].shape, np.unique(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie 05:\n",
      "(500, 64, 512)\n"
     ]
    }
   ],
   "source": [
    "# Compute the number of instances per class per movie\n",
    "n_instances_per_movie = {movie_id: {} for movie_id in sample_ids}\n",
    "\n",
    "for movie_id, i, l in zip(sample_ids, instances.values(), labels.values()):\n",
    "    movie_instances_dict = masks_to_instances_dict(i, l)\n",
    "\n",
    "    print(f\"Movie {movie_id}:\")\n",
    "    print(masks_to_instances_dict(i, l)[\"sparks\"].shape)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sparks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
